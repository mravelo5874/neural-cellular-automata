{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions\n",
    "- NOTE: tensors are organized as follows: [BATCH_SIZE, CHANNELS, WIDTH, HEIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as func\n",
    "import PIL.Image\n",
    "import random\n",
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torchvision.transforms.functional as trans\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "# * loads an image and converts to a tensor\n",
    "# *     default tensor shape: [BATCH_SIZE (1), CHANNELS (4), WIDTH (_size), HEIGHT (_size)]\n",
    "def load_image_as_tensor(_path, _size, _resample=PIL.Image.Resampling.BICUBIC):\n",
    "    img = PIL.Image.open(_path)\n",
    "    img = img.resize((_size, _size), _resample)\n",
    "    img = np.float32(img) / 255.0\n",
    "    img[..., :3] *= img[..., 3:]\n",
    "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]\n",
    "\n",
    "# * given a tensor of default shape, visualize the first 4 channels as a RGBA image\n",
    "def show_tensor_as_image(_tensor):\n",
    "    img = to_rgb(_tensor).squeeze().permute(1, 2, 0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# * takes the first 4 channels of a tensor of default shape and converts to a RGB image\n",
    "def to_rgb(_x, _alpha='BLACK'):\n",
    "    rgb, a = _x[:, :3], _x[:, 3:4]\n",
    "    if _alpha == 'BLACK':\n",
    "        return torch.clamp(rgb, 0.0, 1.0)\n",
    "    elif _alpha == 'WHITE':\n",
    "        return torch.clamp(1.-a + rgb, 0.0, 1.0)\n",
    "\n",
    "# * creates a circle mask centered at a position of a given radius\n",
    "def circle_mask(_size, _radius, _pos):\n",
    "    Y, X = np.ogrid[:_size, :_size]\n",
    "    dist_from_center = np.sqrt((X - _pos[0])**2 + (Y-_pos[1])**2)\n",
    "    mask = dist_from_center >= _radius\n",
    "    return mask\n",
    "\n",
    "# * creates a mask for half the screen\n",
    "def half_mask(_size, _type):\n",
    "    mask_types = ['left', 'right', 'top', 'bottom']\n",
    "    if _type == 'rand':\n",
    "        _type = mask_types[np.random.randint(0, 4)]\n",
    "    mat = np.zeros([_size, _size])\n",
    "    if _type == 'left':\n",
    "        mat[:, _size//2:] = 1.0\n",
    "    elif _type == 'right':\n",
    "        mat[:, :-_size//2] = 1.0\n",
    "    elif _type == 'top':\n",
    "        mat[_size//2:, :] = 1.0\n",
    "    elif _type == 'bottom':\n",
    "        mat[:-_size//2, :] = 1.0\n",
    "    return mat > 0.0\n",
    "\n",
    "# * shows a batch before and after a forward pass given two (2) tensors\n",
    "def show_batch(_batch_size, _before, _after, _dpi=256):\n",
    "    fig = plt.figure(figsize=(_batch_size, 2), dpi=_dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=_batch_size)\n",
    "    gspec = gridspec.GridSpec(2, _batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    for i in range(_batch_size):\n",
    "        img_i = _before[i].unsqueeze(0)\n",
    "        img_rgb = to_rgb(img_i, _alpha='WHITE').squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)   \n",
    "    for i in range(_batch_size):\n",
    "        img_i = _after[i].unsqueeze(0)\n",
    "        img_rgb = to_rgb(img_i, _alpha='WHITE').squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+_batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal') \n",
    "    plt.show()\n",
    "\n",
    "# * find GPU available\n",
    "clear_output()\n",
    "!nvidia-smi -L\n",
    "\n",
    "# * sets the device\n",
    "# *     defaults to 'cuda'\n",
    "_DEVICE_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', _DEVICE_)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment block\n",
    "\n",
    "# img = load_image_as_tensor('..\\\\_images\\\\'+'cowboy.png', 40)\n",
    "# img = func.pad(img, (12, 12, 12, 12), 'constant', 0)\n",
    "\n",
    "# mask = half_mask(64, 'rand')\n",
    "# img = img * torch.tensor(mask, dtype=torch.int64)\n",
    "# print ('random half mask:')\n",
    "# show_tensor_as_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pre-Made Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SEED_FILE_ = '_2_seeds_64.png'\n",
    "_SIZE_ = 64\n",
    "_SEED_ANGLE_RAD_ = (0)*np.pi\n",
    "\n",
    "seed_img = load_image_as_tensor('../../seeds/'+_SEED_FILE_,  _SIZE_)\n",
    "seed_img = trans.rotate(seed_img, np.rad2deg(_SEED_ANGLE_RAD_))\n",
    "print ('seed_img.shape: ', seed_img.shape)\n",
    "# show_tensor_as_image(to_rgb(seed_img))\n",
    "# show_tensor_as_image(to_rgb(seed_img, 'WHITE'))\n",
    "\n",
    "# create seed mask\n",
    "mask = torch.zeros([1, 1, _SIZE_, _SIZE_])\n",
    "mask[:, :, _SIZE_//2, _SIZE_//2] = 1.0\n",
    "print (f'mask.shape: {mask.shape}')\n",
    "# torch.set_printoptions(threshold=None)\n",
    "# torch.set_printoptions(profile='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Image to Train Model\n",
    "- NOTE: seed _SIZE_ should equal _TARGET-SIZE_ + (2 * _PAD_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TARGET_FILE_ = 'cowboy.png'\n",
    "_TARGET_SIZE_ = 40\n",
    "_PAD_ = 12\n",
    "\n",
    "target_img = load_image_as_tensor('../../images/'+_TARGET_FILE_, _TARGET_SIZE_)\n",
    "target_img = func.pad(target_img, (_PAD_, _PAD_, _PAD_, _PAD_), 'constant', 0)\n",
    "print ('target_img.shape: ', target_img.shape)\n",
    "show_tensor_as_image(target_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptions:\n",
    "- LAPLACIAN: isotropic nca model\n",
    "- SOBEL_MAG: isotrpic nca variant which adds upon the 'laplacian' model by making use of the magnitude of the two directional sobel filters\n",
    "- ANGLE_STEER: angle-based steerable nca\n",
    "- GRAD_STEER: gradient-based steerable nca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SOBEL_DIV_ = 1.0\n",
    "_LAP_DIV_ = 1.0\n",
    "\n",
    "SOBEL_KERN = torch.tensor([\n",
    "    [-1., 0., 1.], \n",
    "    [-2., 0., 2.], \n",
    "    [-1., 0., 1.]])\n",
    "LAP_KERN = torch.tensor([\n",
    "    [1.,   2., 1.], \n",
    "    [2., -12., 2.], \n",
    "    [1.,   2., 1.]])\n",
    "ID_KERN = torch.tensor([\n",
    "    [0., 0., 0.], \n",
    "    [0., 1., 0.], \n",
    "    [0., 0., 0.]])\n",
    "\n",
    "# * performs a convolution per filter per channel\n",
    "def per_channel_conv(_x, _filters):\n",
    "    batch_size, channels, height, width = _x.shape\n",
    "    # * reshape x to make per-channel convolution possible + pad 1 on each side\n",
    "    y = _x.reshape(batch_size*channels, 1, height, width)\n",
    "    y = func.pad(y, (1, 1, 1, 1), 'circular')\n",
    "    # send to current device\n",
    "    _filters = _filters.to(_DEVICE_)\n",
    "    y = y.to(_DEVICE_)\n",
    "    # * perform per-channel convolutions\n",
    "    y = func.conv2d(y, _filters[:, None])\n",
    "    y = y.reshape(batch_size, -1, height, width)\n",
    "    return y\n",
    "\n",
    "# * only uses laplacian operator for local perception\n",
    "def laplacian_perception(_x):\n",
    "    # * add an extra dimention to account for batch size\n",
    "    lap_conv = per_channel_conv(_x, LAP_KERN[None, :]/_LAP_DIV_)\n",
    "    # * concat perception w/ self (identity)\n",
    "    y = torch.cat([_x, lap_conv], 1)\n",
    "    return y\n",
    "\n",
    "# * uses laplacian operator and sobel-magnitude (G) for local perception\n",
    "def sobel_mag_perception(_x):\n",
    "    # * add an extra dimention to account for batch size\n",
    "    lap_conv = per_channel_conv(_x, LAP_KERN[None, :]/_LAP_DIV_)\n",
    "    # * compute sobel-magnitude (G)\n",
    "    sobel_conv = per_channel_conv(_x, torch.stack([SOBEL_KERN/_SOBEL_DIV_, SOBEL_KERN.T/_SOBEL_DIV_]))\n",
    "    gx, gy = sobel_conv[:, ::2], sobel_conv[:, 1::2]\n",
    "    # * concat perceptions w/ self (identity)\n",
    "    y = torch.cat([_x, lap_conv, (gx*gx+gy*gy+1e-8).sqrt()], 1)\n",
    "    return y\n",
    "\n",
    "def angle_steerable_perception(_x):\n",
    "    # * separate states and angle channels\n",
    "    states, angle = _x[:, :-1], _x[:, -1:]\n",
    "    # * compute lap, gx and gy\n",
    "    lap_conv = per_channel_conv(states, LAP_KERN[None, :]/_LAP_DIV_).to(_DEVICE_)\n",
    "    gx = per_channel_conv(states, SOBEL_KERN[None, :]/_SOBEL_DIV_).to(_DEVICE_)\n",
    "    gy = per_channel_conv(states, SOBEL_KERN.T[None, :]/_SOBEL_DIV_).to(_DEVICE_)\n",
    "    # * compute px and py \n",
    "    _cos, _sin = angle.cos(), angle.sin()\n",
    "    px = (gx*_cos)+(gy*_sin)\n",
    "    py = (gy*_cos)-(gx*_sin)\n",
    "    # * concat and return\n",
    "    y = torch.cat([states, lap_conv, px, py], 1)\n",
    "    return y\n",
    "\n",
    "# * copy of paper's perception for testing\n",
    "def copy_steerable_perception(x):\n",
    "    state, angle = x[:, :-1], x[:, -1:]\n",
    "    c, s = angle.cos(), angle.sin()\n",
    "    filters = torch.stack([SOBEL_KERN, SOBEL_KERN.T])\n",
    "    grad = per_channel_conv(state, filters)\n",
    "    gx, gy = grad[:, ::2], grad[:, 1::2]\n",
    "    rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
    "    state_lap = per_channel_conv(state, LAP_KERN[None, :])\n",
    "    res = torch.cat([state, rot_grad, state_lap], 1)\n",
    "    return res\n",
    "\n",
    "def gradient_steerable_perception(_x):\n",
    "    # * compute sobel x/y convolutions\n",
    "    filters = torch.stack([SOBEL_KERN/_SOBEL_DIV_, SOBEL_KERN.T/_SOBEL_DIV_])\n",
    "    grad = per_channel_conv(_x, filters)\n",
    "    # * extract grad and dir\n",
    "    grad, dir = grad[:, :-2], grad[:, -2:]\n",
    "    dir = dir / dir.norm(dim=1, keepdim=True).clip(1.0)\n",
    "    gx, gy = grad[:, ::2], grad[:, 1::2]\n",
    "    # * rotate gx and gy using sin/cos of dir\n",
    "    _cos, _sin = dir[:, :1], dir[:, 1::2]\n",
    "    rot_grad = torch.cat([gx*_cos+gy*_sin, gy*_cos-gx*_sin], 1)\n",
    "    lap_conv = per_channel_conv(_x, LAP_KERN[None, :]/_LAP_DIV_)\n",
    "    # * concat and return\n",
    "    y = torch.cat([_x, lap_conv, rot_grad], 1)\n",
    "    return y\n",
    "    \n",
    "perception = {\n",
    "    'LAPLACIAN': laplacian_perception,\n",
    "    'SOBEL_MAG': sobel_mag_perception,\n",
    "    'ANGLE_STEER': angle_steerable_perception,\n",
    "    'CARBON_COPY_STEER': copy_steerable_perception,\n",
    "    'GRADIENT': gradient_steerable_perception,\n",
    "}\n",
    "\n",
    "def get_alive_mask(_x):\n",
    "    return func.max_pool2d(_x[:, 3:4, :, :], kernel_size=3, stride=1, padding=1) > 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isotropic Neural Cellular Automata Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CHANNELS_ = 16\n",
    "_HIDDEN_ = 128\n",
    "_MODEL_TYPE_ = 'GRADIENT'  #'LAPLACIAN', 'SOBEL_MAG', 'ANGLE_STEER', 'GRADIENT'\n",
    "_ANGLE_CHANNEL_ = 'RANDOMIZED' #'DIRECTION', 'RANDOMIZED' \n",
    "_IS_STEERABLE_ = True if 'STEER' in _MODEL_TYPE_ else False\n",
    "_STOCHASTIC_UPDATE_RATE_ = 0.5\n",
    "\n",
    "class ISO_NCA(torch.nn.Module):\n",
    "    def __init__(self, _channels=_CHANNELS_, _hidden=_HIDDEN_, _device=_DEVICE_, _model_type=_MODEL_TYPE_):\n",
    "        super().__init__()\n",
    "        self.device = _device\n",
    "        _MODEL_TYPE_=_model_type\n",
    "\n",
    "        # * determine number of perceived channels\n",
    "        perception_channels = perception[_MODEL_TYPE_](torch.zeros([1, _channels, 8, 8]).to(_device)).shape[1]\n",
    "        \n",
    "        # * determine hidden channels (equalize the parameter count btwn model types)\n",
    "        hidden_channels = 8*1024 // (perception_channels+_channels)\n",
    "        hidden_channels = (_hidden+31) // 32*32\n",
    "        \n",
    "        # * model layers\n",
    "        self.conv1 = torch.nn.Conv2d(perception_channels, hidden_channels, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(hidden_channels, _channels, 1, bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.conv2.weight.data.zero_()\n",
    "        \n",
    "        # * send to device\n",
    "        self.to(_device)\n",
    "        \n",
    "    def forward(self, _x):\n",
    "        # * get alive mask\n",
    "        alive_mask = get_alive_mask(_x).to(self.device)\n",
    "        \n",
    "        # * perception step\n",
    "        _x = _x.to(self.device)\n",
    "        p = perception[_MODEL_TYPE_](_x)\n",
    "        \n",
    "        # * update step\n",
    "        p = self.conv2(torch.relu(self.conv1(p)))\n",
    "        \n",
    "        # * create stochastic update mask\n",
    "        stochastic_mask = (torch.rand(_x[:, :1, :, :].shape) <= _STOCHASTIC_UPDATE_RATE_).to(self.device, torch.float32)\n",
    "        \n",
    "        # * perform update\n",
    "        _x = _x + p * stochastic_mask\n",
    "        if _IS_STEERABLE_:\n",
    "            states = _x[:, :-1]*alive_mask\n",
    "            angle = _x[:, -1:] % (np.pi*2.0)\n",
    "            _x = torch.cat([states, angle], 1)\n",
    "        else:\n",
    "            _x = _x * alive_mask\n",
    "        return _x\n",
    "\n",
    "# * print model parameter count\n",
    "param_n = sum(p.numel() for p in ISO_NCA().parameters())\n",
    "print('ISO-NCA param count:', param_n)\n",
    "print ('is steerable? '+str(_IS_STEERABLE_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to create videos from NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Notebook Utilities and Setup\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pylab as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
    "import requests\n",
    "import torch\n",
    "import torchvision.transforms.functional as T\n",
    "from colorsys import hsv_to_rgb\n",
    "# from google.colab import drive, output\n",
    "from IPython.display import clear_output, Image\n",
    "from tqdm.notebook import tnrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
    "import moviepy.editor as mvp\n",
    "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
    "\n",
    "def imread(url, max_size=None, mode=None):\n",
    "  if url.startswith(('http:', 'https:')):\n",
    "    headers = {'User-Agent': 'Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    f = io.BytesIO(r.content)\n",
    "  else:\n",
    "    f = url\n",
    "  img = PIL.Image.open(f)\n",
    "  if max_size is not None:\n",
    "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
    "  if mode is not None:\n",
    "    img = img.convert(mode)\n",
    "  img = np.float32(img) / 255.\n",
    "  return img\n",
    "\n",
    "def np2pil(a):\n",
    "  if a.dtype in (np.float32, np.float64):\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None, quality=95):\n",
    "  a = np.asarray(a)\n",
    "  if isinstance(f, str):\n",
    "    fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "      fmt = 'jpeg'\n",
    "    f = open(f, 'wb')\n",
    "  np2pil(a).save(f, fmt, quality=quality)\n",
    "\n",
    "def imencode(a, fmt='jpeg'):\n",
    "  a = np.asarray(a)\n",
    "  if a.ndim == 3 and a.shape[-1] == 4:\n",
    "    fmt = 'png'\n",
    "  f = io.BytesIO()\n",
    "  imwrite(f, a, fmt)\n",
    "  return f.getvalue()\n",
    "\n",
    "def im2url(a, fmt='jpeg'):\n",
    "  encoded = imencode(a, fmt)\n",
    "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
    "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
    "\n",
    "def zoom(img, scale=4):\n",
    "  img = np.repeat(img, scale, 0)\n",
    "  img = np.repeat(img, scale, 1)\n",
    "  return img\n",
    "\n",
    "def imshow(a, fmt='jpeg', scale=4):\n",
    "  display(Image(data=imencode(zoom(a, scale), fmt)))\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "  a = np.asarray(a)\n",
    "  if w is None:\n",
    "    w = int(np.ceil(np.sqrt(a.shape[0])))\n",
    "  th, tw = a.shape[1:3]\n",
    "  pad = (w - a.shape[0]) % w\n",
    "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
    "  h = a.shape[0] // w\n",
    "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
    "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
    "  return a\n",
    "\n",
    "def to_rgb_copy(x):\n",
    "  rgb, a = x[:, :3], x[:, 3:4]\n",
    "  return 1. - a + rgb\n",
    "\n",
    "def grab_plot(close=True):\n",
    "  fig = pl.gcf()\n",
    "  fig.canvas.draw()\n",
    "  img = np.array(fig.canvas.renderer._renderer)\n",
    "  a = np.float32(img[..., 3:]/255.)\n",
    "  img = np.uint8(255*(1.-a)+img[..., :3]*a)\n",
    "  if close:\n",
    "    pl.close()\n",
    "  return img\n",
    "\n",
    "def vis_angle(x, w):\n",
    "  m = get_alive_mask(x).cpu()\n",
    "  rgb = to_rgb_copy(x)[0].clip(0, 1).permute(1, 2, 0).cpu()\n",
    "  ang, a, m = x[0, -1].cpu(), x[0, 3].cpu(), m[0,0]\n",
    "  c, s = ang.cos() * a, ang.sin() * a\n",
    "  px, py = np.mgrid[-1:1:w*1j, -1:1:w*1j]\n",
    "  pl.figure(figsize=(10, 10))\n",
    "  pl.axis('equal')\n",
    "  pl.xlim(-0.8, 0.8); pl.ylim(-0.8,0.8)\n",
    "  pl.quiver(px[m], py[m], c[m], s[m], color=rgb[m], pivot='mid', scale_units='xy', units='xy', scale=_SIZE_/3)\n",
    "  pl.tight_layout()\n",
    "  pl.axis('off')\n",
    "  return grab_plot()\n",
    "\n",
    "class VideoWriter:\n",
    "  def __init__(self, filename='_autoplay.mp4', fps=30., **kwargs):\n",
    "    self.writer = None\n",
    "    self.params = dict(filename=filename, fps=fps, **kwargs)\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "  \n",
    "  def __exit__(self, *args):\n",
    "    self.close()\n",
    "    if self.params['filename'] == '_autoplay.mp4':\n",
    "      self.show()\n",
    "\n",
    "  def add(self, img):\n",
    "    img = np.asarray(img)\n",
    "    if self.writer is None:\n",
    "      h, w = img.shape[:2]\n",
    "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
    "    if img.dtype in (np.float32, np.float64):\n",
    "      img = np.uint8(img.clip(0, 1)*255)\n",
    "    if img.ndim == 2:\n",
    "      img = np.repeat(img[..., None], 3, -1)\n",
    "    self.writer.write_frame(img)\n",
    "\n",
    "  def close(self):\n",
    "    if self.writer is not None:\n",
    "      self.writer.close()\n",
    "\n",
    "  def show(self, **kwargs):\n",
    "    self.close()\n",
    "    fn = self.params['filename']\n",
    "    display(mvp.ipython_display(fn, **kwargs))\n",
    "    \n",
    "def rgb_linspace(n):\n",
    "  '''Generates n visually distinct rgb combinations'''\n",
    "  if n == 1:\n",
    "    return torch.tensor([0.0, 0.0, 0.0], dtype=torch.float32)\n",
    "  return torch.tensor([hsv_to_rgb(i / n, 1.0, 1.0) for i in range(n)], dtype=torch.float32)\n",
    "\n",
    "def rotate_n(x, n, min=0., max=360.):\n",
    "  a = np.linspace(0., 360., n)\n",
    "  for i, a in zip(range(n), a):\n",
    "    x[i] = T.rotate(x[i], a)\n",
    "    # * set direction of growth\n",
    "    if _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "      r = np.deg2rad(a)\n",
    "      x[:, -1] = r\n",
    "  return x\n",
    "\n",
    "def generate_seed(n, sz=128, p=2, r=4, xy=None, angle=0., flip=False, rgb_dist=rgb_linspace):\n",
    "    '''Generates a uniform p-point structured seed of radius r'''\n",
    "    x = torch.zeros(n, _CHANNELS_, sz, sz)\n",
    "    if _IS_STEERABLE_:\n",
    "    # * randomize angles for steerable models\n",
    "      if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "        x[:, -1] = torch.rand(n, sz, sz) * np.pi * 2.\n",
    "    # Initialize p points equidistant around a circle of radius r\n",
    "    t = np.linspace(0, 2 * np.pi, p, endpoint=False)\n",
    "    if xy is None:\n",
    "        xy = (np.c_[r*np.cos(t), r*np.sin(t)]+(sz//2)).astype(np.int32).T\n",
    "    # Assign distinct rgb values to each point\n",
    "    if _IS_STEERABLE_:\n",
    "        SCALAR_CHN = _CHANNELS_-1\n",
    "    else:\n",
    "        SCALAR_CHN = _CHANNELS_\n",
    "    x[:, :3, xy[0], xy[1]] = rgb_dist(xy.shape[1]).T\n",
    "    x[:, 3:SCALAR_CHN, xy[0], xy[1]] = 1.0\n",
    "    x = rotate_n(x, n) if angle is None else T.rotate(x, angle)\n",
    "    if flip:\n",
    "        x = torch.flip(x, [3])\n",
    "    return x\n",
    "\n",
    "def vidgen(filename, model, n_frames=500, max_speed=128, n=16, sz=72, p=2, r=4, angle=None):\n",
    "  with VideoWriter(filename=filename) as vid, torch.no_grad():\n",
    "    x = generate_seed(n, sz, p, r, angle=angle)\n",
    "    for i in tnrange(n_frames, leave=False):\n",
    "        img = to_rgb(x).permute(0, 2, 3, 1).cpu()\n",
    "        vid.add(zoom(tile2d(img), 2))\n",
    "        step_n = min(2**(i//30), max_speed)\n",
    "        for _ in range(step_n):\n",
    "            x = model(x)\n",
    "    vid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOSS_FUNC_ = 'PIXEL_WISE' #['PIXEL_WISE', 'INVARIANT']\n",
    "\n",
    "# * used for carbon-copy loss func\n",
    "copy_target = target_img.squeeze(0).to(_DEVICE_)\n",
    "\n",
    "# r = torch.linspace(0.5/_SIZE_, 1, _SIZE_//2.0)[:, None]\n",
    "# a = torch.range(0, _SIZE_*np.pi)/(_SIZE_/2)\n",
    "# polar_xy = torch.stack([r*a.cos(), r*a.sin()], -1)[None, :]\n",
    "# polar_target = func.grid_sample(unsharpen(target_img[None, ...]), polar_xy)\n",
    "\n",
    "# x = torch.linspace(-1, 1, _SIZE_)\n",
    "# y, x = torch.meshgrid(x, x)\n",
    "# xy_grid = torch.stack([x, y], -1)\n",
    "# fft_target = torch.fft.rfft(polar_target).conj()\n",
    "# polar_target_sqnorm = polar_target.square().sum(-1, keepdim=True)\n",
    "\n",
    "def pixel_wise_loss_func(_x, _target, _scale=1e3, _dims=[]):\n",
    "    return _scale * torch.mean(torch.square(_x[:, :4] - _target), _dims)\n",
    "\n",
    "def carbon_copy_fixed_loss_func(x, scale=1e3, ax=[]):\n",
    "    return scale * torch.mean(torch.square(x[:, :4] - copy_target[:4]), ax)\n",
    "\n",
    "# def invariant_losses_func(_x):\n",
    "#     img = unsharpen(_x)\n",
    "#     polar_img = func.grid_sample(img, polar_xy.repeat(len(img), 1, 1, 1), mode='bicubic')\n",
    "#     x = torch.fft.rfft(polar_img)\n",
    "#     xy = torch.fft.irfft(x*fft_target)\n",
    "#     xx = polar_img.square().sum(-1, keepdim=True)\n",
    "#     yy = polar_target_sqnorm\n",
    "#     diff = xx+yy-2.0*xy\n",
    "#     return diff.mean([1, 2])\n",
    "\n",
    "def invariant_loss_func(_x):\n",
    "    raise NotImplementedError\n",
    "    # return invariant_losses_func(_x).min(-1)[0].mean()\n",
    "\n",
    "loss_func = {\n",
    "    'PIXEL_WISE': pixel_wise_loss_func,\n",
    "    'INVARIANT': invariant_loss_func,\n",
    "    'CARBON_COPY': carbon_copy_fixed_loss_func\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ISO-NCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NAME_ = 'cowboy_2seed_grad'\n",
    "_POOL_SIZE_ = 256\n",
    "_BATCH_SIZE_ = 8\n",
    "_LOWER_LR_ = 1e-5\n",
    "_UPPER_LR_ = 1e-3\n",
    "\n",
    "# * create model / optimizer / lr-scheduler\n",
    "model = ISO_NCA()\n",
    "opt = torch.optim.Adam(model.parameters(), _UPPER_LR_)\n",
    "lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, _LOWER_LR_, _UPPER_LR_, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n",
    "\n",
    "# * create target batch\n",
    "target_batch = target_img.clone().repeat(_BATCH_SIZE_, 1, 1, 1).to(_DEVICE_)\n",
    "\n",
    "# * create seed\n",
    "seed = torch.cat([seed_img, seed_img[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "\n",
    "# * set direction of growth\n",
    "if _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "    seed[:, -1:] = 0\n",
    "    \n",
    "# * create training pool\n",
    "with torch.no_grad():\n",
    "    pool = seed.clone().repeat(_POOL_SIZE_, 1, 1, 1)\n",
    "    if _IS_STEERABLE_:\n",
    "        # * randomize angles for steerable models\n",
    "        if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "            for i in range(_POOL_SIZE_):\n",
    "                rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                pool[i, -1:] = rand\n",
    "                if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                    pool[i, -1:, _SIZE_//2+1, _SIZE_//2] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2+1, _SIZE_//2+1] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2+1, _SIZE_//2-1] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2, _SIZE_//2] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2, _SIZE_//2+1] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2, _SIZE_//2-1] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2-1, _SIZE_//2] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2-1, _SIZE_//2+1] = 0.0\n",
    "                    pool[i, -1:, _SIZE_//2-1, _SIZE_//2-1] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ISO-NCA Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "load_from = '_checkpoints\\\\angle_steer_direction_cowboy_1_seed_v0_cp5000'\n",
    "\n",
    "def load_model_checkpoint():\n",
    "    if not load_model: \n",
    "        return\n",
    "\n",
    "    # * open params json file\n",
    "    params = {}\n",
    "    with open(load_from + '_params.json', 'r') as openfile:\n",
    "        params = json.load(openfile)\n",
    "    \n",
    "    # * load in params\n",
    "    _DEVICE_ = params['_DEVICE_']\n",
    "    _SEED_FILE_ = params['_SEED_FILE_']\n",
    "    _SIZE_ = params['_SIZE_']\n",
    "    _SEED_ANGLE_RAD_ = params['_SEED_ANGLE_RAD_']\n",
    "    _NAME_ = params['_NAME_']\n",
    "    _MODEL_TYPE_ = params['_MODEL_TYPE_']\n",
    "    _IS_STEERABLE_ = params['_IS_STEERABLE_']\n",
    "    _ANGLE_CHANNEL_ = params['_ANGLE_CHANNEL_']\n",
    "    _POOL_SIZE_ = params['_POOL_SIZE_']\n",
    "    _TARGET_FILE_ = params['_TARGET_FILE_']\n",
    "    _TARGET_SIZE_ = params['_TARGET_SIZE_']\n",
    "    _PAD_ = params['_PAD_']\n",
    "    _SOBEL_DIV_ = params['_SOBEL_DIV_']\n",
    "    _LAP_DIV_ = params['_LAP_DIV_']\n",
    "    _BATCH_SIZE_ = params['_BATCH_SIZE_']\n",
    "    _LOWER_LR_ = params['_LOWER_LR_']\n",
    "    _UPPER_LR_ = params['_UPPER_LR_']\n",
    "    _LOSS_FUNC_ = params['_LOSS_FUNC_']\n",
    "    \n",
    "    # * load state dictionary\n",
    "    model.load_state_dict(torch.load(load_from + '.pt', map_location=_DEVICE_))   \n",
    "    model.train()\n",
    "\n",
    "    # * load seed\n",
    "    seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+_SEED_FILE_, _SIZE_)\n",
    "    seed_img = trans.rotate(seed_img, np.rad2deg(_SEED_ANGLE_RAD_))\n",
    "    seed = torch.cat([seed_img, seed_img[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "    \n",
    "    # * create training pool\n",
    "    with torch.no_grad():\n",
    "        pool = seed.clone().repeat(_POOL_SIZE_, 1, 1, 1)\n",
    "        # * randomize angles for steerable models\n",
    "        if _IS_STEERABLE_:\n",
    "            # * randomize angles for steerable models\n",
    "            if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                for i in range(_POOL_SIZE_):\n",
    "                    rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                    pool[i, -1:] = rand\n",
    "                    if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                        pool[i, -1:, _SIZE_//2+1, _SIZE_//2] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2+1, _SIZE_//2+1] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2+1, _SIZE_//2-1] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2, _SIZE_//2] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2, _SIZE_//2+1] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2, _SIZE_//2-1] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2-1, _SIZE_//2] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2-1, _SIZE_//2+1] = 0.0\n",
    "                        pool[i, -1:, _SIZE_//2-1, _SIZE_//2-1] = 0.0\n",
    "            # * set direction of growth\n",
    "            elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                for i in range(_POOL_SIZE_):\n",
    "                    pool[i, -1:] = 0\n",
    "        \n",
    "    # * load target\n",
    "    target_img = load_image_as_tensor('..\\\\images\\\\'+_TARGET_FILE_, _TARGET_SIZE_)\n",
    "    target_img = torch.nn.functional.pad(target_img, (_PAD_, _PAD_, _PAD_, _PAD_), 'constant', 0)\n",
    "    target_batch = target_img.clone().repeat(_BATCH_SIZE_, 1, 1, 1).to(_DEVICE_)\n",
    "    \n",
    "    # * setup loss function etc.\n",
    "    opt = torch.optim.Adam(model.parameters(), _UPPER_LR_)\n",
    "    lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, _LOWER_LR_, _UPPER_LR_, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n",
    "    \n",
    "    print ('model loaded in successfully')\n",
    "\n",
    "load_model_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TRAIN_MODEL_ = False\n",
    "_EPOCHS_ = 10_000\n",
    "_NUM_DAMG_ = 4\n",
    "_DAMG_RATE_ = 2\n",
    "_INFO_RATE_ = 500\n",
    "_SAVE_RATE_ = 5000\n",
    "_VIDEO_RATE_ = 100_000\n",
    "\n",
    "# * save model method\n",
    "def save_model(_dir, _model, _name):\n",
    "    model_path = pathlib.Path(_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(_model.state_dict(), _dir + '\\\\' + _name + '.pt')\n",
    "    \n",
    "    # * save model parameters\n",
    "    dict = {\n",
    "        # seed info\n",
    "        '_SEED_FILE_': _SEED_FILE_,\n",
    "        '_SIZE_': _SIZE_,\n",
    "        '_SEED_ANGLE_RAD_':_SEED_ANGLE_RAD_,\n",
    "        # target image info\n",
    "        '_TARGET_FILE_': _TARGET_FILE_,\n",
    "        '_TARGET_SIZE_': _TARGET_SIZE_,\n",
    "        '_PAD_': _PAD_,\n",
    "        # kernel dividers\n",
    "        '_SOBEL_DIV_': _SOBEL_DIV_,\n",
    "        '_LAP_DIV_': _LAP_DIV_,\n",
    "        # model info\n",
    "        '_CHANNELS_': _CHANNELS_,\n",
    "        '_HIDDEN_': _HIDDEN_,\n",
    "        '_MODEL_TYPE_': _MODEL_TYPE_,\n",
    "        '_IS_STEERABLE_': _IS_STEERABLE_,\n",
    "        '_ANGLE_CHANNEL_': _ANGLE_CHANNEL_,\n",
    "        '_STOCHASTIC_UPDATE_RATE_': _STOCHASTIC_UPDATE_RATE_,\n",
    "        # loss/lr info\n",
    "        '_LOSS_FUNC_': _LOSS_FUNC_,\n",
    "        '_LOWER_LR_': _LOWER_LR_,\n",
    "        '_UPPER_LR_': _UPPER_LR_,\n",
    "        # training info\n",
    "        '_DEVICE_': _DEVICE_,\n",
    "        '_NAME_': _NAME_,\n",
    "        '_EPOCHS_': _EPOCHS_,\n",
    "        '_POOL_SIZE_': _POOL_SIZE_,\n",
    "        '_BATCH_SIZE_': _BATCH_SIZE_,\n",
    "        '_NUM_DAMG_': _NUM_DAMG_,\n",
    "        # training rate info\n",
    "        '_DAMG_RATE_': _DAMG_RATE_,\n",
    "        '_INFO_RATE_': _INFO_RATE_,\n",
    "        '_SAVE_RATE_': _SAVE_RATE_,\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(_dir + '\\\\' + _name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "    print ('model + params saved!')\n",
    "\n",
    "loss_log = []\n",
    "progress = 0\n",
    "\n",
    "# * begin training \n",
    "for _ in tqdm(range(_EPOCHS_+1)):\n",
    "    if not _TRAIN_MODEL_:\n",
    "        print ('skipping training')\n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        # * sample batch from pool\n",
    "        i = len(loss_log)\n",
    "        batch_idxs = np.random.choice(_POOL_SIZE_, _BATCH_SIZE_, replace=False)\n",
    "        x = pool[batch_idxs]\n",
    "        \n",
    "        # * re-order batch based on loss\n",
    "        loss_ranks = torch.argsort(loss_func[_LOSS_FUNC_](x, target_batch, _dims=[-2, -3, -1]), descending=True)\n",
    "        x = x[loss_ranks]\n",
    "        \n",
    "        # * re-add seed into batch\n",
    "        x[:1] = seed\n",
    "\n",
    "        # * randomize angles for steerable models\n",
    "        if _IS_STEERABLE_:\n",
    "            # * randomize angles for steerable models\n",
    "            if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                x[:1, -1:] = rand\n",
    "                if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                    x[:1, -1:, _SIZE_//2+1, _SIZE_//2] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2+1, _SIZE_//2+1] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2+1, _SIZE_//2-1] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2, _SIZE_//2] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2, _SIZE_//2+1] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2, _SIZE_//2-1] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2-1, _SIZE_//2] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2-1, _SIZE_//2+1] = 0.0\n",
    "                    x[:1, -1:, _SIZE_//2-1, _SIZE_//2-1] = 0.0\n",
    "            # * set direction of growth\n",
    "            elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                x[:1, -1:] = 0\n",
    "            \n",
    "        # * damage lowest loss in batch\n",
    "        if i % _DAMG_RATE_ == 0:\n",
    "            # * use random half mask\n",
    "            if i % 10 == 0:\n",
    "                mask = half_mask(_SIZE_, 'rand')\n",
    "            # * use random circle mask\n",
    "            else:\n",
    "                radius = random.uniform(_SIZE_*0.05, _SIZE_*0.2)\n",
    "                u = random.uniform(0, 1) * _SIZE_\n",
    "                v = random.uniform(0, 1) * _SIZE_\n",
    "                mask = circle_mask(_SIZE_, radius, [u, v])\n",
    "            \n",
    "            # * apply mask\n",
    "            x[-_NUM_DAMG_:] *= torch.tensor(mask).to(_DEVICE_)\n",
    "            # * randomize angles for steerable models\n",
    "            if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                inv_mask = ~mask\n",
    "                rand = torch.rand(_SIZE_, _SIZE_).to(_DEVICE_)*torch.pi*2.0\n",
    "                rand *= torch.tensor(inv_mask)\n",
    "                x[-_NUM_DAMG_:, -1:] += rand\n",
    "                \n",
    "            \n",
    "    # * save batch before\n",
    "    if i % _INFO_RATE_ == 0:\n",
    "        before = x.detach().cpu()\n",
    "\n",
    "    # * different loss values\n",
    "    overflow_loss = 0.0\n",
    "    diff_loss = 0.0\n",
    "    target_loss = 0.0\n",
    "    \n",
    "    # * forward pass\n",
    "    num_steps = np.random.randint(64, 96)\n",
    "    for _ in range(num_steps):\n",
    "        prev_x = x\n",
    "        x = model(x)\n",
    "        diff_loss += (x - prev_x).abs().mean()\n",
    "        if _IS_STEERABLE_:\n",
    "            overflow_loss += (x - x.clamp(-2.0, 2.0))[:, :_CHANNELS_-1].square().sum()\n",
    "        else:\n",
    "            overflow_loss += (x - x.clamp(-2.0, 2.0))[:, :_CHANNELS_].square().sum()\n",
    "    \n",
    "    # * calculate losses\n",
    "    target_loss += loss_func[_LOSS_FUNC_](x, target_batch)\n",
    "    target_loss /= 2.0\n",
    "    diff_loss *= 10.0\n",
    "    loss = target_loss + overflow_loss + diff_loss\n",
    "    \n",
    "    # * backward pass\n",
    "    with torch.no_grad():\n",
    "        loss.backward()\n",
    "        # * normalize gradients \n",
    "        for p in model.parameters():\n",
    "            p.grad /= (p.grad.norm()+1e-8) \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        lr_sched.step()\n",
    "        # * re-add batch to pool\n",
    "        pool[batch_idxs] = x\n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        # * print out info\n",
    "        if i % _INFO_RATE_ == 0:\n",
    "            # * show loss plot\n",
    "            clear_output(True)\n",
    "            pl.plot(loss_log, '.', alpha=0.1)\n",
    "            pl.yscale('log')\n",
    "            pl.ylim(np.min(loss_log), loss_log[0])\n",
    "            pl.show()\n",
    "            \n",
    "            # * show batch\n",
    "            after = x.detach().cpu()\n",
    "            show_batch(_BATCH_SIZE_, before, after)\n",
    "            \n",
    "            # * print info\n",
    "            print('\\rstep:', i, '\\tloss:', loss.item(), '\\tmin-loss:', np.min(loss_log),  '\\tlr:', lr_sched.get_last_lr()[0], end='')\n",
    "                \n",
    "        # * save checkpoint\n",
    "        if i % _SAVE_RATE_ == 0 and i != 0:\n",
    "            save_model('_checkpoints', model, _NAME_+'_cp'+str(i))\n",
    "            \n",
    "        # * create video\n",
    "        if i % _VIDEO_RATE_ == 0 and i != 0:\n",
    "            vidgen(f'_videos/{_NAME_}_cp{i}.mp4', model, p=1, n_frames=256, sz=_SIZE_)\n",
    "            \n",
    "# * save final model\n",
    "if _TRAIN_MODEL_:\n",
    "    save_model('_models', model, _NAME_)\n",
    "    vidgen(f'_videos/_final_{_NAME_}.mp4', model, n_frames=256, sz=_SIZE_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "_PLAY_ = True\n",
    "_MODELS_DIR_ = '_models'\n",
    "_PLAY_DEVICE_ = 'cpu'\n",
    "_RADIUS_ = 8\n",
    "_PLAY_SIZE_ = 64\n",
    "_WINDOW_SCALE_ = 10\n",
    "_WINDOW_BG_COLOR_ = (255, 255, 255)\n",
    "_WINDOW_TEXT_COLOR_ = (0, 0, 0)\n",
    "\n",
    "# * set current device\n",
    "_DEVICE_ = _PLAY_DEVICE_\n",
    "\n",
    "# * method to load model for play\n",
    "def load_model(_model_name):\n",
    "    # * read params from json file\n",
    "    params = {}\n",
    "    with open(_MODELS_DIR_+'\\\\'+_model_name+'_params.json', 'r') as openfile:\n",
    "        params = json.load(openfile)\n",
    "\n",
    "    # * set important parameters\n",
    "    global _SOBEL_DIV_\n",
    "    global _LAP_DIV_ \n",
    "    global _MODEL_TYPE_\n",
    "    global _IS_STEERABLE_\n",
    "    global _LOSS_FUNC_\n",
    "    global _ANGLE_CHANNEL_\n",
    "    global _CHANNELS_\n",
    "    _SOBEL_DIV_ = params['_SOBEL_DIV_']\n",
    "    _LAP_DIV_ = params['_LAP_DIV_']\n",
    "    _MODEL_TYPE_ = params['_MODEL_TYPE_']\n",
    "    _IS_STEERABLE_ = params['_IS_STEERABLE_']\n",
    "    _ANGLE_CHANNEL_ = params['_ANGLE_CHANNEL_']\n",
    "    _LOSS_FUNC_ = params['_MODEL_TYPE_']\n",
    "    _CHANNELS_ = params['_CHANNELS_']\n",
    "    \n",
    "    # * load in model\n",
    "    model = ISO_NCA(_device=_PLAY_DEVICE_, _model_type=_MODEL_TYPE_)\n",
    "    model.load_state_dict(torch.load(_MODELS_DIR_+'/'+_model_name+'.pt', map_location=_PLAY_DEVICE_))\n",
    "    model.eval()\n",
    "\n",
    "    # * create seed and tensor\n",
    "    seed_img = load_image_as_tensor('../../seeds/'+params['_SEED_FILE_'], params['_SIZE_'])\n",
    "    seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']))\n",
    "    pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "    seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "    tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "    # * randomize angles for steerable models\n",
    "    if _IS_STEERABLE_:\n",
    "        # * randomize angles for steerable models\n",
    "        if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "            rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "            tensor[:1, -1:] = rand\n",
    "            if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']\n",
    "                tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']\n",
    "        # * set direction of growth\n",
    "        elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "            tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']))\n",
    "    return model, tensor, params, seed_img\n",
    "\n",
    "# * get list of seeds\n",
    "seeds_list = os.listdir('../../seeds')\n",
    "seeds_list = [item for item in seeds_list if item.endswith('.png')]\n",
    "print ('seeds: ', seeds_list)\n",
    "curr_seed = 0\n",
    "\n",
    "# * get list of models\n",
    "model_list = os.listdir(_MODELS_DIR_)\n",
    "model_list = [item.replace('.pt', '') for item in model_list if item.endswith('.pt')]\n",
    "print ('models: ', model_list)\n",
    "curr_model = 0\n",
    "\n",
    "# load first model\n",
    "model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
    "\n",
    "# * misc params\n",
    "angle = 0.0\n",
    "fps = 0\n",
    "show_vecs = False\n",
    "bg_color = 'WHITE' if _WINDOW_BG_COLOR_ == (255, 255, 255) else 'BLACK'\n",
    "prev_time = datetime.datetime.now()\n",
    "\n",
    "# * load vector image\n",
    "vec_img = cv2.imread('../../images/vector_v3.png')\n",
    "vec_img = cv2.resize(vec_img, (_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
    "vec_img = vec_img.astype(float)/255.0\n",
    "\n",
    "# * start pygame\n",
    "pygame.init()\n",
    "pygame.display.set_caption('nca play - '+params['_NAME_'])\n",
    "\n",
    "# * model dependent params\n",
    "size = _PLAY_SIZE_\n",
    "window_size = size * _WINDOW_SCALE_\n",
    "window = pygame.display.set_mode((window_size, window_size))\n",
    "\n",
    "# * text renders\n",
    "font_size = 20\n",
    "my_font = pygame.font.SysFont('consolas', font_size)\n",
    "model_surface = my_font.render('[UP/DOWN] model: ' + params['_NAME_'], False, _WINDOW_TEXT_COLOR_)\n",
    "seed_surface = my_font.render('[LEFT/RIGHT] seed: ' + params['_SEED_FILE_'], False, _WINDOW_TEXT_COLOR_)\n",
    "text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
    "fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
    "vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
    "\n",
    "# * start infinite game loop\n",
    "running = True\n",
    "mouse_down = False\n",
    "model_start = False\n",
    "while running:\n",
    "    if not _PLAY_:\n",
    "        print ('skipping game')\n",
    "        break\n",
    "    # empty cache\n",
    "    torch.cuda.empty_cache()\n",
    "    # handle events\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            # * close application\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                running = False\n",
    "                break\n",
    "            # * toggle showing vectors\n",
    "            if event.key == pygame.K_v:\n",
    "                show_vecs = not show_vecs\n",
    "                vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
    "            # * start current model\n",
    "            if event.key == pygame.K_SPACE:\n",
    "                model_start = not model_start\n",
    "            # * reset current model\n",
    "            if event.key == pygame.K_r:\n",
    "                model_start = False\n",
    "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "                pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "                seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "                tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _IS_STEERABLE_:\n",
    "                    # * randomize angles for steerable models\n",
    "                    if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                        rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                        tensor[:1, -1:] = rand\n",
    "                        if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                    # * set direction of growth\n",
    "                    elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                        tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "            # * use up/down arrow keys to cycle though models\n",
    "            if event.key == pygame.K_UP:\n",
    "                    curr_model += 1\n",
    "                    if curr_model >= len(model_list):\n",
    "                        curr_model = 0\n",
    "            if event.key == pygame.K_DOWN:\n",
    "                curr_model -= 1\n",
    "                if curr_model < 0:\n",
    "                    curr_model = len(model_list)-1\n",
    "            # * load new model\n",
    "            if event.key == pygame.K_UP or event.key == pygame.K_DOWN:\n",
    "                model_start = False\n",
    "                model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
    "                pygame.display.set_caption('nca play - '+params['_NAME_'])\n",
    "                model_surface = my_font.render('[UP/DOWN] model: '+params['_NAME_'], False, _WINDOW_TEXT_COLOR_)\n",
    "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+params['_SEED_FILE_'], False, _WINDOW_TEXT_COLOR_)\n",
    "            # * use left/right arrow keys to cycle though seeds\n",
    "            if event.key == pygame.K_LEFT:\n",
    "                curr_seed += 1\n",
    "                if curr_seed >= len(seeds_list):\n",
    "                    curr_seed = 0\n",
    "            if event.key == pygame.K_RIGHT:\n",
    "                curr_seed -= 1\n",
    "                if curr_seed < 0:\n",
    "                    curr_seed = len(seeds_list)-1\n",
    "            # * load new seed image\n",
    "            if event.key == pygame.K_LEFT or event.key == pygame.K_RIGHT:\n",
    "                model_start = False\n",
    "                seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+seeds_list[curr_seed], params['_SIZE_'])\n",
    "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']))\n",
    "                pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "                seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "                tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _IS_STEERABLE_:\n",
    "                    # * randomize angles for steerable models\n",
    "                    if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                        rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                        tensor[:1, -1:] = rand\n",
    "                        if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                    # * set direction of growth\n",
    "                    elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                        tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
    "        if event.type == pygame.MOUSEWHEEL:\n",
    "            # * let player rotate seed before starting model\n",
    "            if not model_start:\n",
    "                angle = np.round((event.y * 0.05)+angle, decimals=2)\n",
    "                text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
    "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "                pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "                seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "                tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _IS_STEERABLE_:\n",
    "                    # * randomize angles for steerable models\n",
    "                    if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                        rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                        tensor[:1, -1:] = rand\n",
    "                        if _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2+1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2+1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                            tensor[:1, -1:, _SIZE_//2-1, _SIZE_//2-1] = params['_SEED_ANGLE_RAD_']+(angle*np.pi)\n",
    "                    # * set direction of growth\n",
    "                    elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                        tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "        # * mouse click events - erase and draw\n",
    "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            mouse_down = True\n",
    "            if pygame.mouse.get_pressed(3)[2] and model_start:\n",
    "                mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
    "                pos = mouse / window_size * size\n",
    "                dot = np.zeros_like(tensor.detach().cpu().numpy())\n",
    "                dot[:, 3:, int(pos[1]), int(pos[0])] = 1.0\n",
    "                tensor += torch.tensor(dot).to(_PLAY_DEVICE_)\n",
    "        if event.type == pygame.MOUSEBUTTONUP:\n",
    "            mouse_down = False\n",
    "        if (event.type == pygame.MOUSEMOTION or event.type == pygame.MOUSEBUTTONDOWN) and mouse_down and model_start:\n",
    "            mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
    "            pos = mouse / window_size * size\n",
    "            if pygame.mouse.get_pressed(3)[0]:\n",
    "                mask = circle_mask(size, _RADIUS_, pos)\n",
    "                tensor[0:] *= torch.tensor(mask).to(_PLAY_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _ANGLE_CHANNEL_ == 'RANDOMIZED' or _ANGLE_CHANNEL_ == 'SEED_DIR':\n",
    "                    inv_mask = ~mask\n",
    "                    rand = torch.rand(_SIZE_, _SIZE_).to(_PLAY_DEVICE_)*np.pi*2.0\n",
    "                    rand *= torch.tensor(inv_mask).to(_PLAY_DEVICE_)\n",
    "                    tensor[0:, -1:] += rand\n",
    "            \n",
    "    # * update tensor\n",
    "    if model_start:\n",
    "        with torch.no_grad():\n",
    "            tensor = model(tensor)\n",
    "    \n",
    "    # * draw tensor to window\n",
    "    window.fill(_WINDOW_BG_COLOR_)\n",
    "    img = to_rgb(tensor, _alpha=bg_color).squeeze()\n",
    "    vis = (np.array(img.cpu())*255).astype(np.uint8)\n",
    "    if show_vecs:\n",
    "        vecs = tensor[:, -1:].squeeze(0)\n",
    "        vecs = np.array(vecs.cpu())%(2.0*torch.pi)\n",
    "        pixel = pygame.Surface((_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
    "    else:\n",
    "        pixel = pygame.Surface((_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
    "    for j in range(size):\n",
    "        for i in range(size):\n",
    "            color = vis[:, i, j]\n",
    "            # * create vectors for each cell\n",
    "            if show_vecs:\n",
    "                vec_dir = vecs[:, i, j]\n",
    "                vec = imutils.rotate(vec_img, angle=np.rad2deg(vec_dir).item())\n",
    "                vec *= color\n",
    "                surf = pygame.surfarray.make_surface(vec)\n",
    "                pixel.blit(surf, (0, 0))\n",
    "            # * fill cell with color\n",
    "            else:\n",
    "                pixel.fill(color)\n",
    "            draw_me = pygame.Rect(j*_WINDOW_SCALE_, i*_WINDOW_SCALE_, _WINDOW_SCALE_, _WINDOW_SCALE_)\n",
    "            window.blit(pixel, draw_me)\n",
    "    \n",
    "    # * calculate fps\n",
    "    now = datetime.datetime.now()\n",
    "    if (now - prev_time).seconds >= 1.0:\n",
    "        prev_time = now\n",
    "        fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
    "        fps = 0\n",
    "    else:\n",
    "        fps += 1       \n",
    "    \n",
    "    # * render text\n",
    "    window.blit(model_surface, (0, 0))\n",
    "    window.blit(seed_surface, (0, font_size))\n",
    "    window.blit(text_surface, (0, window_size-font_size))\n",
    "    window.blit(vec_surface, (0, window_size-font_size*2))\n",
    "    window.blit(fps_surface, (0, window_size-font_size*3))\n",
    "    \n",
    "    # * flip it!\n",
    "    pygame.display.flip()\n",
    "\n",
    "# * quit it!\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CREATE_VIDEO_ = False\n",
    "_VIDEO_MODEL_ = 'angle_steer_cowboy_2_seeds_v5'\n",
    "global _DEVICE_\n",
    "global _PLAY_DEVICE_\n",
    "_DEVICE_ = 'cuda'\n",
    "_PLAY_DEVICE_ = 'cuda'\n",
    "    \n",
    "if _CREATE_VIDEO_:\n",
    "    model, tensor, params, seed_img = load_model(_VIDEO_MODEL_)\n",
    "    vidgen(f'_videos/{_VIDEO_MODEL_}.mp4', model, n_frames=256, sz=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
