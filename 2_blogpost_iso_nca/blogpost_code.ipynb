{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "974P6JcnyfPf"
      },
      "source": [
        "# Isotropic and Steerable NCA (structured seed experiments)\n",
        "\n",
        "### Author: Craig Fouts (cwf2117@columbia.edu)\n",
        "\n",
        "*Copyright 2023 Craig Fouts*\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "NCTKsrsiOUiG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda available?  False\n",
            "device:  cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\mrave\\OneDrive\\Documents\\GitHub\\neural-cellular-automata\\2_blogpost_iso_nca\\blogpost_code.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrave/OneDrive/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39mbenchmark \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrave/OneDrive/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mrave/OneDrive/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m torch\u001b[39m.\u001b[39;49mset_default_tensor_type(\u001b[39m'\u001b[39;49m\u001b[39mtorch.cuda.FloatTensor\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrave/OneDrive/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#W1sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrave/OneDrive/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# USE_DRIVE = False  #@param{type:\"boolean\"}\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mrave\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:614\u001b[0m, in \u001b[0;36mset_default_tensor_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    613\u001b[0m     t \u001b[39m=\u001b[39m _import_dotted_name(t)\n\u001b[1;32m--> 614\u001b[0m _C\u001b[39m.\u001b[39;49m_set_default_tensor_type(t)\n",
            "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
          ]
        }
      ],
      "source": [
        "#@title Notebook Utilities and Setup\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import matplotlib.pylab as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms.functional as T\n",
        "import warnings\n",
        "from colorsys import hsv_to_rgb\n",
        "# from google.colab import drive, output\n",
        "from IPython.display import clear_output, Image\n",
        "from torch.nn import BatchNorm1d, Dropout, InstanceNorm1d, LayerNorm, Module, ReLU, Sequential\n",
        "from torchvision.transforms.functional_tensor import gaussian_blur\n",
        "from tqdm.notebook import tnrange\n",
        "\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "\n",
        "# output.enable_custom_widget_manager()\n",
        "\n",
        "# * find GPU available\n",
        "clear_output()\n",
        "!nvidia-smi -L\n",
        "\n",
        "# * sets the device\n",
        "# *     defaults to 'cuda'\n",
        "_DEVICE_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print ('cuda available? ', torch.cuda.is_available())\n",
        "print ('device: ', _DEVICE_)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.cuda.empty_cache()\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# USE_DRIVE = False  #@param{type:\"boolean\"}\n",
        "DIRECTORY = 'My Drive/Models'  #@param{type:\"string\"}\n",
        "MODEL_PATH = ''\n",
        "\n",
        "# if USE_DRIVE:\n",
        "#   drive.mount('/content/drive')\n",
        "#   MODEL_PATH = os.path.join('/content/drive', DIRECTORY)\n",
        "\n",
        "def imread(url, max_size=None, mode=None):\n",
        "  if url.startswith(('http:', 'https:')):\n",
        "    headers = {'User-Agent': 'Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0'}\n",
        "    r = requests.get(url, headers=headers)\n",
        "    f = io.BytesIO(r.content)\n",
        "  else:\n",
        "    f = url\n",
        "  img = PIL.Image.open(f)\n",
        "  if max_size is not None:\n",
        "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  if mode is not None:\n",
        "    img = img.convert(mode)\n",
        "  img = np.float32(img) / 255.\n",
        "  return img\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in (np.float32, np.float64):\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None, quality=95):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=quality)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if a.ndim == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "def imshow(a, fmt='jpeg', scale=4):\n",
        "  display(Image(data=imencode(zoom(a, scale), fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(a.shape[0])))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w - a.shape[0]) % w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = a.shape[0] // w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def to_rgb(x):\n",
        "  rgb, a = x[:, :3], x[:, 3:4]\n",
        "  return 1. - a + rgb\n",
        "\n",
        "def grab_plot(close=True):\n",
        "  fig = pl.gcf()\n",
        "  fig.canvas.draw()\n",
        "  img = np.array(fig.canvas.renderer._renderer)\n",
        "  a = np.float32(img[..., 3:]/255.)\n",
        "  img = np.uint8(255*(1.-a)+img[..., :3]*a)\n",
        "  if close:\n",
        "    pl.close()\n",
        "  return img\n",
        "\n",
        "def vis_angle(x, w):\n",
        "  m = get_alive_mask(x).cpu()\n",
        "  rgb = to_rgb(x)[0].clip(0, 1).permute(1, 2, 0).cpu()\n",
        "  ang, a, m = x[0, -1].cpu(), x[0, 3].cpu(), m[0,0]\n",
        "  c, s = ang.cos() * a, ang.sin() * a\n",
        "  px, py = np.mgrid[-1:1:w*1j, -1:1:w*1j]\n",
        "  pl.figure(figsize=(10, 10))\n",
        "  pl.axis('equal')\n",
        "  pl.xlim(-0.8, 0.8); pl.ylim(-0.8,0.8)\n",
        "  pl.quiver(px[m], py[m], c[m], s[m], color=rgb[m], pivot='mid', scale_units='xy', units='xy', scale=W/3)\n",
        "  pl.tight_layout()\n",
        "  pl.axis('off')\n",
        "  return grab_plot()\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename='_autoplay.mp4', fps=30., **kwargs):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kwargs)\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "  \n",
        "  def __exit__(self, *args):\n",
        "    self.close()\n",
        "    if self.params['filename'] == '_autoplay.mp4':\n",
        "      self.show()\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in (np.float32, np.float64):\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if img.ndim == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer is not None:\n",
        "      self.writer.close()\n",
        "\n",
        "  def show(self, **kwargs):\n",
        "    self.close()\n",
        "    fn = self.params['filename']\n",
        "    display(mvp.ipython_display(fn, **kwargs))\n",
        "\n",
        "def vidgen(filename, model, n_frames=500, max_speed=128, n=16, sz=72, p=2, r=4, angle=None):\n",
        "  with VideoWriter(filename=filename) as vid, torch.no_grad():\n",
        "    x = seed(n, sz, p, r, angle=angle)\n",
        "    for i in tnrange(n_frames, leave=False):\n",
        "      img = to_rgb(x).permute(0, 2, 3, 1).cpu()\n",
        "      vid.add(zoom(tile2d(img), 2))\n",
        "      step_n = min(2**(i//30), max_speed)\n",
        "      for _ in range(step_n):\n",
        "        x = model(x)\n",
        "    vid.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4azYa9u3aMT"
      },
      "source": [
        "# Model Legend\n",
        "\n",
        "Select the model of interest from the following\n",
        "\n",
        "* LAPLACIAN:&emsp;Isotropic NCA model\n",
        "* LAP6:&emsp;Isotropic NCA, (trained and/or evaluated) on a hexagonal grid\n",
        "* GRADNORM:&emsp;Isotropic NCA variant discussed in the blogpost\n",
        "* STEERABLE:&emsp;Angle-based Steerable NCA\n",
        "* GRADIENT:&emsp;Gradient-based Steerable NCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "08RFfJ5xl-cL"
      },
      "outputs": [],
      "source": [
        "#@title Model Utilities and Setup {vertical-output:true}\n",
        "\n",
        "MODEL_TYPE = 'LAPLACIAN'  #@param['LAPLACIAN', 'LAP6', 'GRADNORM', 'STEERABLE', 'GRADIENT']\n",
        "UPDATE_RATE = .5\n",
        "\n",
        "CHN = 16\n",
        "ANGLE_CHN = 1 if MODEL_TYPE == 'STEERABLE' else 0\n",
        "SCALAR_CHN = CHN - ANGLE_CHN\n",
        "\n",
        "IDENT = torch.tensor([[0., 0., 0.], [0., 1., 0.], [0., 0., 0.]])\n",
        "SOBEL = torch.tensor([[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]])\n",
        "LAP = torch.tensor([[1., 2., 1.], [2., -12., 2.], [1., 2., 1.]])\n",
        "LAP6 = torch.tensor([[0., 2., 2.], [2., -12., 2.], [2., 2., 0.]])\n",
        "GAUSS = torch.tensor([[1., 2., 1.], [2., 4., 2.], [1., 2., 1.]]) / 16.\n",
        "NHOOD_KERNEL = ((LAP6 if MODEL_TYPE == 'LAP6' else LAP) != 0.).to(torch.float32)\n",
        "\n",
        "def perchannel_conv(x, filters):\n",
        "  b, ch, h, w = x.shape\n",
        "  y = x.reshape(b * ch, 1, h, w)\n",
        "  y = F.pad(y, (1, 1, 1, 1), 'circular')\n",
        "  y = F.conv2d(y, filters[:, None])\n",
        "  return y.reshape(b, -1, h, w)\n",
        "\n",
        "# Isotropic models\n",
        "def laplacian_perception(x):\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap], 1)\n",
        "\n",
        "def lap6_perception(x):\n",
        "  state_lap = perchannel_conv(x, LAP6[None, :])\n",
        "  return torch.cat([x, state_lap], 1)\n",
        "\n",
        "def gradnorm_perception(x):\n",
        "  grad = perchannel_conv(x, torch.stack([SOBEL, SOBEL.T]))\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap, (gx*gx+gy*gy+1e-8).sqrt()], 1)\n",
        "\n",
        "# Steerable models\n",
        "def steerable_perception(x):\n",
        "  state, angle = x[:, :-1], x[:, -1:]\n",
        "  c, s = angle.cos(), angle.sin()\n",
        "  filters = torch.stack([SOBEL, SOBEL.T])\n",
        "  grad = perchannel_conv(state, filters)\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "  state_lap = perchannel_conv(state, LAP[None, :])\n",
        "  return torch.cat([state, rot_grad, state_lap], 1)\n",
        "\n",
        "def gradient_perception(x):\n",
        "  filters = torch.stack([SOBEL, SOBEL.T])\n",
        "  grad = perchannel_conv(x, filters)\n",
        "  grad, dir = grad[:, :-2], grad[:, -2:]\n",
        "  dir = dir / dir.norm(dim=1, keepdim=True).clip(1.)\n",
        "  c, s = dir[:, :1], dir[:, 1:2]\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap, rot_grad], 1)\n",
        "\n",
        "perception = {\n",
        "    'LAPLACIAN': laplacian_perception,\n",
        "    'LAP6': lap6_perception,\n",
        "    'GRADNORM': gradnorm_perception,\n",
        "    'STEERABLE': steerable_perception,\n",
        "    'GRADIENT': gradient_perception\n",
        "}[MODEL_TYPE]\n",
        "\n",
        "def get_alive_mask(x):\n",
        "  mature = (x[:, 3:4] > .1).to(torch.float32)\n",
        "  return perchannel_conv(mature, NHOOD_KERNEL[None, :]) > .5\n",
        "\n",
        "def fibonacci_lattice(n):\n",
        "  '''Generates an n-point fibonacci lattice of radius 1'''\n",
        "  epsilon = 0.33  # Assumes n < 24\n",
        "  golden_ratio = (1 + np.sqrt(5)) / 2.\n",
        "  pts = torch.arange(n)\n",
        "  theta = 2 * np.pi * pts / golden_ratio\n",
        "  phi = torch.arccos(1-2*(pts+epsilon)/(n-1+2*epsilon))\n",
        "  x, y, z = torch.cos(theta)*torch.sin(phi), torch.sin(theta)*torch.sin(phi), torch.cos(phi)\n",
        "  return torch.concat([x[None, :], y[None, :], z[None, :]], 0)\n",
        "\n",
        "def rgb_linspace(n):\n",
        "  '''Generates n visually distinct rgb combinations'''\n",
        "  return torch.tensor([hsv_to_rgb(i / n, 1.0, 1.0) for i in range(n)], dtype=torch.float32)\n",
        "\n",
        "def rotate_n(x, n, min=0., max=360.):\n",
        "  a = np.linspace(0., 360., n)\n",
        "  for i, a in zip(range(n), a):\n",
        "    x[i] = T.rotate(x[i], a)\n",
        "  return x\n",
        "\n",
        "def seed(n, sz=128, p=2, r=4, xy=None, angle=0., flip=False, rgb_dist=rgb_linspace):\n",
        "  '''Generates a uniform p-point structured seed of radius r'''\n",
        "  x = torch.zeros(n, CHN, sz, sz)\n",
        "  if SCALAR_CHN != CHN:\n",
        "    x[:, -1] = torch.rand(n, sz, sz) * np.pi * 2.\n",
        "  # Initialize p points equidistant around a circle of radius r\n",
        "  t = np.linspace(0, 2 * np.pi, p, endpoint=False)\n",
        "  if xy is None:\n",
        "    xy = (np.c_[r*np.cos(t), r*np.sin(t)]+(sz//2)).astype(np.int32).T\n",
        "  # Assign distinct rgb values to each point\n",
        "  x[:, :3, xy[0], xy[1]] = rgb_dist(xy.shape[1]).T\n",
        "  x[:, 3:SCALAR_CHN, xy[0], xy[1]] = 1.0\n",
        "  x = rotate_n(x, n) if angle is None else T.rotate(x, angle)\n",
        "  if flip:\n",
        "    x = torch.flip(x, [3])\n",
        "  return x\n",
        "\n",
        "class CA(torch.nn.Module):\n",
        "  def __init__(self, chn=CHN, hidden_n=128):\n",
        "    super().__init__()\n",
        "    self.chn = chn\n",
        "\n",
        "    # Determine the number of perceived channels\n",
        "    perc_n = perception(torch.zeros([1, chn, 8, 8])).shape[1]\n",
        "\n",
        "    # Approximately equalize the parameter count between model variants\n",
        "    hidden_n = 8 * 1024 // (perc_n + chn)\n",
        "    hidden_n = (hidden_n + 31) // 32 * 32\n",
        "\n",
        "    # Model layers\n",
        "    self.w1 = torch.nn.Conv2d(perc_n, hidden_n, 1)\n",
        "    self.w2 = torch.nn.Conv2d(hidden_n, chn, 1, bias=False)\n",
        "    self.w2.weight.data.zero_()\n",
        "\n",
        "  def forward(self, x, update_rate=UPDATE_RATE):\n",
        "    # Get update and masks\n",
        "    alive = get_alive_mask(x)\n",
        "    y = perception(x)\n",
        "    y = self.w2(torch.relu(self.w1(y)))\n",
        "    b, c, h, w = y.shape\n",
        "    update_mask = (torch.rand(b, 1, h, w) + update_rate).floor()\n",
        "\n",
        "    # Perform update\n",
        "    x = x + y * update_mask\n",
        "    if SCALAR_CHN == CHN:\n",
        "      x = x * alive\n",
        "    else:\n",
        "      state = x[:, :SCALAR_CHN] * alive\n",
        "      angle = x[:, SCALAR_CHN:] % (2. * torch.pi)\n",
        "      x = torch.cat([state, angle], 1)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF4nrfDn5lf4"
      },
      "source": [
        "# Target Legend\n",
        "\n",
        "Select the target of interest from the following\n",
        "\n",
        "* LIZARD:&emsp;🦎\n",
        "* HEART:&emsp;❤️\n",
        "* SMILEY:&emsp;😁\n",
        "\n",
        "Select the number of seeds and seed radius below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LPUMYyptdiDx"
      },
      "outputs": [],
      "source": [
        "#@title Seed and Target Setup {vertical-output:true}\n",
        "\n",
        "SEED_N = 2  #@param{type:\"integer\"}\n",
        "SEED_R = 4  #@param{type:\"integer\"}\n",
        "TARGET = 'LIZARD'  #@param['LIZARD', 'HEART', 'SMILEY']\n",
        "PADDING = 12\n",
        "\n",
        "emoji = {\n",
        "    'LIZARD':  '🦎',\n",
        "    'HEART':  '❤️',\n",
        "    'SMILEY': '😁'\n",
        "}[TARGET][0]\n",
        "code = hex(ord(emoji))[2:].lower()\n",
        "url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "target = imread(url, 48)\n",
        "\n",
        "# Show lineup\n",
        "n_seed = seed(1, 48, SEED_N, SEED_R)[0, :4].permute([1, 2, 0]).cpu()\n",
        "imgs = np.stack([n_seed, target], 0)\n",
        "imshow(tile2d(imgs, 2))\n",
        "\n",
        "# Format target\n",
        "target[:, :, :3] *= target[:, :, 3:]\n",
        "target = F.pad(torch.tensor(target).permute(2, 0, 1), [*(PADDING,)*4, 0, 0])\n",
        "W = target.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR5RlK-97Kg2"
      },
      "source": [
        "# Loss Legend\n",
        "\n",
        "Select the loss function of interest from the following\n",
        "\n",
        "* FIXED:&emsp;L2-norm loss\n",
        "* INVARIANT:&emsp;Rotation-invariant loss\n",
        "\n",
        "Select the lower and upper learning rate limits below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QaqCjNgCmmjS"
      },
      "outputs": [],
      "source": [
        "#@title Training Utilities and Setup\n",
        "\n",
        "LOSS_FN = 'FIXED'  #@param['FIXED', 'INVARIANT']\n",
        "LOWER_LR = 1e-5  #@param{type:\"number\"}\n",
        "UPPER_LR = 1e-3  #@param{type:\"number\"}\n",
        "MODEL_NAME = f'{MODEL_TYPE}_{TARGET}_{LOSS_FN}_{SEED_N}pt_{SEED_R}r'.lower()\n",
        "MODEL_DIR = os.path.join(MODEL_PATH, MODEL_NAME)\n",
        "\n",
        "if USE_DRIVE and not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)\n",
        "\n",
        "def fixed_loss_fn(x, scale=1e3, ax=[]):\n",
        "  return scale * torch.mean(torch.square(x[:, :4] - target[:4]), ax)\n",
        "\n",
        "def unsharp(img):\n",
        "  blured = gaussian_blur(img, (5, 5), (1, 1))\n",
        "  return img + (img - blured) * 2.\n",
        "\n",
        "s = np.sqrt(3) / 2.\n",
        "hex2xy = np.float32([[1., 0.], [.5, s]])\n",
        "xy2hex = torch.tensor(np.linalg.inv(hex2xy))\n",
        "r = torch.linspace(.5/W, 1, W//2)[:, None]\n",
        "a = torch.range(0, W*np.pi) / (W / 2)\n",
        "polar_xy = torch.stack([r*a.cos(), r*a.sin()], -1)[None, :]\n",
        "polar_target = F.grid_sample(unsharp(target[None, :]), polar_xy)\n",
        "\n",
        "x = torch.linspace(-1, 1, W)\n",
        "y, x = torch.meshgrid(x, x)\n",
        "xy_grid = torch.stack([x, y], -1)\n",
        "fft_target = torch.fft.rfft(polar_target).conj()\n",
        "polar_target_sqnorm = polar_target.square().sum(-1, keepdim=True)\n",
        "\n",
        "def invariant_losses_fn(img):\n",
        "  img = unsharp(img)\n",
        "  polar_img = F.grid_sample(img, polar_xy.repeat(len(img), 1, 1, 1), mode='bicubic')\n",
        "  x = torch.fft.rfft(polar_img)\n",
        "  xy = torch.fft.irfft(x*fft_target)\n",
        "  xx = polar_img.square().sum(-1, keepdim=True)\n",
        "  yy = polar_target_sqnorm\n",
        "  sqdiff = xx + yy - 2. * xy\n",
        "  return sqdiff.mean([1, 2])\n",
        "\n",
        "def invariant_loss_fn(img):\n",
        "  return invariant_losses_fn(img).min(-1)[0].mean()\n",
        "\n",
        "loss_fn = {\n",
        "    'FIXED': fixed_loss_fn,\n",
        "    'INVARIANT': invariant_loss_fn,\n",
        "}[LOSS_FN]\n",
        "\n",
        "def circle_masks(n, sz):\n",
        "  x = torch.linspace(-1.0, 1.0, sz)[None, None, :]\n",
        "  y = torch.linspace(-1.0, 1.0, sz)[None, :, None]\n",
        "  center = -torch.rand([2, n, 1, 1]) + 0.5\n",
        "  r = -0.3*torch.rand([n, 1, 1]) + 0.4\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = (x*x+y*y < 1.0).float()\n",
        "  return mask\n",
        "\n",
        "model = CA()\n",
        "loss_log = []\n",
        "progress = 0\n",
        "with torch.no_grad():\n",
        "  pool = seed(256, W, SEED_N, SEED_R)\n",
        "opt = torch.optim.Adam(model.parameters(), UPPER_LR)\n",
        "lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, LOWER_LR, UPPER_LR, step_size_up=2000, mode='triangular2', cycle_momentum=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OFCqvxs1dr10"
      },
      "outputs": [],
      "source": [
        "#@title Training Loop {vertical-output:true}\n",
        "\n",
        "EPOCHS = 15000  #@param{type:\"number\"}\n",
        "DAMAGE_RATE = 3\n",
        "IMAGE_RATE = 20\n",
        "INFO_RATE = 20\n",
        "SAVE_RATE = 500\n",
        "\n",
        "for _ in range(EPOCHS+1):\n",
        "  with torch.no_grad():\n",
        "    i = len(loss_log)\n",
        "    batch_idx = np.random.choice(len(pool), 8, replace=False)\n",
        "    x = pool[batch_idx]\n",
        "    # loss_rank = torch.argsort(loss_fn(x, ax=[-2, -3, -1]), descending=True)\n",
        "    # x = x[loss_rank]\n",
        "    \n",
        "    seed_rate = 1  if i < 4000 else 5\n",
        "    if i % seed_rate == 0:\n",
        "      x[:1] = seed(1, W, SEED_N, SEED_R)\n",
        "\n",
        "    if i % DAMAGE_RATE == 0:\n",
        "      damage_mask = 1. - circle_masks(1, W)[:, None]\n",
        "      x[-1:] *= damage_mask\n",
        "\n",
        "  step_n = np.random.randint(64, 96)\n",
        "  overflow_loss = 0.\n",
        "  diff_loss = 0.\n",
        "  target_loss = 0.\n",
        "  last_x = torch.zeros(x.shape)\n",
        "  for _ in range(step_n):\n",
        "    px = x\n",
        "    x = model(x)\n",
        "    diff_loss += (x - px).abs().mean()\n",
        "    overflow_loss += (x - x.clamp(-2., 2.))[:, :SCALAR_CHN].square().sum()\n",
        "\n",
        "  target_loss += loss_fn(x[:, :target.shape[0]])\n",
        "  diff_loss *= 10.\n",
        "  loss = target_loss + overflow_loss + diff_loss\n",
        "  # if loss.isnan():\n",
        "  #   # TODO: reload model from last checkpoint\n",
        "  #   print('\\nWARNING: NaN')\n",
        "  #   pool[batch_idx] = seed(8, W, SEED_N, SEED_R)\n",
        "  #   continue\n",
        "\n",
        "  with torch.no_grad():\n",
        "    loss.backward()\n",
        "    for p in model.parameters():\n",
        "      p.grad /= (p.grad.norm() + 1e-8)\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    lr_sched.step()\n",
        "    pool[batch_idx] = x\n",
        "    loss_log.append(loss.item())\n",
        "\n",
        "    if i % IMAGE_RATE == 0:\n",
        "      clear_output(True)\n",
        "      pl.plot(loss_log, '.', alpha=.1)\n",
        "      pl.yscale('log')\n",
        "      pl.ylim(np.min(loss_log), loss_log[0])\n",
        "      pl.show()\n",
        "      imgs = to_rgb(x)\n",
        "      imgs = imgs.permute([0, 2, 3, 1]).cpu()\n",
        "      imshow(tile2d(imgs, 4), scale=2)\n",
        "\n",
        "    if i % INFO_RATE == 0:\n",
        "      print('\\rstep_n:', i, '\\tloss:', loss.item(), '\\tlr:', lr_sched.get_lr()[0], end='')\n",
        "\n",
        "    if i % SAVE_RATE == 0:\n",
        "      progress = i\n",
        "      torch.save(model, os.path.join(MODEL_DIR, f'{MODEL_NAME}_{i}.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8Hf6DHbym4oy"
      },
      "outputs": [],
      "source": [
        "#@title Model Demo {vertical-output:true}\n",
        "\n",
        "FRAMES = 500  #@param{type:\"integer\"}\n",
        "\n",
        "model_name = f'{MODEL_TYPE}_{TARGET}_{LOSS_FN}_{SEED_N}pt_{SEED_R}r_{progress}'.lower()\n",
        "model_path = os.path.join(MODEL_DIR, f'{model_name}.pt')\n",
        "demo_path = os.path.join(MODEL_DIR, f'{model_name}.mp4')\n",
        "\n",
        "try:\n",
        "  model = torch.load(model_path)\n",
        "  vidgen(demo_path, model, n_frames=FRAMES, p=SEED_N, r=SEED_R)\n",
        "except FileNotFoundError:\n",
        "  print(f'Model \"{model_name}\" not found.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
