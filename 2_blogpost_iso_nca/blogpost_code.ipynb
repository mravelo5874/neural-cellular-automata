{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "974P6JcnyfPf"
      },
      "source": [
        "# Isotropic and Steerable NCA (structured seed experiments)\n",
        "\n",
        "### Author: Craig Fouts (cwf2117@columbia.edu)\n",
        "\n",
        "*Copyright 2023 Craig Fouts*\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "NCTKsrsiOUiG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce GTX 1660 Ti (UUID: GPU-d77bcb98-b41a-4494-1c93-f4f7d0b55d9c)\n",
            "cuda available?  True\n",
            "device:  cuda\n"
          ]
        }
      ],
      "source": [
        "#@title Notebook Utilities and Setup\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import matplotlib.pylab as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms.functional as T\n",
        "import warnings\n",
        "from colorsys import hsv_to_rgb\n",
        "# from google.colab import drive, output\n",
        "from IPython.display import clear_output, Image\n",
        "from torch.nn import BatchNorm1d, Dropout, InstanceNorm1d, LayerNorm, Module, ReLU, Sequential\n",
        "from torchvision.transforms.functional_tensor import gaussian_blur\n",
        "from tqdm.notebook import tnrange\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "\n",
        "# output.enable_custom_widget_manager()\n",
        "\n",
        "# * find GPU available\n",
        "clear_output()\n",
        "!nvidia-smi -L\n",
        "\n",
        "# * sets the device\n",
        "# *     defaults to 'cuda'\n",
        "_DEVICE_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print ('cuda available? ', torch.cuda.is_available())\n",
        "print ('device: ', _DEVICE_)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.cuda.empty_cache()\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# USE_DRIVE = False  #@param{type:\"boolean\"}\n",
        "DIRECTORY = 'My Drive/Models'  #@param{type:\"string\"}\n",
        "MODEL_PATH = '_checkpoints'\n",
        "\n",
        "# if USE_DRIVE:\n",
        "#   drive.mount('/content/drive')\n",
        "#   MODEL_PATH = os.path.join('/content/drive', DIRECTORY)\n",
        "\n",
        "def imread(url, max_size=None, mode=None):\n",
        "  if url.startswith(('http:', 'https:')):\n",
        "    headers = {'User-Agent': 'Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0'}\n",
        "    r = requests.get(url, headers=headers)\n",
        "    f = io.BytesIO(r.content)\n",
        "  else:\n",
        "    f = url\n",
        "  img = PIL.Image.open(f)\n",
        "  if max_size is not None:\n",
        "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  if mode is not None:\n",
        "    img = img.convert(mode)\n",
        "  img = np.float32(img) / 255.\n",
        "  return img\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in (np.float32, np.float64):\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None, quality=95):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=quality)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if a.ndim == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "def imshow(a, fmt='jpeg', scale=4):\n",
        "  display(Image(data=imencode(zoom(a, scale), fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(a.shape[0])))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w - a.shape[0]) % w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = a.shape[0] // w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def to_rgb(x):\n",
        "  rgb, a = x[:, :3], x[:, 3:4]\n",
        "  return 1. - a + rgb\n",
        "\n",
        "def grab_plot(close=True):\n",
        "  fig = pl.gcf()\n",
        "  fig.canvas.draw()\n",
        "  img = np.array(fig.canvas.renderer._renderer)\n",
        "  a = np.float32(img[..., 3:]/255.)\n",
        "  img = np.uint8(255*(1.-a)+img[..., :3]*a)\n",
        "  if close:\n",
        "    pl.close()\n",
        "  return img\n",
        "\n",
        "def vis_angle(x, w):\n",
        "  m = get_alive_mask(x).cpu()\n",
        "  rgb = to_rgb(x)[0].clip(0, 1).permute(1, 2, 0).cpu()\n",
        "  ang, a, m = x[0, -1].cpu(), x[0, 3].cpu(), m[0,0]\n",
        "  c, s = ang.cos() * a, ang.sin() * a\n",
        "  px, py = np.mgrid[-1:1:w*1j, -1:1:w*1j]\n",
        "  pl.figure(figsize=(10, 10))\n",
        "  pl.axis('equal')\n",
        "  pl.xlim(-0.8, 0.8); pl.ylim(-0.8,0.8)\n",
        "  pl.quiver(px[m], py[m], c[m], s[m], color=rgb[m], pivot='mid', scale_units='xy', units='xy', scale=W/3)\n",
        "  pl.tight_layout()\n",
        "  pl.axis('off')\n",
        "  return grab_plot()\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename='_autoplay.mp4', fps=30., **kwargs):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kwargs)\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "  \n",
        "  def __exit__(self, *args):\n",
        "    self.close()\n",
        "    if self.params['filename'] == '_autoplay.mp4':\n",
        "      self.show()\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in (np.float32, np.float64):\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if img.ndim == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer is not None:\n",
        "      self.writer.close()\n",
        "\n",
        "  def show(self, **kwargs):\n",
        "    self.close()\n",
        "    fn = self.params['filename']\n",
        "    display(mvp.ipython_display(fn, **kwargs))\n",
        "\n",
        "def vidgen(filename, model, n_frames=500, max_speed=128, n=16, sz=72, p=2, r=4, angle=None):\n",
        "  with VideoWriter(filename=filename) as vid, torch.no_grad():\n",
        "    x = seed(n, sz, p, r, angle=angle)\n",
        "    for i in tnrange(n_frames, leave=False):\n",
        "      img = to_rgb(x).permute(0, 2, 3, 1).cpu()\n",
        "      vid.add(zoom(tile2d(img), 2))\n",
        "      step_n = min(2**(i//30), max_speed)\n",
        "      for _ in range(step_n):\n",
        "        x = model(x)\n",
        "    vid.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4azYa9u3aMT"
      },
      "source": [
        "# Model Legend\n",
        "\n",
        "Select the model of interest from the following\n",
        "\n",
        "* LAPLACIAN:&emsp;Isotropic NCA model\n",
        "* LAP6:&emsp;Isotropic NCA, (trained and/or evaluated) on a hexagonal grid\n",
        "* GRADNORM:&emsp;Isotropic NCA variant discussed in the blogpost\n",
        "* STEERABLE:&emsp;Angle-based Steerable NCA\n",
        "* GRADIENT:&emsp;Gradient-based Steerable NCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "08RFfJ5xl-cL"
      },
      "outputs": [],
      "source": [
        "#@title Model Utilities and Setup {vertical-output:true}\n",
        "\n",
        "MODEL_TYPE = 'GRADIENT'  #@param['LAPLACIAN', 'LAP6', 'GRADNORM', 'STEERABLE', 'GRADIENT']\n",
        "UPDATE_RATE = .5\n",
        "\n",
        "CHN = 16\n",
        "ANGLE_CHN = 1 if MODEL_TYPE == 'STEERABLE' else 0\n",
        "SCALAR_CHN = CHN - ANGLE_CHN\n",
        "\n",
        "IDENT = torch.tensor([[0., 0., 0.], [0., 1., 0.], [0., 0., 0.]])\n",
        "SOBEL = torch.tensor([[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]])\n",
        "LAP = torch.tensor([[1., 2., 1.], [2., -12., 2.], [1., 2., 1.]])\n",
        "LAP6 = torch.tensor([[0., 2., 2.], [2., -12., 2.], [2., 2., 0.]])\n",
        "GAUSS = torch.tensor([[1., 2., 1.], [2., 4., 2.], [1., 2., 1.]]) / 16.\n",
        "NHOOD_KERNEL = ((LAP6 if MODEL_TYPE == 'LAP6' else LAP) != 0.).to(torch.float32)\n",
        "\n",
        "def perchannel_conv(x, filters):\n",
        "  b, ch, h, w = x.shape\n",
        "  y = x.reshape(b * ch, 1, h, w)\n",
        "  y = F.pad(y, (1, 1, 1, 1), 'circular')\n",
        "  print ('filters.device',filters.device)\n",
        "  print ('y.device',y.device)\n",
        "  y = F.conv2d(y, filters[:, None])\n",
        "  return y.reshape(b, -1, h, w)\n",
        "\n",
        "# Isotropic models\n",
        "def laplacian_perception(x):\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap], 1)\n",
        "\n",
        "def lap6_perception(x):\n",
        "  state_lap = perchannel_conv(x, LAP6[None, :])\n",
        "  return torch.cat([x, state_lap], 1)\n",
        "\n",
        "def gradnorm_perception(x):\n",
        "  grad = perchannel_conv(x, torch.stack([SOBEL, SOBEL.T]))\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap, (gx*gx+gy*gy+1e-8).sqrt()], 1)\n",
        "\n",
        "# Steerable models\n",
        "def steerable_perception(x):\n",
        "  state, angle = x[:, :-1], x[:, -1:]\n",
        "  c, s = angle.cos(), angle.sin()\n",
        "  filters = torch.stack([SOBEL, SOBEL.T])\n",
        "  grad = perchannel_conv(state, filters)\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "  state_lap = perchannel_conv(state, LAP[None, :])\n",
        "  return torch.cat([state, rot_grad, state_lap], 1)\n",
        "\n",
        "def gradient_perception(x):\n",
        "  filters = torch.stack([SOBEL, SOBEL.T])\n",
        "  grad = perchannel_conv(x, filters)\n",
        "  grad, dir = grad[:, :-2], grad[:, -2:]\n",
        "  dir = dir / dir.norm(dim=1, keepdim=True).clip(1.)\n",
        "  c, s = dir[:, :1], dir[:, 1:2]\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap, rot_grad], 1)\n",
        "\n",
        "perception = {\n",
        "    'LAPLACIAN': laplacian_perception,\n",
        "    'LAP6': lap6_perception,\n",
        "    'GRADNORM': gradnorm_perception,\n",
        "    'STEERABLE': steerable_perception,\n",
        "    'GRADIENT': gradient_perception\n",
        "}[MODEL_TYPE]\n",
        "\n",
        "def get_alive_mask(x):\n",
        "  mature = (x[:, 3:4] > .1).to(torch.float32)\n",
        "  return perchannel_conv(mature, NHOOD_KERNEL[None, :]) > .5\n",
        "\n",
        "def fibonacci_lattice(n):\n",
        "  '''Generates an n-point fibonacci lattice of radius 1'''\n",
        "  epsilon = 0.33  # Assumes n < 24\n",
        "  golden_ratio = (1 + np.sqrt(5)) / 2.\n",
        "  pts = torch.arange(n)\n",
        "  theta = 2 * np.pi * pts / golden_ratio\n",
        "  phi = torch.arccos(1-2*(pts+epsilon)/(n-1+2*epsilon))\n",
        "  x, y, z = torch.cos(theta)*torch.sin(phi), torch.sin(theta)*torch.sin(phi), torch.cos(phi)\n",
        "  return torch.concat([x[None, :], y[None, :], z[None, :]], 0)\n",
        "\n",
        "def rgb_linspace(n):\n",
        "  '''Generates n visually distinct rgb combinations'''\n",
        "  return torch.tensor([hsv_to_rgb(i / n, 1.0, 1.0) for i in range(n)], dtype=torch.float32)\n",
        "\n",
        "def rotate_n(x, n, min=0., max=360.):\n",
        "  a = np.linspace(0., 360., n)\n",
        "  for i, a in zip(range(n), a):\n",
        "    x[i] = T.rotate(x[i], a)\n",
        "  return x\n",
        "\n",
        "def seed(n, sz=128, p=2, r=4, xy=None, angle=0., flip=False, rgb_dist=rgb_linspace):\n",
        "  '''Generates a uniform p-point structured seed of radius r'''\n",
        "  x = torch.zeros(n, CHN, sz, sz)\n",
        "  if SCALAR_CHN != CHN:\n",
        "    x[:, -1] = torch.rand(n, sz, sz) * np.pi * 2.\n",
        "  # Initialize p points equidistant around a circle of radius r\n",
        "  t = np.linspace(0, 2 * np.pi, p, endpoint=False)\n",
        "  if xy is None:\n",
        "    xy = (np.c_[r*np.cos(t), r*np.sin(t)]+(sz//2)).astype(np.int32).T\n",
        "  # Assign distinct rgb values to each point\n",
        "  x[:, :3, xy[0], xy[1]] = rgb_dist(xy.shape[1]).T\n",
        "  x[:, 3:SCALAR_CHN, xy[0], xy[1]] = 1.0\n",
        "  x = rotate_n(x, n) if angle is None else T.rotate(x, angle)\n",
        "  if flip:\n",
        "    x = torch.flip(x, [3])\n",
        "  return x\n",
        "\n",
        "class CA(torch.nn.Module):\n",
        "  def __init__(self, chn=CHN, hidden_n=128):\n",
        "    super().__init__()\n",
        "    self.chn = chn\n",
        "\n",
        "    # Determine the number of perceived channels\n",
        "    perc_n = perception(torch.zeros([1, chn, 8, 8])).shape[1]\n",
        "\n",
        "    # Approximately equalize the parameter count between model variants\n",
        "    hidden_n = 8 * 1024 // (perc_n + chn)\n",
        "    hidden_n = (hidden_n + 31) // 32 * 32\n",
        "\n",
        "    # Model layers\n",
        "    self.w1 = torch.nn.Conv2d(perc_n, hidden_n, 1)\n",
        "    self.w2 = torch.nn.Conv2d(hidden_n, chn, 1, bias=False)\n",
        "    self.w2.weight.data.zero_()\n",
        "\n",
        "  def forward(self, x, update_rate=UPDATE_RATE):\n",
        "    # Get update and masks\n",
        "    alive = get_alive_mask(x)\n",
        "    y = perception(x)\n",
        "    y = self.w2(torch.relu(self.w1(y)))\n",
        "    b, c, h, w = y.shape\n",
        "    update_mask = (torch.rand(b, 1, h, w) + update_rate).floor()\n",
        "\n",
        "    # Perform update\n",
        "    x = x + y * update_mask\n",
        "    if SCALAR_CHN == CHN:\n",
        "      x = x * alive\n",
        "    else:\n",
        "      state = x[:, :SCALAR_CHN] * alive\n",
        "      angle = x[:, SCALAR_CHN:] % (2. * torch.pi)\n",
        "      x = torch.cat([state, angle], 1)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF4nrfDn5lf4"
      },
      "source": [
        "# Target Legend\n",
        "\n",
        "Select the target of interest from the following\n",
        "\n",
        "* LIZARD:&emsp;🦎\n",
        "* HEART:&emsp;❤️\n",
        "* SMILEY:&emsp;😁\n",
        "\n",
        "Select the number of seeds and seed radius below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "LPUMYyptdiDx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W:  64\n"
          ]
        }
      ],
      "source": [
        "#@title Seed and Target Setup {vertical-output:true}\n",
        "\n",
        "SEED_N = 2  #@param{type:\"integer\"}\n",
        "SEED_R = 4  #@param{type:\"integer\"}\n",
        "TARGET = 'COWBOY'  #@param['LIZARD', 'HEART', 'SMILEY']\n",
        "PADDING = 12\n",
        "\n",
        "# emoji = {\n",
        "#     'LIZARD':  '🦎',\n",
        "#     'HEART':  '❤️',\n",
        "#     'SMILEY': '😁'\n",
        "# }[TARGET][0]\n",
        "# code = hex(ord(emoji))[2:].lower()\n",
        "url = '../_images/cowboy.png' #https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "target = imread(url, 40)\n",
        "\n",
        "# Show lineup\n",
        "n_seed = seed(1, 40, SEED_N, SEED_R)[0, :4].permute([1, 2, 0]).cpu()\n",
        "imgs = np.stack([n_seed, target], 0)\n",
        "imshow(tile2d(imgs, 2))\n",
        "\n",
        "# Format target\n",
        "target[:, :, :3] *= target[:, :, 3:]\n",
        "target = F.pad(torch.tensor(target).permute(2, 0, 1), [*(PADDING,)*4, 0, 0])\n",
        "W = target.shape[1]\n",
        "\n",
        "print ('W: ', W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR5RlK-97Kg2"
      },
      "source": [
        "# Loss Legend\n",
        "\n",
        "Select the loss function of interest from the following\n",
        "\n",
        "* FIXED:&emsp;L2-norm loss\n",
        "* INVARIANT:&emsp;Rotation-invariant loss\n",
        "\n",
        "Select the lower and upper learning rate limits below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "QaqCjNgCmmjS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "filters.device cuda:0\n",
            "y.device cuda:0\n",
            "filters.device cuda:0\n",
            "y.device cuda:0\n",
            "model name:  gradient_cowboy_fixed_2pt_4r\n"
          ]
        }
      ],
      "source": [
        "#@title Training Utilities and Setup\n",
        "\n",
        "LOSS_FN = 'FIXED'  #@param['FIXED', 'INVARIANT']\n",
        "LOWER_LR = 1e-5  #@param{type:\"number\"}\n",
        "UPPER_LR = 1e-3  #@param{type:\"number\"}\n",
        "MODEL_NAME = f'{MODEL_TYPE}_{TARGET}_{LOSS_FN}_{SEED_N}pt_{SEED_R}r'.lower()\n",
        "MODEL_DIR = os.path.join(MODEL_PATH, MODEL_NAME)\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "# if USE_DRIVE and not os.path.exists(MODEL_DIR):\n",
        "#   os.mkdir(MODEL_DIR)\n",
        "\n",
        "def fixed_loss_fn(x, scale=1e3, ax=[]):\n",
        "  return scale * torch.mean(torch.square(x[:, :4] - target[:4]), ax)\n",
        "\n",
        "def unsharp(img):\n",
        "  blured = gaussian_blur(img, (5, 5), (1, 1))\n",
        "  return img + (img - blured) * 2.\n",
        "\n",
        "s = np.sqrt(3) / 2.\n",
        "hex2xy = np.float32([[1., 0.], [.5, s]])\n",
        "xy2hex = torch.tensor(np.linalg.inv(hex2xy))\n",
        "r = torch.linspace(.5/W, 1, W//2)[:, None]\n",
        "a = torch.range(0, W*np.pi) / (W / 2)\n",
        "polar_xy = torch.stack([r*a.cos(), r*a.sin()], -1)[None, :]\n",
        "polar_target = F.grid_sample(unsharp(target[None, :]), polar_xy)\n",
        "\n",
        "x = torch.linspace(-1, 1, W)\n",
        "y, x = torch.meshgrid(x, x)\n",
        "xy_grid = torch.stack([x, y], -1)\n",
        "fft_target = torch.fft.rfft(polar_target).conj()\n",
        "polar_target_sqnorm = polar_target.square().sum(-1, keepdim=True)\n",
        "\n",
        "def invariant_losses_fn(img):\n",
        "  img = unsharp(img)\n",
        "  polar_img = F.grid_sample(img, polar_xy.repeat(len(img), 1, 1, 1), mode='bicubic')\n",
        "  x = torch.fft.rfft(polar_img)\n",
        "  xy = torch.fft.irfft(x*fft_target)\n",
        "  xx = polar_img.square().sum(-1, keepdim=True)\n",
        "  yy = polar_target_sqnorm\n",
        "  sqdiff = xx + yy - 2. * xy\n",
        "  return sqdiff.mean([1, 2])\n",
        "\n",
        "def invariant_loss_fn(img):\n",
        "  return invariant_losses_fn(img).min(-1)[0].mean()\n",
        "\n",
        "loss_fn = {\n",
        "    'FIXED': fixed_loss_fn,\n",
        "    'INVARIANT': invariant_loss_fn,\n",
        "}[LOSS_FN]\n",
        "\n",
        "def circle_masks(n, sz):\n",
        "  x = torch.linspace(-1.0, 1.0, sz)[None, None, :]\n",
        "  y = torch.linspace(-1.0, 1.0, sz)[None, :, None]\n",
        "  center = -torch.rand([2, n, 1, 1]) + 0.5\n",
        "  r = -0.3*torch.rand([n, 1, 1]) + 0.4\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = (x*x+y*y < 1.0).float()\n",
        "  return mask\n",
        "\n",
        "model = CA()\n",
        "loss_log = []\n",
        "progress = 0\n",
        "with torch.no_grad():\n",
        "  pool = seed(256, W, SEED_N, SEED_R)\n",
        "opt = torch.optim.Adam(model.parameters(), UPPER_LR)\n",
        "lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, LOWER_LR, UPPER_LR, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n",
        "\n",
        "print ('model name: ', MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "OFCqvxs1dr10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/15001 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipping training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Training Loop {vertical-output:true}\n",
        "\n",
        "TRAIN_MODEL = False\n",
        "EPOCHS = 15000  #@param{type:\"number\"}\n",
        "DAMAGE_RATE = 3\n",
        "IMAGE_RATE = 20\n",
        "INFO_RATE = 20\n",
        "SAVE_RATE = 500\n",
        "\n",
        "for _ in tqdm(range(EPOCHS+1)):\n",
        "    if not TRAIN_MODEL:\n",
        "        print ('skipping training')\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        i = len(loss_log)\n",
        "        batch_idx = np.random.choice(len(pool), 8, replace=False)\n",
        "        x = pool[batch_idx]\n",
        "        # loss_rank = torch.argsort(loss_fn(x, ax=[-2, -3, -1]), descending=True)\n",
        "        # x = x[loss_rank]\n",
        "        \n",
        "        seed_rate = 1  if i < 4000 else 5\n",
        "        if i % seed_rate == 0:\n",
        "            x[:1] = seed(1, W, SEED_N, SEED_R)\n",
        "\n",
        "        if i % DAMAGE_RATE == 0:\n",
        "            damage_mask = 1. - circle_masks(1, W)[:, None]\n",
        "            x[-1:] *= damage_mask\n",
        "\n",
        "    step_n = np.random.randint(64, 96)\n",
        "    overflow_loss = 0.\n",
        "    diff_loss = 0.\n",
        "    target_loss = 0.\n",
        "    last_x = torch.zeros(x.shape)\n",
        "    for _ in range(step_n):\n",
        "        px = x\n",
        "        x = model(x)\n",
        "        diff_loss += (x - px).abs().mean()\n",
        "        overflow_loss += (x - x.clamp(-2., 2.))[:, :SCALAR_CHN].square().sum()\n",
        "\n",
        "    target_loss += loss_fn(x[:, :target.shape[0]])\n",
        "    diff_loss *= 10.\n",
        "    loss = target_loss + overflow_loss + diff_loss\n",
        "    # if loss.isnan():\n",
        "    #   # TODO: reload model from last checkpoint\n",
        "    #   print('\\nWARNING: NaN')\n",
        "    #   pool[batch_idx] = seed(8, W, SEED_N, SEED_R)\n",
        "    #   continue\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss.backward()\n",
        "        for p in model.parameters():\n",
        "            p.grad /= (p.grad.norm() + 1e-8)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        lr_sched.step()\n",
        "        pool[batch_idx] = x\n",
        "        loss_log.append(loss.item())\n",
        "\n",
        "    if i % IMAGE_RATE == 0:\n",
        "        clear_output(True)\n",
        "        pl.plot(loss_log, '.', alpha=.1)\n",
        "        pl.yscale('log')\n",
        "        pl.ylim(np.min(loss_log), loss_log[0])\n",
        "        pl.show()\n",
        "        imgs = to_rgb(x)\n",
        "        imgs = imgs.permute([0, 2, 3, 1]).cpu()\n",
        "        imshow(tile2d(imgs.detach(), 4), scale=2)\n",
        "\n",
        "    if i % INFO_RATE == 0:\n",
        "        print('\\rstep_n:', i, '\\tloss:', loss.item(), '\\tlr:', lr_sched.get_lr()[0], end='')\n",
        "\n",
        "    if i % SAVE_RATE == 0:\n",
        "        progress = i\n",
        "        torch.save(model, os.path.join(MODEL_DIR, f'{MODEL_NAME}_{i}.pt'))\n",
        "\n",
        "if TRAIN_MODEL: \n",
        "    # * save final model\n",
        "    torch.save(model, os.path.join('_models', f'{MODEL_NAME}.pt'))\n",
        "\n",
        "    # * create model video!\n",
        "    FRAMES = 500  #@param{type:\"integer\"}\n",
        "    progress = 15000\n",
        "\n",
        "    model_name = f'{MODEL_TYPE}_{TARGET}_{LOSS_FN}_{SEED_N}pt_{SEED_R}r_{progress}'.lower()\n",
        "    model_path = os.path.join(MODEL_DIR, f'{model_name}.pt')\n",
        "    demo_path = os.path.join('_videos', f'{model_name}.mp4')\n",
        "\n",
        "    try:\n",
        "        model = torch.load(model_path)\n",
        "        vidgen(demo_path, model, n_frames=FRAMES, p=SEED_N, r=SEED_R)\n",
        "    except FileNotFoundError:\n",
        "        print(f'Model \"{model_name}\" not found.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions for running pygame instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "\n",
        "# * loads an image and converts to a tensor\n",
        "# *     default tensor shape: [BATCH_SIZE (1), CHANNELS (4), WIDTH (_size), HEIGHT (_size)]\n",
        "def load_image_as_tensor(_path, _size, _resample=PIL.Image.Resampling.BICUBIC):\n",
        "    img = PIL.Image.open(_path)\n",
        "    img = img.resize((_size, _size), _resample)\n",
        "    img = np.float32(img) / 255.0\n",
        "    img[..., :3] *= img[..., 3:]\n",
        "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]\n",
        "\n",
        "# * takes the first 4 channels of a tensor of default shape and converts to a RGB image\n",
        "def to_rgb(_x, _alpha='BLACK'):\n",
        "    rgb, a = _x[:, :3], _x[:, 3:4]\n",
        "    if _alpha == 'BLACK':\n",
        "        return torch.clamp(rgb, 0.0, 1.0)\n",
        "    elif _alpha == 'WHITE':\n",
        "        return torch.clamp(1.-a + rgb, 0.0, 1.0)\n",
        "    \n",
        "# * creates a circle mask centered at a position of a given radius\n",
        "def circle_mask(_size, _radius, _pos):\n",
        "    Y, X = np.ogrid[:_size, :_size]\n",
        "    dist_from_center = np.sqrt((X - _pos[0])**2 + (Y-_pos[1])**2)\n",
        "    mask = dist_from_center >= _radius\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seeds:  ['_1_seed_64.png', '_2x2_seeds_64.png', '_2x3_seeds_64.png', '_2_seeds_64.png', '_3_seeds_64.png']\n",
            "models:  ['gradient_cowboy_fixed_2pt_4r', 'steerable_cowboy_fixed_2pt_4r_15000', 'steerable_lizard_fixed_2pt_4r_15000']\n",
            "filters.device cuda:0\n",
            "y.device cuda:0\n",
            "filters.device cuda:0\n",
            "y.device cuda:0\n",
            "params:  ['gradient', 'cowboy', 'fixed', '2pt', '4r']\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\2_blogpost_iso_nca\\blogpost_code.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m curr_model \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# load first model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m model, tensor, params, seed_img \u001b[39m=\u001b[39m load_model(model_list[curr_model])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# * misc params\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m angle \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
            "\u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\2_blogpost_iso_nca\\blogpost_code.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# * create seed and tensor\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m seed_img \u001b[39m=\u001b[39m load_image_as_tensor(\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m_seeds\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mseeds_list[curr_seed], _PLAY_SIZE_)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([seed_img, torch\u001b[39m.\u001b[39;49mzeros([\u001b[39m1\u001b[39;49m, \u001b[39m12\u001b[39;49m, _PLAY_SIZE_, _PLAY_SIZE_])\u001b[39m.\u001b[39;49mto(_PLAY_DEVICE_)], \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mto(_PLAY_DEVICE_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# * randomize angles for steerable models\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/2_blogpost_iso_nca/blogpost_code.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m params[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msteerable\u001b[39m\u001b[39m'\u001b[39m:\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "import datetime\n",
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "\n",
        "import torchvision.transforms.functional as trans\n",
        "\n",
        "_PLAY_ = True\n",
        "_MODELS_DIR_ = '_models'\n",
        "_PLAY_DEVICE_ = 'cpu'\n",
        "_RADIUS_ = 8\n",
        "_PLAY_SIZE_ = 64\n",
        "_WINDOW_SCALE_ = 10\n",
        "_WINDOW_BG_COLOR_ = (0, 0, 0)\n",
        "_WINDOW_TEXT_COLOR_ = (255, 255, 255)\n",
        "\n",
        "# * set current device\n",
        "_DEVICE_ = _PLAY_DEVICE_\n",
        "\n",
        "# * method to load model for play\n",
        "def load_model(_model_name):\n",
        "    model = CA()\n",
        "    model = torch.load(os.path.join(_MODELS_DIR_, _model_name+'.pt'), map_location=_PLAY_DEVICE_)\n",
        "    \n",
        "    # * find params from name\n",
        "    params = _model_name.split('_')\n",
        "    print ('params: ', params)\n",
        "    \n",
        "    # * create seed and tensor\n",
        "    seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+seeds_list[curr_seed], _PLAY_SIZE_)\n",
        "    tensor = torch.cat([seed_img, torch.zeros([1, 12, _PLAY_SIZE_, _PLAY_SIZE_]).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "    # * randomize angles for steerable models\n",
        "    if params[0] == 'steerable':\n",
        "        rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "        tensor[:, -1:] = rand\n",
        "    return model, tensor, params, seed_img\n",
        "\n",
        "# * get list of seeds\n",
        "seeds_list = os.listdir('..\\\\_seeds')\n",
        "seeds_list = [item for item in seeds_list if item.endswith('.png')]\n",
        "print ('seeds: ', seeds_list)\n",
        "curr_seed = 3\n",
        "\n",
        "# * get list of models\n",
        "model_list = os.listdir(_MODELS_DIR_)\n",
        "model_list = [item.replace('.pt', '') for item in model_list if item.endswith('.pt')]\n",
        "print ('models: ', model_list)\n",
        "curr_model = 0\n",
        "\n",
        "# load first model\n",
        "model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
        "\n",
        "# * misc params\n",
        "angle = 0.0\n",
        "fps = 0\n",
        "show_vecs = False\n",
        "bg_color = 'WHITE' if _WINDOW_BG_COLOR_ == (255, 255, 255) else 'BLACK'\n",
        "prev_time = datetime.datetime.now()\n",
        "\n",
        "# * load vector image\n",
        "vec_img = cv2.imread('..\\\\_images\\\\vector_v3.png') \n",
        "vec_img = cv2.resize(vec_img, (_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
        "vec_img = vec_img.astype(float)/255.0\n",
        "\n",
        "# * start pygame\n",
        "pygame.init()\n",
        "pygame.display.set_caption('nca play - '+model_list[curr_model])\n",
        "\n",
        "# * model dependent params\n",
        "size = _PLAY_SIZE_\n",
        "window_size = size * _WINDOW_SCALE_\n",
        "window = pygame.display.set_mode((window_size, window_size))\n",
        "\n",
        "# * text renders\n",
        "font_size = 20\n",
        "my_font = pygame.font.SysFont('consolas', font_size)\n",
        "model_surface = my_font.render('[UP/DOWN] model: ' + model_list[curr_model], False, _WINDOW_TEXT_COLOR_)\n",
        "seed_surface = my_font.render('[LEFT/RIGHT] seed: ' + seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
        "text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
        "fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
        "vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
        "\n",
        "# * start infinite game loop\n",
        "running = True\n",
        "mouse_down = False\n",
        "model_start = False\n",
        "while running:\n",
        "    if not _PLAY_:\n",
        "        print ('skipping game')\n",
        "        break\n",
        "    # empty cache\n",
        "    torch.cuda.empty_cache()\n",
        "    # handle events\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.QUIT:\n",
        "            running = False\n",
        "        if event.type == pygame.KEYDOWN:\n",
        "            # * close application\n",
        "            if event.key == pygame.K_ESCAPE:\n",
        "                running = False\n",
        "                break\n",
        "            # * toggle showing vectors\n",
        "            if event.key == pygame.K_v:\n",
        "                show_vecs = not show_vecs\n",
        "                vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
        "            # * start current model\n",
        "            if event.key == pygame.K_SPACE:\n",
        "                model_start = not model_start\n",
        "            # * reset current model\n",
        "            if event.key == pygame.K_r:\n",
        "                model_start = False\n",
        "                tensor = torch.cat([seed_img, torch.zeros([1, 12, _PLAY_SIZE_, _PLAY_SIZE_]).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "                # * randomize angles for steerable models\n",
        "                if params[0] == 'steerable':\n",
        "                    rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "                    tensor[:, -1:] = rand\n",
        "            # * use up/down arrow keys to cycle though models\n",
        "            if event.key == pygame.K_UP:\n",
        "                    curr_model += 1\n",
        "                    if curr_model >= len(model_list):\n",
        "                        curr_model = 0\n",
        "            if event.key == pygame.K_DOWN:\n",
        "                curr_model -= 1\n",
        "                if curr_model < 0:\n",
        "                    curr_model = len(model_list)-1\n",
        "            # * load new model\n",
        "            if event.key == pygame.K_UP or event.key == pygame.K_DOWN:\n",
        "                model_start = False\n",
        "                model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
        "                pygame.display.set_caption('nca play - '+model_list[curr_model])\n",
        "                model_surface = my_font.render('[UP/DOWN] model: '+model_list[curr_model], False, _WINDOW_TEXT_COLOR_)\n",
        "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
        "            # * use left/right arrow keys to cycle though seeds\n",
        "            if event.key == pygame.K_LEFT:\n",
        "                curr_seed += 1\n",
        "                if curr_seed >= len(seeds_list):\n",
        "                    curr_seed = 0\n",
        "            if event.key == pygame.K_RIGHT:\n",
        "                curr_seed -= 1\n",
        "                if curr_seed < 0:\n",
        "                    curr_seed = len(seeds_list)-1\n",
        "            # * load new seed image\n",
        "            if event.key == pygame.K_LEFT or event.key == pygame.K_RIGHT:\n",
        "                model_start = False\n",
        "                seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+seeds_list[curr_seed], _PLAY_SIZE_)\n",
        "                tensor = torch.cat([seed_img, torch.zeros([1, 12, _PLAY_SIZE_, _PLAY_SIZE_]).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "                # * randomize angles for steerable models\n",
        "                if params[0] == 'steerable':\n",
        "                    rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "                    tensor[:, -1:] = rand\n",
        "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
        "        if event.type == pygame.MOUSEWHEEL:\n",
        "            # * let player rotate seed before starting model\n",
        "            if not model_start:\n",
        "                angle = np.round((event.y * 0.05) + angle, decimals=2)\n",
        "                text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
        "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
        "                tensor = torch.cat([seed_img, torch.zeros([1, 12, _PLAY_SIZE_, _PLAY_SIZE_]).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_) \n",
        "        # * mouse click events - erase and draw\n",
        "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
        "            mouse_down = True\n",
        "            if pygame.mouse.get_pressed(3)[2] and model_start:\n",
        "                mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
        "                pos = mouse / window_size * size\n",
        "                dot = np.zeros_like(tensor.detach().cpu().numpy())\n",
        "                dot[:, 3:, int(pos[1]), int(pos[0])] = 1.0\n",
        "                tensor += torch.tensor(dot).to(_PLAY_DEVICE_)\n",
        "        if event.type == pygame.MOUSEBUTTONUP:\n",
        "            mouse_down = False\n",
        "        if (event.type == pygame.MOUSEMOTION or event.type == pygame.MOUSEBUTTONDOWN) and mouse_down and model_start:\n",
        "            mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
        "            pos = mouse / window_size * size\n",
        "            if pygame.mouse.get_pressed(3)[0]:\n",
        "                mask = circle_mask(size, _RADIUS_, pos)\n",
        "                tensor[0:] *= torch.tensor(mask).to(_PLAY_DEVICE_)\n",
        "            \n",
        "    # * update tensor\n",
        "    if model_start:\n",
        "        with torch.no_grad():\n",
        "            tensor = model(tensor)\n",
        "    \n",
        "    # * draw tensor to window\n",
        "    window.fill(_WINDOW_BG_COLOR_)\n",
        "    img = to_rgb(tensor, _alpha=bg_color).squeeze()\n",
        "    vis = (np.array(img.cpu())*255).astype(np.uint8)\n",
        "    if show_vecs:\n",
        "        vecs = tensor[:, -1:].squeeze(0)\n",
        "        vecs = np.array(vecs.cpu())%(2.0*torch.pi)\n",
        "    pixel = pygame.Surface((_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
        "    for j in range(size):\n",
        "        for i in range(size):\n",
        "            color = vis[:, i, j]\n",
        "            # * create vectors for each cell\n",
        "            if show_vecs:\n",
        "                vec_dir = vecs[:, i, j]\n",
        "                vec = imutils.rotate(vec_img, angle=np.rad2deg(vec_dir).item())\n",
        "                vec *= color\n",
        "                surf = pygame.surfarray.make_surface(vec)\n",
        "                pixel.blit(surf, (0, 0))\n",
        "            # * fill cell with color\n",
        "            else:\n",
        "                pixel.fill(color)\n",
        "            draw_me = pygame.Rect(j*_WINDOW_SCALE_, i*_WINDOW_SCALE_, _WINDOW_SCALE_, _WINDOW_SCALE_)\n",
        "            window.blit(pixel, draw_me)\n",
        "    \n",
        "    # * calculate fps\n",
        "    now = datetime.datetime.now()\n",
        "    if (now - prev_time).seconds >= 1.0:\n",
        "        prev_time = now\n",
        "        fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
        "        fps = 0\n",
        "    else:\n",
        "        fps += 1       \n",
        "    \n",
        "    # * render text\n",
        "    window.blit(model_surface, (0, 0))\n",
        "    window.blit(seed_surface, (0, font_size))\n",
        "    window.blit(text_surface, (0, window_size-font_size))\n",
        "    window.blit(vec_surface, (0, window_size-font_size*2))\n",
        "    window.blit(fps_surface, (0, window_size-font_size*3))\n",
        "    \n",
        "    # * flip it!\n",
        "    pygame.display.flip()\n",
        "\n",
        "# * quit it!\n",
        "pygame.quit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
