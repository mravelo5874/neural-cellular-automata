{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from models import NCA_grow_learnable, NCA_grow_laplace, NCA_grow_sobel\n",
    "from utils import Utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, channel=None):\n",
    "    img_rgb = Utils.to_rgb(img).squeeze().permute(1, 2, 0)\n",
    "    print ('img_rgb.shape: ', img_rgb.shape)\n",
    "    if channel is not None:\n",
    "        c = img_rgb[:,:, channel]\n",
    "        channels = img_rgb.shape[2]\n",
    "        for i in range(channels):\n",
    "            if i != channel:\n",
    "                img_rgb[:,:, i] = torch.zeros((img_rgb.shape[0], img_rgb.shape[1]))\n",
    "        \n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(batch_size, before, after, dpi=256):\n",
    "    fig = plt.figure(figsize=(batch_size, 2), dpi=dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=batch_size)\n",
    "    gspec = gridspec.GridSpec(2, batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img_i = before[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        img_i = after[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "seed = Utils.make_seed(16, 16)\n",
    "pad = 16\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(8, 1, 1, 1)\n",
    "\n",
    "#show_batch(8, pool, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x = torch.rand(2, 3, 3, 3)\n",
    "#print (x)\n",
    "\n",
    "z = torch.zeros(1, 3, 3, 1)\n",
    "x[-1:] *= z\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preception!\n",
      "x.shape:  torch.Size([1, 4, 3, 3])\n",
      "sobel_filters.shape:  torch.Size([2, 3, 3])\n",
      "sobel_filters.shape:  torch.Size([8, 3, 3])\n",
      "ident_filters.shape:  torch.Size([4, 3, 3])\n",
      "sobel_filters.shape:  torch.Size([8, 1, 3, 3])\n",
      "ident_filters.shape:  torch.Size([4, 1, 3, 3])\n",
      "sobel_res.shape:  torch.Size([1, 8, 3, 3])\n",
      "sobel_mag.shape:  torch.Size([1, 4, 3, 3])\n",
      "res.shape:  torch.Size([1, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "# identity vector\n",
    "identity_filter = torch.tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=torch.float32)\n",
    "\n",
    "# create sobel filters\n",
    "batch_size = 1\n",
    "n_channels = 4\n",
    "size = 3\n",
    "angle = 0.0\n",
    "scalar = 1.0\n",
    "dx = np.outer([1, 2, 1], [-1, 0, 1]) / scalar # Sobel filter\n",
    "dy = dx.T\n",
    "c, s = np.cos(angle), np.sin(angle)\n",
    "sobel_filter_x = torch.tensor(c*dx-s*dy, dtype=torch.float32)\n",
    "sobel_filter_y = torch.tensor(s*dx+c*dy, dtype=torch.float32)\n",
    "\n",
    "x = torch.randint(1, 5, (batch_size, n_channels, size, size), dtype=torch.float32)\n",
    "print ('preception!')\n",
    "print ('x.shape: ', x.shape)\n",
    "#print (x)\n",
    "\n",
    "# stack filters together\n",
    "sobel_filters = torch.stack([sobel_filter_x, sobel_filter_y]) # (2, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "#print (filters)\n",
    "\n",
    "sobel_filters = sobel_filters.repeat((n_channels, 1, 1)) # (2 * n_channels, 3, 3)\n",
    "ident_filters = identity_filter.repeat((n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "print ('ident_filters.shape: ', ident_filters.shape)\n",
    "#print (filters)\n",
    "\n",
    "sobel_filters = sobel_filters[:, None, ...] # (2 * n_channels, 1, 3, 3)\n",
    "ident_filters = ident_filters[:, None, ...] # (2 * n_channels, 1, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "print ('ident_filters.shape: ', ident_filters.shape)\n",
    "#print (sobel_filters)\n",
    "\n",
    "sobel_res = nn.functional.conv2d(x, sobel_filters, padding=1, groups=4)\n",
    "ident_res = nn.functional.conv2d(x, ident_filters, padding=1, groups=4)\n",
    "print ('sobel_res.shape: ', sobel_res.shape)\n",
    "#print (sobel_res)\n",
    "#print ('ident_res.shape: ', ident_res.shape)\n",
    "#print (ident_res)\n",
    "\n",
    "sobel_square = torch.square(sobel_res)\n",
    "sobel_mag = torch.zeros_like(x)\n",
    "count = 0\n",
    "for i in range(0, (n_channels*2), 2):\n",
    "    mag = torch.sqrt(sobel_square[:,i] + sobel_square[:,i+1])\n",
    "    sobel_mag[:,count] = mag\n",
    "    count += 1\n",
    "\n",
    "print ('sobel_mag.shape: ', sobel_mag.shape)\n",
    "#print (sobel_mag)\n",
    "\n",
    "res = torch.cat((ident_res, sobel_mag), dim=1)\n",
    "print ('res.shape: ', res.shape)\n",
    "#print (res)\n",
    "\n",
    "# return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  True\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "img = '..\\\\_images\\\\rainbow.png'\n",
    "name = 'cowboy_learnable'\n",
    "model_type = 'learnable'\n",
    "viz_train = True\n",
    "\n",
    "size = 40\n",
    "pad = 12\n",
    "n_channels = 16\n",
    "hid_channels = 128\n",
    "fire_rate = 0.5\n",
    "\n",
    "n_train_iter = 3000\n",
    "batch_size = 8\n",
    "pool_size = 32\n",
    "n_damage = 3\n",
    "iter_start_damage = 500\n",
    "\n",
    "checkpoint_freq = 1000\n",
    "eval_freq = 500\n",
    "eval_iter = 300\n",
    "\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "checkpoint_dir = 'checkpoints'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded_img.shape:  torch.Size([1, 4, 40, 40])\n",
      "torch.Size([1, 4, 40, 40])\n",
      "torch.Size([1, 4, 64, 64])\n",
      "target image: \n",
      "img_rgb.shape:  torch.Size([40, 40, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# misc\n",
    "full_size = size + (2 * pad)\n",
    "#device_n = torch.device(device)\n",
    "\n",
    "# create log\n",
    "log_path = pathlib.Path(log_dir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# target image\n",
    "loaded_img = Utils.load_image(img, size)\n",
    "print('loaded_img.shape: ', loaded_img.shape)\n",
    "print (loaded_img.shape)\n",
    "\n",
    "target_img_ = nn.functional.pad(loaded_img, (pad, pad, pad, pad), 'constant', 0)\n",
    "\n",
    "print (target_img_.shape)\n",
    "\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "print ('target_img.shape: ', target_img.shape)\n",
    "\n",
    "# show image\n",
    "print ('target image: ')\n",
    "show_image(loaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('sobel x')\n",
    "show_image(target_img_)\n",
    "print ('red channel')\n",
    "show_image(target_img_, 0)\n",
    "print ('green channel')\n",
    "show_image(target_img_, 1)\n",
    "print ('blue channel')\n",
    "show_image(target_img_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randint(1, 8, (3, 3), dtype=torch.float32)\n",
    "print(x0)\n",
    "x1 = torch.square(x0)\n",
    "print(x1)\n",
    "x2 = torch.sqrt(x1)\n",
    "print(x2)\n",
    "print (x0 == x2)\n",
    "\n",
    "y = torch.randint(1, 8, (3, 3), dtype=torch.float32)\n",
    "print (y == torch.sqrt(torch.square(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_channels = 4\n",
    "_angle = 0.0\n",
    "_scalar = 1.0\n",
    "\n",
    "dx = np.outer([1, 2, 1], [-1, 0, 1]) / _scalar # sobel filter\n",
    "dy = dx.T\n",
    "c, s = np.cos(_angle), np.sin(_angle)\n",
    "sobel_x = torch.tensor(c*dx-s*dy, dtype=torch.float32)\n",
    "sobel_y = torch.tensor(s*dx+c*dy, dtype=torch.float32)\n",
    "laplace = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32)\n",
    "laplace /= _scalar\n",
    "identty = torch.tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=torch.float32)\n",
    "\n",
    "print (sobel_x)\n",
    "print (laplace)\n",
    "\n",
    "# sobel_x = torch.tensor([[0,0,0],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "# sobel_y = torch.tensor([[0,0,0],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "\n",
    "sobel_x = sobel_x.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "sobel_y = sobel_y.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "laplace = laplace.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "identty = identty.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "\n",
    "sobel_x = sobel_x[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "sobel_y = sobel_y[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "laplace = laplace[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "identty = identty[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "\n",
    "# 2d conv\n",
    "G_x = nn.functional.conv2d(target_img_, sobel_x, padding=1, groups=_n_channels)\n",
    "G_y = nn.functional.conv2d(target_img_, sobel_y, padding=1, groups=_n_channels)\n",
    "G_l = nn.functional.conv2d(target_img_, laplace, padding=1, groups=_n_channels)\n",
    "G_i = nn.functional.conv2d(target_img_, identty, padding=1, groups=_n_channels)\n",
    "\n",
    "for i in range(4):\n",
    "    min_y = torch.min(G_y[:, i])\n",
    "    max_y = torch.max(G_y[:, i])\n",
    "    # Shift the values from [min, max] to [0, 1]\n",
    "    G_y[:, i] = G_y[:, i]+abs(min_y)\n",
    "    # Scale the values from [0, 2] to [0, 1]\n",
    "    div_y = (abs(min_y)+abs(max_y))\n",
    "    if div_y != 0:\n",
    "        G_y[:, i] = G_y[:, i]/div_y\n",
    "    \n",
    "    min_x = torch.min(G_x[:, i])\n",
    "    max_x = torch.max(G_x[:, i])\n",
    "    # Shift the values from [-1, 1] to [0, 2]\n",
    "    G_x[:, i] = G_x[:, i]+abs(min_x)\n",
    "    # Scale the values from [0, 2] to [0, 1]\n",
    "    div_x = (abs(min_x)+abs(max_x))\n",
    "    if div_x != 0:\n",
    "        G_x[:, i] = G_x[:, i]/div_x\n",
    "        \n",
    "print ('G_x.shape: ', G_x.shape)\n",
    "print ('G_x')\n",
    "show_image(G_x)\n",
    "print ('G_x red channel')\n",
    "show_image(G_x, 0)\n",
    "print ('G_x green channel')\n",
    "show_image(G_x, 1)\n",
    "print ('G_x blue channel')\n",
    "show_image(G_x, 2)\n",
    "\n",
    "print ('G_y.shape: ', G_y.shape)\n",
    "print ('G_y')\n",
    "show_image(G_y)\n",
    "print ('G_y red channel')\n",
    "show_image(G_y, 0)\n",
    "print ('G_y green channel')\n",
    "show_image(G_y, 1)\n",
    "print ('G_y blue channel')\n",
    "show_image(G_y, 2)\n",
    "\n",
    "G_x2 = torch.square(G_x)\n",
    "G_y2 = torch.square(G_y)\n",
    "print ('G_x^2')\n",
    "show_image(G_x2)\n",
    "print ('G_y^2')\n",
    "show_image(G_y2)\n",
    "\n",
    "print ('G_laplace')\n",
    "show_image(G_l)\n",
    "print ('G_identity')\n",
    "show_image(G_i)\n",
    "\n",
    "sobel_mag = torch.zeros_like(target_img_)\n",
    "\n",
    "for i in range(0, _n_channels):\n",
    "    sobel_mag[:,i] = torch.sqrt(G_x2[:,i]+G_y2[:,i])\n",
    "\n",
    "# show_image(G_x2)\n",
    "# show_image(G_y2)\n",
    "\n",
    "print ('mag:')\n",
    "show_image(sobel_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(_dir, _model, _name = None):\n",
    "    model_path = pathlib.Path(_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    if _name == None:\n",
    "        ts = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').replace('.', '-')\n",
    "        _name = 'model_' + ts\n",
    "    torch.save(_model.state_dict(), _dir + '\\\\' + _name + '.pt')\n",
    "    \n",
    "    # save model parameters\n",
    "    dict = {\n",
    "        \"img\": img,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"device\": device,\n",
    "        \"eval_freq\": eval_freq,\n",
    "        \"eval_iter\": eval_iter,\n",
    "        \"n_train_iter\": n_train_iter,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"log_dir\": log_dir,\n",
    "        \"pad\": pad,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"size\": size,\n",
    "        \"model_dir\": _dir,\n",
    "        \"name\": _name,\n",
    "        \"damage\": n_damage,\n",
    "        \"model_type\": model_type\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(_dir + '\\\\' + _name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "        print ('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer\n",
    "load_checkpoint = True\n",
    "checkpoint = 'cowboy_learnable_cp1.pt'\n",
    "\n",
    "print ('model type: ', model_type)\n",
    "if model_type == 'learnable':\n",
    "    model = NCA_grow_learnable(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "elif model_type == 'laplace':\n",
    "    model = NCA_grow_laplace(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "elif model_type == 'sobel':\n",
    "    model = NCA_grow_sobel(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "\n",
    "if load_checkpoint:\n",
    "    model.load_state_dict(torch.load(checkpoint_dir + '\\\\' + checkpoint, map_location=device))\n",
    "    print ('loaded checkpoint!')\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop begin\n",
    "\n",
    "# pool init\n",
    "seed = Utils.make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "cp_count = 0\n",
    "\n",
    "def loss_f(x):\n",
    "    return ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "\n",
    "# training loop\n",
    "for it in tqdm(range(n_train_iter)):\n",
    "    batch_ixs = np.random.choice(\n",
    "        pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "    \n",
    "    # get training batch and set first in batch as seed\n",
    "    x = pool[batch_ixs]\n",
    "\n",
    "    # sort batch by loss, replace the highest-loss sample with the seed.\n",
    "    loss_rank = loss_f(x).detach().cpu().numpy().argsort()[::-1]\n",
    "    x = x[loss_rank.copy()]\n",
    "    x[0] = seed.clone()\n",
    "    \n",
    "    # damage examples in batch\n",
    "    if n_damage > 0 and it > iter_start_damage:\n",
    "        radius = random.uniform(size*0.1, size*0.35)\n",
    "        u = random.uniform(0, 1) * size + pad\n",
    "        v = random.uniform(0, 1) * size + pad\n",
    "        mask = Utils.create_circle_mask(full_size, radius, [u, v])\n",
    "        x[-n_damage:] *= torch.tensor(mask).to(device)\n",
    "        \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        before = x.detach().cpu()\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "        \n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print ('train/loss: ', it, '/', loss.item())\n",
    "    \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        after = x.detach().cpu()\n",
    "        show_batch(batch_size, before, after)\n",
    "    \n",
    "    # find best in batch\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "    \n",
    "    # replace most loss example with seed\n",
    "    if it <= iter_start_damage:\n",
    "        pool[argmax_pool] = seed.clone()\n",
    "        pool[remaining_pool] = x[remaining_batch].detach()\n",
    "    else:\n",
    "        pool[batch_ixs] = x.detach()\n",
    "    \n",
    "    # clear output after 100 iterations\n",
    "    if it % 100 == 0 and it != 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # check for create checkpoint\n",
    "    if it % checkpoint_freq == 0 and it > 0:\n",
    "        save_model(checkpoint_dir, model, name + '_cp' + str(cp_count))\n",
    "        cp_count += 1\n",
    "\n",
    "# save final model\n",
    "save_model(model_dir, model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click here to watch batch viz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
