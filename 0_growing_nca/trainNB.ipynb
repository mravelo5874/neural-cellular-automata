{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from model import NCA_model\n",
    "from utils import Utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    #print ('img.shape: ', img.shape)\n",
    "    img_rgb = Utils.to_rgb(img).squeeze().permute(1, 2, 0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(batch_size, before, after, dpi=256):\n",
    "    fig = plt.figure(figsize=(batch_size, 2), dpi=dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=batch_size)\n",
    "    gspec = gridspec.GridSpec(2, batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img_i = before[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        img_i = after[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "seed = Utils.make_seed(16, 16)\n",
    "pad = 16\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(8, 1, 1, 1)\n",
    "\n",
    "#show_batch(8, pool, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x = torch.rand(2, 3, 3, 3)\n",
    "#print (x)\n",
    "\n",
    "z = torch.zeros(1, 3, 3, 1)\n",
    "x[-1:] *= z\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  True\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "img = 'imgs\\\\rainbow.png'\n",
    "name = 'rainbow'\n",
    "viz_train = True\n",
    "\n",
    "size = 32\n",
    "pad = 24\n",
    "n_channels = 16\n",
    "hid_channels = 128\n",
    "fire_rate = 0.5\n",
    "\n",
    "n_train_iter = 5000\n",
    "batch_size = 5\n",
    "pool_size = 32\n",
    "n_damage = 2\n",
    "iter_start_damage = 1000\n",
    "\n",
    "checkpoint_freq = 1000\n",
    "eval_freq = 500\n",
    "eval_iter = 300\n",
    "\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "checkpoint_dir = 'checkpoints'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape:  (32, 32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (32,3) (32,29) (32,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m log_path\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# target image\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m loaded_img \u001b[39m=\u001b[39m Utils\u001b[39m.\u001b[39;49mload_image(img, size)\n\u001b[0;32m     11\u001b[0m target_img_ \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(loaded_img, (pad, pad, pad, pad), \u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m target_img \u001b[39m=\u001b[39m target_img_\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\0_growing_nca\\utils.py:22\u001b[0m, in \u001b[0;36mUtils.load_image\u001b[1;34m(path, size)\u001b[0m\n\u001b[0;32m     20\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(img) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mimg.shape: \u001b[39m\u001b[39m'\u001b[39m, img\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 22\u001b[0m img[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :\u001b[39m3\u001b[39;49m] \u001b[39m*\u001b[39;49m\u001b[39m=\u001b[39;49m img[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39m3\u001b[39;49m:]\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mfrom_numpy(img)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39mNone\u001b[39;00m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (32,3) (32,29) (32,3) "
     ]
    }
   ],
   "source": [
    "# misc\n",
    "full_size = size + (2 * pad)\n",
    "#device_n = torch.device(device)\n",
    "\n",
    "# create log\n",
    "log_path = pathlib.Path(log_dir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# target image\n",
    "loaded_img = Utils.load_image(img, size)\n",
    "target_img_ = nn.functional.pad(loaded_img, (pad, pad, pad, pad), 'constant', 0)\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "# show image\n",
    "print ('target image: ')\n",
    "show_image(loaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(_dir, _model, _name = None):\n",
    "    model_path = pathlib.Path(_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    if _name == None:\n",
    "        ts = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').replace('.', '-')\n",
    "        _name = 'model_' + ts\n",
    "    torch.save(_model.state_dict(), _dir + '\\\\' + _name + '.pt')\n",
    "    \n",
    "    # save model parameters\n",
    "    dict = {\n",
    "        \"img\": img,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"device\": device,\n",
    "        \"eval_freq\": eval_freq,\n",
    "        \"eval_iter\": eval_iter,\n",
    "        \"n_train_iter\": n_train_iter,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"log_dir\": log_dir,\n",
    "        \"pad\": pad,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"size\": size,\n",
    "        \"model_dir\": _dir,\n",
    "        \"name\": _name,\n",
    "        \"damage\": n_damage\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(_dir + '\\\\' + _name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "        print ('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer\n",
    "load_checkpoint = False\n",
    "checkpoint = 'cowboy.pt'\n",
    "\n",
    "model = NCA_model(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "if load_checkpoint:\n",
    "    model.load_state_dict(torch.load(checkpoint_dir + '\\\\' + checkpoint, map_location=device))\n",
    "    print ('loaded checkpoint!')\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/loss:  2 / 0.022737780585885048\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x512 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5000 [00:03<1:30:47,  1.09s/it]"
     ]
    }
   ],
   "source": [
    "# training loop begin\n",
    "\n",
    "# pool init\n",
    "seed = Utils.make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "cp_count = 0\n",
    "\n",
    "def loss_f(x):\n",
    "    return ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "\n",
    "# training loop\n",
    "for it in tqdm(range(n_train_iter)):\n",
    "    batch_ixs = np.random.choice(\n",
    "        pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "    \n",
    "    # get training batch and set first in batch as seed\n",
    "    x = pool[batch_ixs]\n",
    "    \n",
    "    # sort batch by loss, replace the highest-loss sample with the seed.\n",
    "    loss_rank = loss_f(x).detach().cpu().numpy().argsort()[::-1]\n",
    "    x = x[loss_rank.copy()]\n",
    "    x[0] = seed.clone()\n",
    "    \n",
    "    # damage examples in batch\n",
    "    if n_damage > 0 and it > iter_start_damage:\n",
    "        radius = random.uniform(size*0.1, size*0.3)\n",
    "        u = random.uniform(0, 1) * size + pad\n",
    "        v = random.uniform(0, 1) * size + pad\n",
    "        mask = Utils.create_circle_mask(full_size, radius, [u, v])\n",
    "        x[-n_damage:] *= torch.tensor(mask).to(device)\n",
    "        \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        before = x.detach().cpu()\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "        \n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print ('train/loss: ', it, '/', loss.item())\n",
    "    \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        after = x.detach().cpu()\n",
    "        show_batch(batch_size, before, after)\n",
    "    \n",
    "    # find best in batch\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "    \n",
    "    # replace most loss example with seed\n",
    "    if it <= iter_start_damage:\n",
    "        pool[argmax_pool] = seed.clone()\n",
    "        pool[remaining_pool] = x[remaining_batch].detach()\n",
    "    else:\n",
    "        pool[batch_ixs] = x.detach()\n",
    "    \n",
    "    # clear output after 100 iterations\n",
    "    if it % 100 == 0 and it != 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # check for create checkpoint\n",
    "    if it % checkpoint_freq == 0 and it > 0:\n",
    "        save_model(checkpoint_dir, model, name + '_cp' + str(cp_count))\n",
    "        cp_count += 1\n",
    "\n",
    "# save final model\n",
    "save_model(model_dir, model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click here to watch batch viz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
