{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from model import NCA_model\n",
    "from utils import Utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    #print ('img.shape: ', img.shape)\n",
    "    img_rgb = Utils.to_rgb(img).squeeze().permute(1, 2, 0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(batch_size, before, after, dpi=256):\n",
    "    fig = plt.figure(figsize=(batch_size, 2), dpi=dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=batch_size)\n",
    "    gspec = gridspec.GridSpec(2, batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img_i = before[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        img_i = after[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "seed = Utils.make_seed(16, 16)\n",
    "pad = 16\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(8, 1, 1, 1)\n",
    "\n",
    "#show_batch(8, pool, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x = torch.rand(2, 3, 3, 3)\n",
    "#print (x)\n",
    "\n",
    "z = torch.zeros(1, 3, 3, 1)\n",
    "x[-1:] *= z\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  True\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "img = 'imgs\\\\frog.png'\n",
    "name = 'frog40'\n",
    "save_model = True\n",
    "viz_train = True\n",
    "\n",
    "size = 40\n",
    "pad = 16\n",
    "n_channels = 16\n",
    "hid_channels = 128\n",
    "fire_rate = 0.5\n",
    "\n",
    "n_train_iter = 4000\n",
    "batch_size = 8\n",
    "pool_size = 1024\n",
    "n_damage = 3\n",
    "iter_start_damage = 1000\n",
    "\n",
    "eval_freq = 500\n",
    "eval_iter = 300\n",
    "\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target image: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# misc\n",
    "full_size = size + (2 * pad)\n",
    "#device_n = torch.device(device)\n",
    "\n",
    "# create log\n",
    "log_path = pathlib.Path(log_dir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# target image\n",
    "loaded_img = Utils.load_image(img, size)\n",
    "target_img_ = nn.functional.pad(loaded_img, (pad, pad, pad, pad), 'constant', 0)\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "# show image\n",
    "print ('target image: ')\n",
    "show_image(loaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# sort batch by loss, replace the highest-loss sample with the seed.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss_rank \u001b[39m=\u001b[39m loss_f(x)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39margsort()[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m x \u001b[39m=\u001b[39m x[loss_rank]\n\u001b[0;32m     25\u001b[0m x[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m seed\u001b[39m.\u001b[39mclone()\n\u001b[0;32m     27\u001b[0m \u001b[39m# damage examples in batch\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) "
     ]
    }
   ],
   "source": [
    "# model and optimizer\n",
    "model = NCA_model(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "# pool init\n",
    "seed = Utils.make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "\n",
    "def loss_f(x):\n",
    "    return ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "\n",
    "# training loop\n",
    "for it in tqdm(range(n_train_iter)):\n",
    "    batch_ixs = np.random.choice(\n",
    "        pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "    \n",
    "    # get training batch and set first in batch as seed\n",
    "    x = pool[batch_ixs]\n",
    "    \n",
    "    # sort batch by loss, replace the highest-loss sample with the seed.\n",
    "    loss_rank = loss_f(x).detach().cpu().numpy().argsort()[::-1]\n",
    "    x = x[loss_rank.copy()]\n",
    "    x[0] = seed.clone()\n",
    "    \n",
    "    # damage examples in batch\n",
    "    if n_damage > 0 and it > iter_start_damage:\n",
    "        radius = random.uniform(size*0.1, size*0.3)\n",
    "        u = random.uniform(0, 1) * size + pad\n",
    "        v = random.uniform(0, 1) * size + pad\n",
    "        mask = Utils.create_circle_mask(full_size, radius, [u, v])\n",
    "        x[-n_damage:] *= torch.tensor(mask).to(device)\n",
    "        \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        before = x.detach().cpu()\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "        \n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print ('train/loss: ', it, '/', loss.item())\n",
    "    \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        after = x.detach().cpu()\n",
    "        show_batch(batch_size, before, after)\n",
    "    \n",
    "    # find best in batch\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "    \n",
    "    # replace most loss example with seed\n",
    "    if it <= iter_start_damage:\n",
    "        pool[argmax_pool] = seed.clone()\n",
    "        pool[remaining_pool] = x[remaining_batch].detach()\n",
    "    else:\n",
    "        pool[batch_ixs] = x.detach()\n",
    "    \n",
    "    # clear output after 100 iterations\n",
    "    if it % 100 == 0 and it != 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # if it % eval_freq == 0:\n",
    "    #     x_eval = seed.clone()\n",
    "    #     eval_video = torch.empty(1, eval_freq, 3, *x_eval.shape[2:])\n",
    "    #     for it_eval in range(eval_iter):\n",
    "    #         x_eval = model(x_eval)\n",
    "    #         x_eval_out = Utils.to_rgb(x_eval[:, :4].detach().cpu())\n",
    "    #         eval_video[0, it_eval] = x_eval_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "if save_model:\n",
    "    model_path = pathlib.Path(model_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    if name == None:\n",
    "        ts = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').replace('.', '-')\n",
    "        name = 'model_' + ts\n",
    "    torch.save(model.state_dict(), model_dir + '\\\\' + name + '.pt')\n",
    "    \n",
    "    # save model parameters\n",
    "    dict = {\n",
    "        \"img\": img,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"device\": device,\n",
    "        \"eval_freq\": eval_freq,\n",
    "        \"eval_iter\": eval_iter,\n",
    "        \"n_train_iter\": n_train_iter,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"log_dir\": log_dir,\n",
    "        \"pad\": pad,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"size\": size,\n",
    "        \"save_model\": save_model,\n",
    "        \"model_dir\": model_dir,\n",
    "        \"name\": name,\n",
    "        \"damage\": n_damage\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(model_dir + '\\\\' + name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "        print ('model saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
