{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from models import NCA_grow_learnable, NCA_grow_laplace, NCA_grow_sobel\n",
    "from utils import Utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, channel=None):\n",
    "    img_rgb = Utils.to_rgb(img).squeeze().permute(1, 2, 0)\n",
    "    print ('img_rgb.shape: ', img_rgb.shape)\n",
    "    if channel is not None:\n",
    "        c = img_rgb[:,:, channel]\n",
    "        channels = img_rgb.shape[2]\n",
    "        for i in range(channels):\n",
    "            if i != channel:\n",
    "                img_rgb[:,:, i] = torch.zeros((img_rgb.shape[0], img_rgb.shape[1]))\n",
    "        \n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(batch_size, before, after, dpi=256):\n",
    "    fig = plt.figure(figsize=(batch_size, 2), dpi=dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=batch_size)\n",
    "    gspec = gridspec.GridSpec(2, batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img_i = before[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        img_i = after[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "seed = Utils.make_seed(16, 16)\n",
    "pad = 16\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(8, 1, 1, 1)\n",
    "\n",
    "#show_batch(8, pool, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x = torch.rand(2, 3, 3, 3)\n",
    "#print (x)\n",
    "\n",
    "z = torch.zeros(1, 3, 3, 1)\n",
    "x[-1:] *= z\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preception!\n",
      "x.shape:  torch.Size([1, 4, 3, 3])\n",
      "sobel_filters.shape:  torch.Size([2, 3, 3])\n",
      "sobel_filters.shape:  torch.Size([8, 3, 3])\n",
      "ident_filters.shape:  torch.Size([4, 3, 3])\n",
      "sobel_filters.shape:  torch.Size([8, 1, 3, 3])\n",
      "ident_filters.shape:  torch.Size([4, 1, 3, 3])\n",
      "sobel_res.shape:  torch.Size([1, 8, 3, 3])\n",
      "sobel_mag.shape:  torch.Size([1, 4, 3, 3])\n",
      "res.shape:  torch.Size([1, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "# identity vector\n",
    "identity_filter = torch.tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=torch.float32)\n",
    "\n",
    "# create sobel filters\n",
    "batch_size = 1\n",
    "n_channels = 4\n",
    "size = 3\n",
    "angle = 0.0\n",
    "scalar = 1.0\n",
    "dx = np.outer([1, 2, 1], [-1, 0, 1]) / scalar # Sobel filter\n",
    "dy = dx.T\n",
    "c, s = np.cos(angle), np.sin(angle)\n",
    "sobel_filter_x = torch.tensor(c*dx-s*dy, dtype=torch.float32)\n",
    "sobel_filter_y = torch.tensor(s*dx+c*dy, dtype=torch.float32)\n",
    "\n",
    "x = torch.randint(1, 5, (batch_size, n_channels, size, size), dtype=torch.float32)\n",
    "print ('preception!')\n",
    "print ('x.shape: ', x.shape)\n",
    "#print (x)\n",
    "\n",
    "# stack filters together\n",
    "sobel_filters = torch.stack([sobel_filter_x, sobel_filter_y]) # (2, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "#print (filters)\n",
    "\n",
    "sobel_filters = sobel_filters.repeat((n_channels, 1, 1)) # (2 * n_channels, 3, 3)\n",
    "ident_filters = identity_filter.repeat((n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "print ('ident_filters.shape: ', ident_filters.shape)\n",
    "#print (filters)\n",
    "\n",
    "sobel_filters = sobel_filters[:, None, ...] # (2 * n_channels, 1, 3, 3)\n",
    "ident_filters = ident_filters[:, None, ...] # (2 * n_channels, 1, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "print ('ident_filters.shape: ', ident_filters.shape)\n",
    "#print (sobel_filters)\n",
    "\n",
    "sobel_res = nn.functional.conv2d(x, sobel_filters, padding=1, groups=4)\n",
    "ident_res = nn.functional.conv2d(x, ident_filters, padding=1, groups=4)\n",
    "print ('sobel_res.shape: ', sobel_res.shape)\n",
    "#print (sobel_res)\n",
    "#print ('ident_res.shape: ', ident_res.shape)\n",
    "#print (ident_res)\n",
    "\n",
    "sobel_square = torch.square(sobel_res)\n",
    "sobel_mag = torch.zeros_like(x)\n",
    "count = 0\n",
    "for i in range(0, (n_channels*2), 2):\n",
    "    mag = torch.sqrt(sobel_square[:,i] + sobel_square[:,i+1])\n",
    "    sobel_mag[:,count] = mag\n",
    "    count += 1\n",
    "\n",
    "print ('sobel_mag.shape: ', sobel_mag.shape)\n",
    "#print (sobel_mag)\n",
    "\n",
    "res = torch.cat((ident_res, sobel_mag), dim=1)\n",
    "print ('res.shape: ', res.shape)\n",
    "#print (res)\n",
    "\n",
    "# return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  True\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "img = '..\\\\_images\\\\rainbow.png'\n",
    "name = 'cowboy_learnable'\n",
    "model_type = 'learnable'\n",
    "viz_train = True\n",
    "\n",
    "size = 40\n",
    "pad = 12\n",
    "n_channels = 16\n",
    "hid_channels = 128\n",
    "fire_rate = 0.5\n",
    "\n",
    "n_train_iter = 3000\n",
    "batch_size = 8\n",
    "pool_size = 32\n",
    "n_damage = 3\n",
    "iter_start_damage = 500\n",
    "\n",
    "checkpoint_freq = 1000\n",
    "eval_freq = 500\n",
    "eval_iter = 300\n",
    "\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "checkpoint_dir = 'checkpoints'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imgs\\\\rainbow.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\0_growing_nca\\trainNB.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/0_growing_nca/trainNB.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m log_path\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/0_growing_nca/trainNB.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# target image\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/0_growing_nca/trainNB.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loaded_img \u001b[39m=\u001b[39m Utils\u001b[39m.\u001b[39;49mload_image(img, size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/0_growing_nca/trainNB.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloaded_img.shape: \u001b[39m\u001b[39m'\u001b[39m, loaded_img\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/0_growing_nca/trainNB.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m (loaded_img\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\0_growing_nca\\utils.py:25\u001b[0m, in \u001b[0;36mUtils.load_image\u001b[1;34m(path, size)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(path, size):\n\u001b[1;32m---> 25\u001b[0m     img \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39;49mImage\u001b[39m.\u001b[39;49mopen(path)\n\u001b[0;32m     26\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mresize((size, size), PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mResampling\u001b[39m.\u001b[39mBILINEAR)\n\u001b[0;32m     27\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(img) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\PIL\\Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3233\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3235\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3236\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3237\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3239\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imgs\\\\rainbow.png'"
     ]
    }
   ],
   "source": [
    "# misc\n",
    "full_size = size + (2 * pad)\n",
    "#device_n = torch.device(device)\n",
    "\n",
    "# create log\n",
    "log_path = pathlib.Path(log_dir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# target image\n",
    "loaded_img = Utils.load_image(img, size)\n",
    "print('loaded_img.shape: ', loaded_img.shape)\n",
    "print (loaded_img.shape)\n",
    "\n",
    "target_img_ = nn.functional.pad(loaded_img, (pad, pad, pad, pad), 'constant', 0)\n",
    "\n",
    "print (target_img_.shape)\n",
    "\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "# show image\n",
    "print ('target image: ')\n",
    "show_image(loaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('sobel x')\n",
    "show_image(target_img_)\n",
    "print ('red channel')\n",
    "show_image(target_img_, 0)\n",
    "print ('green channel')\n",
    "show_image(target_img_, 1)\n",
    "print ('blue channel')\n",
    "show_image(target_img_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randint(1, 8, (3, 3), dtype=torch.float32)\n",
    "print(x0)\n",
    "x1 = torch.square(x0)\n",
    "print(x1)\n",
    "x2 = torch.sqrt(x1)\n",
    "print(x2)\n",
    "print (x0 == x2)\n",
    "\n",
    "y = torch.randint(1, 8, (3, 3), dtype=torch.float32)\n",
    "print (y == torch.sqrt(torch.square(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_channels = 4\n",
    "_angle = 0.0\n",
    "_scalar = 1.0\n",
    "\n",
    "dx = np.outer([1, 2, 1], [-1, 0, 1]) / _scalar # sobel filter\n",
    "dy = dx.T\n",
    "c, s = np.cos(_angle), np.sin(_angle)\n",
    "sobel_x = torch.tensor(c*dx-s*dy, dtype=torch.float32)\n",
    "sobel_y = torch.tensor(s*dx+c*dy, dtype=torch.float32)\n",
    "laplace = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32)\n",
    "laplace /= _scalar\n",
    "identty = torch.tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=torch.float32)\n",
    "\n",
    "print (sobel_x)\n",
    "print (laplace)\n",
    "\n",
    "# sobel_x = torch.tensor([[0,0,0],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "# sobel_y = torch.tensor([[0,0,0],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "\n",
    "sobel_x = sobel_x.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "sobel_y = sobel_y.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "laplace = laplace.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "identty = identty.repeat((_n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "\n",
    "sobel_x = sobel_x[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "sobel_y = sobel_y[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "laplace = laplace[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "identty = identty[:, None, ...] # (n_channels, 1, 3, 3)\n",
    "\n",
    "# 2d conv\n",
    "G_x = nn.functional.conv2d(target_img_, sobel_x, padding=1, groups=_n_channels)\n",
    "G_y = nn.functional.conv2d(target_img_, sobel_y, padding=1, groups=_n_channels)\n",
    "G_l = nn.functional.conv2d(target_img_, laplace, padding=1, groups=_n_channels)\n",
    "G_i = nn.functional.conv2d(target_img_, identty, padding=1, groups=_n_channels)\n",
    "\n",
    "for i in range(4):\n",
    "    min_y = torch.min(G_y[:, i])\n",
    "    max_y = torch.max(G_y[:, i])\n",
    "    # Shift the values from [min, max] to [0, 1]\n",
    "    G_y[:, i] = G_y[:, i]+abs(min_y)\n",
    "    # Scale the values from [0, 2] to [0, 1]\n",
    "    div_y = (abs(min_y)+abs(max_y))\n",
    "    if div_y != 0:\n",
    "        G_y[:, i] = G_y[:, i]/div_y\n",
    "    \n",
    "    min_x = torch.min(G_x[:, i])\n",
    "    max_x = torch.max(G_x[:, i])\n",
    "    # Shift the values from [-1, 1] to [0, 2]\n",
    "    G_x[:, i] = G_x[:, i]+abs(min_x)\n",
    "    # Scale the values from [0, 2] to [0, 1]\n",
    "    div_x = (abs(min_x)+abs(max_x))\n",
    "    if div_x != 0:\n",
    "        G_x[:, i] = G_x[:, i]/div_x\n",
    "        \n",
    "print ('G_x.shape: ', G_x.shape)\n",
    "print ('G_x')\n",
    "show_image(G_x)\n",
    "print ('G_x red channel')\n",
    "show_image(G_x, 0)\n",
    "print ('G_x green channel')\n",
    "show_image(G_x, 1)\n",
    "print ('G_x blue channel')\n",
    "show_image(G_x, 2)\n",
    "\n",
    "print ('G_y.shape: ', G_y.shape)\n",
    "print ('G_y')\n",
    "show_image(G_y)\n",
    "print ('G_y red channel')\n",
    "show_image(G_y, 0)\n",
    "print ('G_y green channel')\n",
    "show_image(G_y, 1)\n",
    "print ('G_y blue channel')\n",
    "show_image(G_y, 2)\n",
    "\n",
    "G_x2 = torch.square(G_x)\n",
    "G_y2 = torch.square(G_y)\n",
    "print ('G_x^2')\n",
    "show_image(G_x2)\n",
    "print ('G_y^2')\n",
    "show_image(G_y2)\n",
    "\n",
    "print ('G_laplace')\n",
    "show_image(G_l)\n",
    "print ('G_identity')\n",
    "show_image(G_i)\n",
    "\n",
    "sobel_mag = torch.zeros_like(target_img_)\n",
    "\n",
    "for i in range(0, _n_channels):\n",
    "    sobel_mag[:,i] = torch.sqrt(G_x2[:,i]+G_y2[:,i])\n",
    "\n",
    "# show_image(G_x2)\n",
    "# show_image(G_y2)\n",
    "\n",
    "print ('mag:')\n",
    "show_image(sobel_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(_dir, _model, _name = None):\n",
    "    model_path = pathlib.Path(_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    if _name == None:\n",
    "        ts = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').replace('.', '-')\n",
    "        _name = 'model_' + ts\n",
    "    torch.save(_model.state_dict(), _dir + '\\\\' + _name + '.pt')\n",
    "    \n",
    "    # save model parameters\n",
    "    dict = {\n",
    "        \"img\": img,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"device\": device,\n",
    "        \"eval_freq\": eval_freq,\n",
    "        \"eval_iter\": eval_iter,\n",
    "        \"n_train_iter\": n_train_iter,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"log_dir\": log_dir,\n",
    "        \"pad\": pad,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"size\": size,\n",
    "        \"model_dir\": _dir,\n",
    "        \"name\": _name,\n",
    "        \"damage\": n_damage,\n",
    "        \"model_type\": model_type\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(_dir + '\\\\' + _name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "        print ('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer\n",
    "load_checkpoint = True\n",
    "checkpoint = 'cowboy_learnable_cp1.pt'\n",
    "\n",
    "print ('model type: ', model_type)\n",
    "if model_type == 'learnable':\n",
    "    model = NCA_grow_learnable(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "elif model_type == 'laplace':\n",
    "    model = NCA_grow_laplace(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "elif model_type == 'sobel':\n",
    "    model = NCA_grow_sobel(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "\n",
    "if load_checkpoint:\n",
    "    model.load_state_dict(torch.load(checkpoint_dir + '\\\\' + checkpoint, map_location=device))\n",
    "    print ('loaded checkpoint!')\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop begin\n",
    "\n",
    "# pool init\n",
    "seed = Utils.make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "cp_count = 0\n",
    "\n",
    "def loss_f(x):\n",
    "    return ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "\n",
    "# training loop\n",
    "for it in tqdm(range(n_train_iter)):\n",
    "    batch_ixs = np.random.choice(\n",
    "        pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "    \n",
    "    # get training batch and set first in batch as seed\n",
    "    x = pool[batch_ixs]\n",
    "\n",
    "    # sort batch by loss, replace the highest-loss sample with the seed.\n",
    "    loss_rank = loss_f(x).detach().cpu().numpy().argsort()[::-1]\n",
    "    x = x[loss_rank.copy()]\n",
    "    x[0] = seed.clone()\n",
    "    \n",
    "    # damage examples in batch\n",
    "    if n_damage > 0 and it > iter_start_damage:\n",
    "        radius = random.uniform(size*0.1, size*0.35)\n",
    "        u = random.uniform(0, 1) * size + pad\n",
    "        v = random.uniform(0, 1) * size + pad\n",
    "        mask = Utils.create_circle_mask(full_size, radius, [u, v])\n",
    "        x[-n_damage:] *= torch.tensor(mask).to(device)\n",
    "        \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        before = x.detach().cpu()\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "        \n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print ('train/loss: ', it, '/', loss.item())\n",
    "    \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        after = x.detach().cpu()\n",
    "        show_batch(batch_size, before, after)\n",
    "    \n",
    "    # find best in batch\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "    \n",
    "    # replace most loss example with seed\n",
    "    if it <= iter_start_damage:\n",
    "        pool[argmax_pool] = seed.clone()\n",
    "        pool[remaining_pool] = x[remaining_batch].detach()\n",
    "    else:\n",
    "        pool[batch_ixs] = x.detach()\n",
    "    \n",
    "    # clear output after 100 iterations\n",
    "    if it % 100 == 0 and it != 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # check for create checkpoint\n",
    "    if it % checkpoint_freq == 0 and it > 0:\n",
    "        save_model(checkpoint_dir, model, name + '_cp' + str(cp_count))\n",
    "        cp_count += 1\n",
    "\n",
    "# save final model\n",
    "save_model(model_dir, model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click here to watch batch viz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
