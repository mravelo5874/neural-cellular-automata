{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import io\n",
    "import base64\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from model import NCA_model\n",
    "\n",
    "from IPython.display import Image, clear_output\n",
    "import PIL.Image, PIL.ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "# creates a circle mask given a size, radius and position\n",
    "def create_circle_mask(size, radius, pos):\n",
    "    pos = pos * size\n",
    "    Y, X = np.ogrid[:size, :size]\n",
    "    dist_from_center = np.sqrt((X - pos[0])**2 + (Y-pos[1])**2)\n",
    "    mask = dist_from_center >= radius\n",
    "    return mask\n",
    "\n",
    "# Loads an image from a specified path and converts to torch.Tensor\n",
    "def load_image(path, size):\n",
    "    img = PIL.Image.open(path)\n",
    "    img = img.resize((size, size), PIL.Image.Resampling.BILINEAR)\n",
    "    img = np.float32(img) / 255.0\n",
    "    img[..., :3] *= img[..., 3:]\n",
    "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]\n",
    "\n",
    "# converts an RGBA image to a RGB image\n",
    "def to_rgb(img_rgba):\n",
    "    rgb, a = img_rgba[:, :3, ...], torch.clamp(img_rgba[:, 3:, ...], 0, 1)\n",
    "    return torch.clamp(1.0 - a + rgb, 0, 1)\n",
    "\n",
    "def np2pil(a):\n",
    "    if a.dtype in [np.float32, np.float64]:\n",
    "        a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "    return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None):\n",
    "    a = np.asarray(a)\n",
    "    if isinstance(f, str):\n",
    "        fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "        fmt = 'jpeg'\n",
    "    file = open(f, 'wb')\n",
    "    np2pil(a).save(file, fmt, quality=95)\n",
    "  \n",
    "def imencode(a, fmt='jpeg'):\n",
    "    a = np.asarray(a)\n",
    "    if len(a.shape) == 3 and a.shape[-1] == 4:\n",
    "        fmt = 'png'\n",
    "    f = io.BytesIO()\n",
    "    imwrite(f, a, fmt)\n",
    "    return f.getvalue()\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "    display(Image(data=imencode(a, fmt)))\n",
    "  \n",
    "def zoom(img, scale=4):\n",
    "    img = np.repeat(img, scale, 0)\n",
    "    img = np.repeat(img, scale, 1)\n",
    "    return img\n",
    " \n",
    "def show_batch(batch):\n",
    "    batch_size = batch.shape[0]\n",
    "    fig, axs = plt.subplots(1, batch_size)\n",
    "    fig.suptitle('batch viz')\n",
    "    plt.axis('off')\n",
    "    for i in range(batch_size):\n",
    "        img_i = batch[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        print ('img_i.shape: ', img_i.shape)\n",
    "        # show_image(img_i)\n",
    "    #     img_rgb = to_rgb(img).squeeze().permute(1, 2, 0)\n",
    "    #     axs[i].imshow(img_rgb)\n",
    "    # plt.show(fig)\n",
    "\n",
    "# Create a starting tensor for training\n",
    "# Only the active pixels are goin to be in the middle\n",
    "def make_seed(size, n_channels):\n",
    "    x = torch.zeros((1, n_channels, size, size), dtype=torch.float32)\n",
    "    x[:, 3:, size // 2, size // 2] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for experiments\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x = torch.rand(2, 3, 3, 3)\n",
    "#print (x)\n",
    "\n",
    "z = torch.zeros(1, 3, 3, 1)\n",
    "\n",
    "x[-1:] *= z\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  True\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "img = 'imgs\\pup.png'\n",
    "name = 'pup40'\n",
    "save_model = True\n",
    "\n",
    "size = 40\n",
    "pad = 16\n",
    "n_channels = 16\n",
    "\n",
    "n_train_iter = 5000\n",
    "batch_size = 8\n",
    "pool_size = 1024\n",
    "n_damage = 3\n",
    "\n",
    "eval_freq = 500\n",
    "eval_iter = 300\n",
    "\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_rgb.shape:  torch.Size([40, 40, 3])\n",
      "target image: \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_io.BytesIO' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mimg_rgb.shape: \u001b[39m\u001b[39m'\u001b[39m, img_rgb\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mtarget image: \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m imshow(zoom(img_rgb), fmt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(a, fmt)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(a, fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjpeg\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     display(Image(data\u001b[39m=\u001b[39mimencode(a, fmt)))\n",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m, in \u001b[0;36mimencode\u001b[1;34m(a, fmt)\u001b[0m\n\u001b[0;32m     41\u001b[0m     fmt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     42\u001b[0m f \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m---> 43\u001b[0m imwrite(f, a, fmt)\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mgetvalue()\n",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36mimwrite\u001b[1;34m(f, a, fmt)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjpg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     34\u001b[0m     fmt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjpeg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 35\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(f\u001b[39m.\u001b[39;49mname, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m np2pil(a)\u001b[39m.\u001b[39msave(f, fmt, quality\u001b[39m=\u001b[39m\u001b[39m95\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_io.BytesIO' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# misc\n",
    "full_size = size + (2 * pad)\n",
    "device = torch.device(device)\n",
    "\n",
    "# create log\n",
    "log_path = pathlib.Path(log_dir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# target image\n",
    "loaded_img = load_image(img, size)\n",
    "target_img_ = nn.functional.pad(loaded_img, (pad, pad, pad, pad), 'constant', 0)\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "img_rgb = to_rgb(loaded_img).squeeze().permute(1, 2, 0)\n",
    "print ('img_rgb.shape: ', img_rgb.shape)\n",
    "\n",
    "print ('target image: ')\n",
    "imshow(zoom(img_rgb), fmt='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer\n",
    "model = NCA_model(_n_channels=n_channels, _device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "# pool init\n",
    "seed = make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "\n",
    "# training loop\n",
    "for it in tqdm(range(n_train_iter)):\n",
    "    batch_ixs = np.random.choice(\n",
    "        pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "    \n",
    "    # get training batch\n",
    "    x = pool[batch_ixs]\n",
    "    \n",
    "    # damage examples in batch\n",
    "    if n_damage > 0:\n",
    "        radius = random.uniform(size*0.1, size*0.4)\n",
    "        u = random.uniform(0, 1) * size + pad\n",
    "        v = random.uniform(0, 1) * size + pad\n",
    "        mask = create_circle_mask(full_size, radius, [u, v])\n",
    "        x[-n_damage:] *= torch.tensor(mask).to(device)\n",
    "        \n",
    "    # visualize batch\n",
    "    show_batch(x)\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "    \n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print ('train/loss: ', it, '/', loss)\n",
    "    \n",
    "    # find best in batch\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "    \n",
    "    pool[argmax_pool] = seed.clone()\n",
    "    pool[remaining_pool] = x[remaining_batch].detach()\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if it % eval_freq == 0:\n",
    "        x_eval = seed.clone()\n",
    "        eval_video = torch.empty(1, eval_freq, 3, *x_eval.shape[2:])\n",
    "        for it_eval in range(eval_iter):\n",
    "            x_eval = model(x_eval)\n",
    "            x_eval_out = to_rgb(x_eval[:, :4].detach().cpu())\n",
    "            eval_video[0, it_eval] = x_eval_out\n",
    "                    \n",
    "# save model\n",
    "if save_model:\n",
    "    model_path = pathlib.Path(model_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    if name == None:\n",
    "        ts = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').replace('.', '-')\n",
    "        name = 'model_' + ts\n",
    "    torch.save(model, model_dir + '\\\\' + name + '.pt')\n",
    "    \n",
    "    # save model parameters\n",
    "    dict = {\n",
    "        \"img\": img,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"device\": device,\n",
    "        \"eval_freq\": eval_freq,\n",
    "        \"eval_iter\": eval_iter,\n",
    "        \"n_train_iter\": n_train_iter,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"log_dir\": log_dir,\n",
    "        \"pad\": pad,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"size\": size,\n",
    "        \"save_model\": save_model,\n",
    "        \"model_dir\": model_dir,\n",
    "        \"name\": name,\n",
    "        \"damage\": n_damage\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(model_dir + '\\\\' + name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
