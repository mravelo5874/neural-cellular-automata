{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from model import NCA_model\n",
    "from utils import Utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    #print ('img.shape: ', img.shape)\n",
    "    img_rgb = Utils.to_rgb(img).squeeze().permute(1, 2, 0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "def show_batch(batch_size, before, after, dpi=256):\n",
    "    fig = plt.figure(figsize=(batch_size, 2), dpi=dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=batch_size)\n",
    "    gspec = gridspec.GridSpec(2, batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img_i = before[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        img_i = after[i]\n",
    "        img_i = img_i[:4].unsqueeze(0)\n",
    "        img_rgb = Utils.to_rgb(img_i).squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "seed = Utils.make_seed(16, 16)\n",
    "pad = 16\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(8, 1, 1, 1)\n",
    "\n",
    "#show_batch(8, pool, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "x = torch.rand(2, 3, 3, 3)\n",
    "#print (x)\n",
    "\n",
    "z = torch.zeros(1, 3, 3, 1)\n",
    "x[-1:] *= z\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block used for experiments\n",
    "\n",
    "# identity vector\n",
    "identity_filter = torch.tensor([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=torch.float32)\n",
    "\n",
    "# create sobel filters\n",
    "batch_size = 1\n",
    "n_channels = 3\n",
    "size = 3\n",
    "angle = 0.0\n",
    "scalar = 1.0\n",
    "dx = np.outer([1, 2, 1], [-1, 0, 1]) / scalar # Sobel filter\n",
    "dy = dx.T\n",
    "c, s = np.cos(angle), np.sin(angle)\n",
    "sobel_filter_x = torch.tensor(c*dx-s*dy, dtype=torch.float32)\n",
    "sobel_filter_y = torch.tensor(s*dx+c*dy, dtype=torch.float32)\n",
    "\n",
    "x = torch.randint(1, 5, (batch_size, n_channels, size, size), dtype=torch.float32)\n",
    "print ('preception!')\n",
    "print ('x.shape: ', x.shape)\n",
    "print (x)\n",
    "\n",
    "# stack filters together\n",
    "sobel_filters = torch.stack([sobel_filter_x, sobel_filter_y]) # (2, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "#print (filters)\n",
    "\n",
    "sobel_filters = sobel_filters.repeat((n_channels, 1, 1)) # (2 * n_channels, 3, 3)\n",
    "ident_filters = identity_filter.repeat((n_channels, 1, 1)) # (n_channels, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "print ('ident_filters.shape: ', ident_filters.shape)\n",
    "#print (filters)\n",
    "\n",
    "sobel_filters = sobel_filters[:, None, ...] # (2 * n_channels, 1, 3, 3)\n",
    "ident_filters = ident_filters[:, None, ...] # (2 * n_channels, 1, 3, 3)\n",
    "print ('sobel_filters.shape: ', sobel_filters.shape)\n",
    "print ('ident_filters.shape: ', ident_filters.shape)\n",
    "#print (sobel_filters)\n",
    "\n",
    "sobel_res = nn.functional.conv2d(x, sobel_filters, padding=1, groups=n_channels)\n",
    "ident_res = nn.functional.conv2d(x, ident_filters, padding=1, groups=n_channels)\n",
    "print ('sobel_res.shape: ', sobel_res.shape)\n",
    "#print (sobel_res)\n",
    "print ('ident_res.shape: ', ident_res.shape)\n",
    "#print (ident_res)\n",
    "\n",
    "sobel_square = torch.square(sobel_res)\n",
    "print (sobel_square)\n",
    "\n",
    "sobel_mag = torch.zeros_like(x)\n",
    "count = 0\n",
    "for i in range(0, (n_channels*2), 2):\n",
    "    mag = torch.sqrt(sobel_square[:,i] + sobel_square[:,i+1])\n",
    "    sobel_mag[:,count] = mag\n",
    "    count += 1\n",
    "\n",
    "print ('sobel_mag.shape: ', sobel_mag.shape)\n",
    "print (sobel_mag)\n",
    "\n",
    "res = torch.cat((ident_res, sobel_mag), dim=1)\n",
    "print ('res.shape: ', res.shape)\n",
    "print (res)\n",
    "\n",
    "# return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "img = 'imgs\\\\cowboy.png'\n",
    "name = 'cowboy_laplace'\n",
    "viz_train = True\n",
    "\n",
    "size = 40\n",
    "pad = 12\n",
    "n_channels = 16\n",
    "hid_channels = 128\n",
    "fire_rate = 0.5\n",
    "\n",
    "n_train_iter = 8000\n",
    "batch_size = 8\n",
    "pool_size = 64\n",
    "n_damage = 3\n",
    "iter_start_damage = 1000\n",
    "\n",
    "checkpoint_freq = 1000\n",
    "eval_freq = 500\n",
    "eval_iter = 300\n",
    "\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "checkpoint_dir = 'checkpoints'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc\n",
    "full_size = size + (2 * pad)\n",
    "#device_n = torch.device(device)\n",
    "\n",
    "# create log\n",
    "log_path = pathlib.Path(log_dir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# target image\n",
    "loaded_img = Utils.load_image(img, size)\n",
    "target_img_ = nn.functional.pad(loaded_img, (pad, pad, pad, pad), 'constant', 0)\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "# show image\n",
    "print ('target image: ')\n",
    "show_image(loaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(_dir, _model, _name = None):\n",
    "    model_path = pathlib.Path(_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    if _name == None:\n",
    "        ts = str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').replace('.', '-')\n",
    "        _name = 'model_' + ts\n",
    "    torch.save(_model.state_dict(), _dir + '\\\\' + _name + '.pt')\n",
    "    \n",
    "    # save model parameters\n",
    "    dict = {\n",
    "        \"img\": img,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"device\": device,\n",
    "        \"eval_freq\": eval_freq,\n",
    "        \"eval_iter\": eval_iter,\n",
    "        \"n_train_iter\": n_train_iter,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"log_dir\": log_dir,\n",
    "        \"pad\": pad,\n",
    "        \"pool_size\": pool_size,\n",
    "        \"size\": size,\n",
    "        \"model_dir\": _dir,\n",
    "        \"name\": _name,\n",
    "        \"damage\": n_damage\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(_dir + '\\\\' + _name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "        print ('model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer\n",
    "load_checkpoint = False\n",
    "checkpoint = 'cowboy.pt'\n",
    "\n",
    "model = NCA_model(_n_channels=n_channels, _hid_channels=hid_channels, _fire_rate=fire_rate, _device=device)\n",
    "if load_checkpoint:\n",
    "    model.load_state_dict(torch.load(checkpoint_dir + '\\\\' + checkpoint, map_location=device))\n",
    "    print ('loaded checkpoint!')\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop begin\n",
    "\n",
    "# pool init\n",
    "seed = Utils.make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (pad, pad, pad, pad), 'constant', 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "cp_count = 0\n",
    "\n",
    "def loss_f(x):\n",
    "    return ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "\n",
    "# training loop\n",
    "for it in tqdm(range(n_train_iter)):\n",
    "    batch_ixs = np.random.choice(\n",
    "        pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "    \n",
    "    # get training batch and set first in batch as seed\n",
    "    x = pool[batch_ixs]\n",
    "    \n",
    "    # sort batch by loss, replace the highest-loss sample with the seed.\n",
    "    loss_rank = loss_f(x).detach().cpu().numpy().argsort()[::-1]\n",
    "    x = x[loss_rank.copy()]\n",
    "    x[0] = seed.clone()\n",
    "    \n",
    "    # damage examples in batch\n",
    "    if n_damage > 0 and it > iter_start_damage:\n",
    "        radius = random.uniform(size*0.1, size*0.35)\n",
    "        u = random.uniform(0, 1) * size + pad\n",
    "        v = random.uniform(0, 1) * size + pad\n",
    "        mask = Utils.create_circle_mask(full_size, radius, [u, v])\n",
    "        x[-n_damage:] *= torch.tensor(mask).to(device)\n",
    "        \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        before = x.detach().cpu()\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "        \n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print ('train/loss: ', it, '/', loss.item())\n",
    "    \n",
    "    # visualize batch\n",
    "    if viz_train:\n",
    "        after = x.detach().cpu()\n",
    "        show_batch(batch_size, before, after)\n",
    "    \n",
    "    # find best in batch\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "    \n",
    "    # replace most loss example with seed\n",
    "    if it <= iter_start_damage:\n",
    "        pool[argmax_pool] = seed.clone()\n",
    "        pool[remaining_pool] = x[remaining_batch].detach()\n",
    "    else:\n",
    "        pool[batch_ixs] = x.detach()\n",
    "    \n",
    "    # clear output after 100 iterations\n",
    "    if it % 100 == 0 and it != 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # check for create checkpoint\n",
    "    if it % checkpoint_freq == 0 and it > 0:\n",
    "        save_model(checkpoint_dir, model, name + '_cp' + str(cp_count))\n",
    "        cp_count += 1\n",
    "\n",
    "# save final model\n",
    "save_model(model_dir, model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click here to watch batch viz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
