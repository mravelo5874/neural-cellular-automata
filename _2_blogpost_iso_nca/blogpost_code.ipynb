{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "974P6JcnyfPf"
      },
      "source": [
        "# Isotropic and Steerable NCA (structured seed experiments)\n",
        "\n",
        "### Author: Craig Fouts (cwf2117@columbia.edu)\n",
        "\n",
        "*Copyright 2023 Craig Fouts*\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "NCTKsrsiOUiG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce GTX 1660 Ti (UUID: GPU-d77bcb98-b41a-4494-1c93-f4f7d0b55d9c)\n",
            "cuda available?  True\n",
            "device:  cuda\n"
          ]
        }
      ],
      "source": [
        "#@title Notebook Utilities and Setup\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import matplotlib.pylab as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms.functional as T\n",
        "import warnings\n",
        "from colorsys import hsv_to_rgb\n",
        "# from google.colab import drive, output\n",
        "from IPython.display import clear_output, Image\n",
        "from torch.nn import BatchNorm1d, Dropout, InstanceNorm1d, LayerNorm, Module, ReLU, Sequential\n",
        "from torchvision.transforms.functional_tensor import gaussian_blur\n",
        "from tqdm.notebook import tnrange\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "\n",
        "# output.enable_custom_widget_manager()\n",
        "\n",
        "# * find GPU available\n",
        "clear_output()\n",
        "!nvidia-smi -L\n",
        "\n",
        "# * sets the device\n",
        "# *     defaults to 'cuda'\n",
        "_DEVICE_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print ('cuda available? ', torch.cuda.is_available())\n",
        "print ('device: ', _DEVICE_)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.cuda.empty_cache()\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# USE_DRIVE = False  #@param{type:\"boolean\"}\n",
        "DIRECTORY = 'My Drive/Models'  #@param{type:\"string\"}\n",
        "MODEL_PATH = '_checkpoints'\n",
        "\n",
        "# if USE_DRIVE:\n",
        "#   drive.mount('/content/drive')\n",
        "#   MODEL_PATH = os.path.join('/content/drive', DIRECTORY)\n",
        "\n",
        "def imread(url, max_size=None, mode=None):\n",
        "  if url.startswith(('http:', 'https:')):\n",
        "    headers = {'User-Agent': 'Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0'}\n",
        "    r = requests.get(url, headers=headers)\n",
        "    f = io.BytesIO(r.content)\n",
        "  else:\n",
        "    f = url\n",
        "  img = PIL.Image.open(f)\n",
        "  if max_size is not None:\n",
        "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  if mode is not None:\n",
        "    img = img.convert(mode)\n",
        "  img = np.float32(img) / 255.\n",
        "  return img\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in (np.float32, np.float64):\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None, quality=95):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=quality)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if a.ndim == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "def imshow(a, fmt='jpeg', scale=4):\n",
        "  display(Image(data=imencode(zoom(a, scale), fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(a.shape[0])))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w - a.shape[0]) % w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = a.shape[0] // w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def to_rgb(x):\n",
        "  rgb, a = x[:, :3], x[:, 3:4]\n",
        "  return 1. - a + rgb\n",
        "\n",
        "def grab_plot(close=True):\n",
        "  fig = pl.gcf()\n",
        "  fig.canvas.draw()\n",
        "  img = np.array(fig.canvas.renderer._renderer)\n",
        "  a = np.float32(img[..., 3:]/255.)\n",
        "  img = np.uint8(255*(1.-a)+img[..., :3]*a)\n",
        "  if close:\n",
        "    pl.close()\n",
        "  return img\n",
        "\n",
        "def vis_angle(x, w):\n",
        "  m = get_alive_mask(x).cpu()\n",
        "  rgb = to_rgb(x)[0].clip(0, 1).permute(1, 2, 0).cpu()\n",
        "  ang, a, m = x[0, -1].cpu(), x[0, 3].cpu(), m[0,0]\n",
        "  c, s = ang.cos() * a, ang.sin() * a\n",
        "  px, py = np.mgrid[-1:1:w*1j, -1:1:w*1j]\n",
        "  pl.figure(figsize=(10, 10))\n",
        "  pl.axis('equal')\n",
        "  pl.xlim(-0.8, 0.8); pl.ylim(-0.8,0.8)\n",
        "  pl.quiver(px[m], py[m], c[m], s[m], color=rgb[m], pivot='mid', scale_units='xy', units='xy', scale=W/3)\n",
        "  pl.tight_layout()\n",
        "  pl.axis('off')\n",
        "  return grab_plot()\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename='_autoplay.mp4', fps=30., **kwargs):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kwargs)\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "  \n",
        "  def __exit__(self, *args):\n",
        "    self.close()\n",
        "    if self.params['filename'] == '_autoplay.mp4':\n",
        "      self.show()\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in (np.float32, np.float64):\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if img.ndim == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer is not None:\n",
        "      self.writer.close()\n",
        "\n",
        "  def show(self, **kwargs):\n",
        "    self.close()\n",
        "    fn = self.params['filename']\n",
        "    display(mvp.ipython_display(fn, **kwargs))\n",
        "\n",
        "def vidgen(filename, model, n_frames=500, max_speed=128, n=16, sz=72, p=2, r=4, angle=None, custom_seed=None):\n",
        "  with VideoWriter(filename=filename) as vid, torch.no_grad():\n",
        "    if custom_seed is None:\n",
        "        x = seed(n, sz, p, r, angle=angle)\n",
        "    for i in tnrange(n_frames, leave=False):\n",
        "        img = to_rgb(x).permute(0, 2, 3, 1).cpu()\n",
        "        vid.add(zoom(tile2d(img), 2))\n",
        "        step_n = min(2**(i//30), max_speed)\n",
        "        for _ in range(step_n):\n",
        "            x = model(x)\n",
        "    vid.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4azYa9u3aMT"
      },
      "source": [
        "# Model Legend\n",
        "\n",
        "Select the model of interest from the following\n",
        "\n",
        "* LAPLACIAN:&emsp;Isotropic NCA model\n",
        "* LAP6:&emsp;Isotropic NCA, (trained and/or evaluated) on a hexagonal grid\n",
        "* GRADNORM:&emsp;Isotropic NCA variant discussed in the blogpost\n",
        "* STEERABLE:&emsp;Angle-based Steerable NCA\n",
        "* GRADIENT:&emsp;Gradient-based Steerable NCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "08RFfJ5xl-cL"
      },
      "outputs": [],
      "source": [
        "#@title Model Utilities and Setup {vertical-output:true}\n",
        "\n",
        "MODEL_TYPE = 'STEERABLE'  #@param['LAPLACIAN', 'LAP6', 'GRADNORM', 'STEERABLE', 'GRADIENT']\n",
        "UPDATE_RATE = .5\n",
        "\n",
        "CHN = 16\n",
        "ANGLE_CHN = 1 if MODEL_TYPE == 'STEERABLE' else 0\n",
        "SCALAR_CHN = CHN - ANGLE_CHN\n",
        "\n",
        "IDENT = torch.tensor([[0., 0., 0.], [0., 1., 0.], [0., 0., 0.]])\n",
        "SOBEL = torch.tensor([[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]])\n",
        "LAP = torch.tensor([[1., 2., 1.], [2., -12., 2.], [1., 2., 1.]])\n",
        "LAP6 = torch.tensor([[0., 2., 2.], [2., -12., 2.], [2., 2., 0.]])\n",
        "GAUSS = torch.tensor([[1., 2., 1.], [2., 4., 2.], [1., 2., 1.]]) / 16.\n",
        "NHOOD_KERNEL = ((LAP6 if MODEL_TYPE == 'LAP6' else LAP) != 0.).to(torch.float32)\n",
        "\n",
        "def perchannel_conv(x, filters):\n",
        "  b, ch, h, w = x.shape\n",
        "  y = x.reshape(b * ch, 1, h, w)\n",
        "  y = F.pad(y, (1, 1, 1, 1), 'circular')\n",
        "  filters = filters.to(_DEVICE_)\n",
        "  y = y.to(_DEVICE_)\n",
        "  y = F.conv2d(y, filters[:, None])\n",
        "  return y.reshape(b, -1, h, w)\n",
        "\n",
        "# Isotropic models\n",
        "def laplacian_perception(x):\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap], 1)\n",
        "\n",
        "def lap6_perception(x):\n",
        "  state_lap = perchannel_conv(x, LAP6[None, :])\n",
        "  return torch.cat([x, state_lap], 1)\n",
        "\n",
        "def gradnorm_perception(x):\n",
        "  grad = perchannel_conv(x, torch.stack([SOBEL, SOBEL.T]))\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap, (gx*gx+gy*gy+1e-8).sqrt()], 1)\n",
        "\n",
        "# Steerable models\n",
        "def steerable_perception(x):\n",
        "  state, angle = x[:, :-1], x[:, -1:]\n",
        "  c, s = angle.cos(), angle.sin()\n",
        "  filters = torch.stack([SOBEL, SOBEL.T])\n",
        "  grad = perchannel_conv(state, filters)\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "  state_lap = perchannel_conv(state, LAP[None, :])\n",
        "  res = torch.cat([state, rot_grad, state_lap], 1)\n",
        "  return res\n",
        "\n",
        "def gradient_perception(x):\n",
        "  filters = torch.stack([SOBEL, SOBEL.T])\n",
        "  grad = perchannel_conv(x, filters)\n",
        "  grad, dir = grad[:, :-2], grad[:, -2:]\n",
        "  dir = dir / dir.norm(dim=1, keepdim=True).clip(1.)\n",
        "  c, s = dir[:, :1], dir[:, 1:2]\n",
        "  gx, gy = grad[:, ::2], grad[:, 1::2]\n",
        "  rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "  state_lap = perchannel_conv(x, LAP[None, :])\n",
        "  return torch.cat([x, state_lap, rot_grad], 1)\n",
        "\n",
        "perception = {\n",
        "    'LAPLACIAN': laplacian_perception,\n",
        "    'LAP6': lap6_perception,\n",
        "    'GRADNORM': gradnorm_perception,\n",
        "    'STEERABLE': steerable_perception,\n",
        "    'GRADIENT': gradient_perception\n",
        "}\n",
        "\n",
        "def get_alive_mask(x):\n",
        "  mature = (x[:, 3:4] > .1).to(torch.float32)\n",
        "  return perchannel_conv(mature, NHOOD_KERNEL[None, :]) > .5\n",
        "\n",
        "def fibonacci_lattice(n):\n",
        "  '''Generates an n-point fibonacci lattice of radius 1'''\n",
        "  epsilon = 0.33  # Assumes n < 24\n",
        "  golden_ratio = (1 + np.sqrt(5)) / 2.\n",
        "  pts = torch.arange(n)\n",
        "  theta = 2 * np.pi * pts / golden_ratio\n",
        "  phi = torch.arccos(1-2*(pts+epsilon)/(n-1+2*epsilon))\n",
        "  x, y, z = torch.cos(theta)*torch.sin(phi), torch.sin(theta)*torch.sin(phi), torch.cos(phi)\n",
        "  return torch.concat([x[None, :], y[None, :], z[None, :]], 0)\n",
        "\n",
        "def rgb_linspace(n):\n",
        "  '''Generates n visually distinct rgb combinations'''\n",
        "  return torch.tensor([hsv_to_rgb(i / n, 1.0, 1.0) for i in range(n)], dtype=torch.float32)\n",
        "\n",
        "def rotate_n(x, n, min=0., max=360.):\n",
        "  a = np.linspace(0., 360., n)\n",
        "  for i, a in zip(range(n), a):\n",
        "    x[i] = T.rotate(x[i], a)\n",
        "  return x\n",
        "\n",
        "def seed(n, sz=128, p=2, r=4, xy=None, angle=0., flip=False, rgb_dist=rgb_linspace):\n",
        "  '''Generates a uniform p-point structured seed of radius r'''\n",
        "  x = torch.zeros(n, CHN, sz, sz)\n",
        "  if SCALAR_CHN != CHN:\n",
        "    x[:, -1] = torch.rand(n, sz, sz) * np.pi * 2.\n",
        "  # Initialize p points equidistant around a circle of radius r\n",
        "  t = np.linspace(0, 2 * np.pi, p, endpoint=False)\n",
        "  if xy is None:\n",
        "    xy = (np.c_[r*np.cos(t), r*np.sin(t)]+(sz//2)).astype(np.int32).T\n",
        "  # Assign distinct rgb values to each point\n",
        "  x[:, :3, xy[0], xy[1]] = rgb_dist(xy.shape[1]).T\n",
        "  x[:, 3:SCALAR_CHN, xy[0], xy[1]] = 1.0\n",
        "  x = rotate_n(x, n) if angle is None else T.rotate(x, angle)\n",
        "  if flip:\n",
        "    x = torch.flip(x, [3])\n",
        "  return x\n",
        "\n",
        "class CA(torch.nn.Module):\n",
        "  def __init__(self, chn=CHN, hidden_n=128):\n",
        "    super().__init__()\n",
        "    self.chn = chn\n",
        "\n",
        "    # Determine the number of perceived channels\n",
        "    perc_n = perception[MODEL_TYPE](torch.zeros([1, chn, 8, 8])).shape[1]\n",
        "\n",
        "    # Approximately equalize the parameter count between model variants\n",
        "    hidden_n = 8 * 1024 // (perc_n + chn)\n",
        "    hidden_n = (hidden_n + 31) // 32 * 32\n",
        "\n",
        "    # Model layers\n",
        "    self.w1 = torch.nn.Conv2d(perc_n, hidden_n, 1)\n",
        "    self.w2 = torch.nn.Conv2d(hidden_n, chn, 1, bias=False)\n",
        "    self.w2.weight.data.zero_()\n",
        "\n",
        "  def forward(self, x, update_rate=UPDATE_RATE):\n",
        "    # Get update and masks\n",
        "    alive = get_alive_mask(x)\n",
        "    y = perception[MODEL_TYPE](x)\n",
        "    y = self.w2(torch.relu(self.w1(y)))\n",
        "    b, c, h, w = y.shape\n",
        "    update_mask = (torch.rand(b, 1, h, w) + update_rate).floor()\n",
        "\n",
        "    # Perform update\n",
        "    x = x + y * update_mask\n",
        "    if SCALAR_CHN == CHN:\n",
        "      x = x * alive\n",
        "    else:\n",
        "      state = x[:, :SCALAR_CHN] * alive\n",
        "      angle = x[:, SCALAR_CHN:] % (2. * torch.pi)\n",
        "      x = torch.cat([state, angle], 1)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF4nrfDn5lf4"
      },
      "source": [
        "# Target Legend\n",
        "\n",
        "Select the target of interest from the following\n",
        "\n",
        "* LIZARD:&emsp;🦎\n",
        "* HEART:&emsp;❤️\n",
        "* SMILEY:&emsp;😁\n",
        "\n",
        "Select the number of seeds and seed radius below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "LPUMYyptdiDx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAYAAACLz2ctAAAAp0lEQVR4nO3cMQ6AUAgDUPD+d8aZ8cehGt/b2EjTuVUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABApx/4vJlZd7dMD1zpB/g3BSRKAQEAAAAAAAAAAAAAAAAAAAAAgMWW3UNTtfYBW6ZHrGMRpYBEKSAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvMwN1/EFD65GJCAAAAAASUVORK5CYII=",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Seed and Target Setup {vertical-output:true}\n",
        "\n",
        "SEED_N = 2  #@param{type:\"integer\"}\n",
        "SEED_R = 4  #@param{type:\"integer\"}\n",
        "TARGET = 'COWBOY'  #@param['LIZARD', 'HEART', 'SMILEY']\n",
        "PADDING = 12\n",
        "\n",
        "# emoji = {\n",
        "#     'LIZARD':  '🦎',\n",
        "#     'HEART':  '❤️',\n",
        "#     'SMILEY': '😁'\n",
        "# }[TARGET][0]\n",
        "# code = hex(ord(emoji))[2:].lower()\n",
        "url = '../_images/cowboy.png' #https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "target = imread(url, 40)\n",
        "\n",
        "# Show lineup\n",
        "n_seed = seed(1, 40, SEED_N, SEED_R)[0, :4].permute([1, 2, 0]).cpu()\n",
        "imgs = np.stack([n_seed, target], 0)\n",
        "imshow(n_seed)\n",
        "imshow(target)\n",
        "\n",
        "# Format target\n",
        "target[:, :, :3] *= target[:, :, 3:]\n",
        "target = F.pad(torch.tensor(target).permute(2, 0, 1), [*(PADDING,)*4, 0, 0])\n",
        "W = target.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target.shape torch.Size([4, 64, 64])\n",
            "img.shape torch.Size([64, 64, 4])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tgt.shape: torch.Size([1, 4, 64, 64])\n",
            "sobel_x.shape: torch.Size([1, 4, 64, 64])\n",
            "sobel_x.shape: torch.Size([64, 64, 4])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sobel_y.shape: torch.Size([64, 64, 4])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lap.shape: torch.Size([64, 64, 4])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print ('target.shape',target.shape)\n",
        "img = target.permute(1, 2, 0).cpu()\n",
        "print ('img.shape',img.shape)\n",
        "imshow(img)\n",
        "\n",
        "tgt = target[None, ...]\n",
        "print ('tgt.shape:',tgt.shape)\n",
        "\n",
        "sobel_x = perchannel_conv(tgt, SOBEL[None, :])\n",
        "print ('sobel_x.shape:',sobel_x.shape)\n",
        "sobel_x = sobel_x.squeeze().permute(1,2,0).cpu()\n",
        "print ('sobel_x.shape:',sobel_x.shape)\n",
        "imshow(sobel_x)\n",
        "\n",
        "sobel_y = perchannel_conv(tgt, SOBEL.T[None, :]).squeeze(0).permute(1,2,0).cpu()\n",
        "print ('sobel_y.shape:',sobel_y.shape)\n",
        "imshow(sobel_y)\n",
        "\n",
        "lap = perchannel_conv(tgt, LAP[None, :]).squeeze(0).permute(1,2,0).cpu()\n",
        "print ('lap.shape:',lap.shape)\n",
        "imshow(lap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR5RlK-97Kg2"
      },
      "source": [
        "# Loss Legend\n",
        "\n",
        "Select the loss function of interest from the following\n",
        "\n",
        "* FIXED:&emsp;L2-norm loss\n",
        "* INVARIANT:&emsp;Rotation-invariant loss\n",
        "\n",
        "Select the lower and upper learning rate limits below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "QaqCjNgCmmjS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model name:  steerable_cowboy_fixed_2pt_4r\n"
          ]
        }
      ],
      "source": [
        "#@title Training Utilities and Setup\n",
        "\n",
        "LOSS_FN = 'FIXED'  #@param['FIXED', 'INVARIANT']\n",
        "LOWER_LR = 1e-5  #@param{type:\"number\"}\n",
        "UPPER_LR = 1e-3  #@param{type:\"number\"}\n",
        "MODEL_NAME = f'{MODEL_TYPE}_{TARGET}_{LOSS_FN}_{SEED_N}pt_{SEED_R}r'.lower()\n",
        "MODEL_DIR = os.path.join(MODEL_PATH, MODEL_NAME)\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "# if USE_DRIVE and not os.path.exists(MODEL_DIR):\n",
        "#   os.mkdir(MODEL_DIR)\n",
        "\n",
        "def fixed_loss_fn(x, scale=1e3, ax=[]):\n",
        "  return scale * torch.mean(torch.square(x[:, :4] - target[:4]), ax)\n",
        "\n",
        "def unsharp(img):\n",
        "  blured = gaussian_blur(img, (5, 5), (1, 1))\n",
        "  return img + (img - blured) * 2.\n",
        "\n",
        "s = np.sqrt(3) / 2.\n",
        "hex2xy = np.float32([[1., 0.], [.5, s]])\n",
        "xy2hex = torch.tensor(np.linalg.inv(hex2xy))\n",
        "r = torch.linspace(.5/W, 1, W//2)[:, None]\n",
        "a = torch.range(0, W*np.pi) / (W / 2)\n",
        "polar_xy = torch.stack([r*a.cos(), r*a.sin()], -1)[None, :]\n",
        "polar_target = F.grid_sample(unsharp(target[None, :]), polar_xy)\n",
        "\n",
        "x = torch.linspace(-1, 1, W)\n",
        "y, x = torch.meshgrid(x, x)\n",
        "xy_grid = torch.stack([x, y], -1)\n",
        "fft_target = torch.fft.rfft(polar_target).conj()\n",
        "polar_target_sqnorm = polar_target.square().sum(-1, keepdim=True)\n",
        "\n",
        "def invariant_losses_fn(img):\n",
        "  img = unsharp(img)\n",
        "  polar_img = F.grid_sample(img, polar_xy.repeat(len(img), 1, 1, 1), mode='bicubic')\n",
        "  x = torch.fft.rfft(polar_img)\n",
        "  xy = torch.fft.irfft(x*fft_target)\n",
        "  xx = polar_img.square().sum(-1, keepdim=True)\n",
        "  yy = polar_target_sqnorm\n",
        "  sqdiff = xx + yy - 2. * xy\n",
        "  return sqdiff.mean([1, 2])\n",
        "\n",
        "def invariant_loss_fn(img):\n",
        "  return invariant_losses_fn(img).min(-1)[0].mean()\n",
        "\n",
        "loss_fn = {\n",
        "    'FIXED': fixed_loss_fn,\n",
        "    'INVARIANT': invariant_loss_fn,\n",
        "}\n",
        "\n",
        "def circle_masks(n, sz):\n",
        "  x = torch.linspace(-1.0, 1.0, sz)[None, None, :]\n",
        "  y = torch.linspace(-1.0, 1.0, sz)[None, :, None]\n",
        "  center = -torch.rand([2, n, 1, 1]) + 0.5\n",
        "  r = -0.3*torch.rand([n, 1, 1]) + 0.4\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = (x*x+y*y < 1.0).float()\n",
        "  return mask\n",
        "\n",
        "model = CA()\n",
        "loss_log = []\n",
        "progress = 0\n",
        "with torch.no_grad():\n",
        "  pool = seed(256, W, SEED_N, SEED_R)\n",
        "#   img = to_rgb(pool)\n",
        "#   imgs = img.permute([0, 2, 3, 1]).cpu()\n",
        "#   imshow(tile2d(imgs.detach(), 16), scale=1)\n",
        "opt = torch.optim.Adam(model.parameters(), UPPER_LR)\n",
        "lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, LOWER_LR, UPPER_LR, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n",
        "\n",
        "print ('model name: ', MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "OFCqvxs1dr10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/15001 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipping training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Training Loop {vertical-output:true}\n",
        "\n",
        "TRAIN_MODEL = False\n",
        "EPOCHS = 15000  #@param{type:\"number\"}\n",
        "DAMAGE_RATE = 3\n",
        "IMAGE_RATE = 20\n",
        "INFO_RATE = 20\n",
        "SAVE_RATE = 500\n",
        "\n",
        "for _ in tqdm(range(EPOCHS+1)):\n",
        "    if not TRAIN_MODEL:\n",
        "        print ('skipping training')\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        i = len(loss_log)\n",
        "        batch_idx = np.random.choice(len(pool), 8, replace=False)\n",
        "        x = pool[batch_idx]\n",
        "        # loss_rank = torch.argsort(loss_fn(x, ax=[-2, -3, -1]), descending=True)\n",
        "        # x = x[loss_rank]\n",
        "        \n",
        "        seed_rate = 1  if i < 4000 else 5\n",
        "        if i % seed_rate == 0:\n",
        "            x[:1] = seed(1, W, SEED_N, SEED_R)\n",
        "\n",
        "        if i % DAMAGE_RATE == 0:\n",
        "            damage_mask = 1. - circle_masks(1, W)[:, None]\n",
        "            x[-1:] *= damage_mask\n",
        "\n",
        "    step_n = np.random.randint(64, 96)\n",
        "    overflow_loss = 0.\n",
        "    diff_loss = 0.\n",
        "    target_loss = 0.\n",
        "    last_x = torch.zeros(x.shape)\n",
        "    for _ in range(step_n):\n",
        "        px = x\n",
        "        x = model(x)\n",
        "        diff_loss += (x - px).abs().mean()\n",
        "        overflow_loss += (x - x.clamp(-2., 2.))[:, :SCALAR_CHN].square().sum()\n",
        "\n",
        "    target_loss += loss_fn[LOSS_FN](x[:, :target.shape[0]])\n",
        "    diff_loss *= 10.\n",
        "    loss = target_loss + overflow_loss + diff_loss\n",
        "    # if loss.isnan():\n",
        "    #   # TODO: reload model from last checkpoint\n",
        "    #   print('\\nWARNING: NaN')\n",
        "    #   pool[batch_idx] = seed(8, W, SEED_N, SEED_R)\n",
        "    #   continue\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss.backward()\n",
        "        for p in model.parameters():\n",
        "            p.grad /= (p.grad.norm() + 1e-8)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        lr_sched.step()\n",
        "        pool[batch_idx] = x\n",
        "        loss_log.append(loss.item())\n",
        "\n",
        "    if i % IMAGE_RATE == 0:\n",
        "        clear_output(True)\n",
        "        pl.plot(loss_log, '.', alpha=.1)\n",
        "        pl.yscale('log')\n",
        "        pl.ylim(np.min(loss_log), loss_log[0])\n",
        "        pl.show()\n",
        "        imgs = to_rgb(x)\n",
        "        imgs = imgs.permute([0, 2, 3, 1]).cpu()\n",
        "        imshow(tile2d(imgs.detach(), 4), scale=2)\n",
        "\n",
        "    if i % INFO_RATE == 0:\n",
        "        print('\\rstep_n:', i, '\\tloss:', loss.item(), '\\tlr:', lr_sched.get_lr()[0], end='')\n",
        "\n",
        "    if i % SAVE_RATE == 0:\n",
        "        progress = i\n",
        "        torch.save(model, os.path.join(MODEL_DIR, f'{MODEL_NAME}_{i}.pt'))\n",
        "\n",
        "if TRAIN_MODEL: \n",
        "    # * save final model\n",
        "    torch.save(model, os.path.join('_models', f'{MODEL_NAME}.pt'))\n",
        "    torch.save(model.state_dict(), os.path.join('_states', f'{MODEL_NAME}_state_dict.pt'))\n",
        "\n",
        "    # * create model video!\n",
        "    FRAMES = 500  #@param{type:\"integer\"}\n",
        "    progress = 15000\n",
        "\n",
        "    model_name = f'{MODEL_TYPE}_{TARGET}_{LOSS_FN}_{SEED_N}pt_{SEED_R}r_{progress}'.lower()\n",
        "    model_path = os.path.join(MODEL_DIR, f'{model_name}.pt')\n",
        "    demo_path = os.path.join('_videos', f'{model_name}.mp4')\n",
        "\n",
        "    try:\n",
        "        model = torch.load(model_path)\n",
        "        vidgen(demo_path, model, n_frames=FRAMES, p=SEED_N, r=SEED_R)\n",
        "    except FileNotFoundError:\n",
        "        print(f'Model \"{model_name}\" not found.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions for running pygame instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "\n",
        "# * loads an image and converts to a tensor\n",
        "# *     default tensor shape: [BATCH_SIZE (1), CHANNELS (4), WIDTH (_size), HEIGHT (_size)]\n",
        "def load_image_as_tensor(_path, _size, _resample=PIL.Image.Resampling.BICUBIC):\n",
        "    img = PIL.Image.open(_path)\n",
        "    img = img.resize((_size, _size), _resample)\n",
        "    img = np.float32(img) / 255.0\n",
        "    img[..., :3] *= img[..., 3:]\n",
        "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]\n",
        "\n",
        "# * takes the first 4 channels of a tensor of default shape and converts to a RGB image\n",
        "def to_rgb(_x, _alpha='BLACK'):\n",
        "    rgb, a = _x[:, :3], _x[:, 3:4]\n",
        "    if _alpha == 'BLACK':\n",
        "        return torch.clamp(rgb, 0.0, 1.0)\n",
        "    elif _alpha == 'WHITE':\n",
        "        return torch.clamp(1.-a + rgb, 0.0, 1.0)\n",
        "    \n",
        "# * creates a circle mask centered at a position of a given radius\n",
        "def circle_mask(_size, _radius, _pos):\n",
        "    Y, X = np.ogrid[:_size, :_size]\n",
        "    dist_from_center = np.sqrt((X - _pos[0])**2 + (Y-_pos[1])**2)\n",
        "    mask = dist_from_center >= _radius\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seeds:  ['_1_seed_64.png', '_2x2_seeds_64.png', '_2x2_seeds_64_wide.png', '_2x3_seeds_64.png', '_2_seeds_64.png', '_3_seeds_64.png']\n",
            "models:  ['gradient_cowboy_fixed_2pt_4r_state_dict', 'steerable_cowboy_fixed_2pt_4r_states', 'steerable_lizard_fixed_2pt_4r_states']\n"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "import datetime\n",
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "import torch.nn.functional as func\n",
        "import torchvision.transforms.functional as trans\n",
        "\n",
        "_PLAY_ = True\n",
        "_MODELS_DIR_ = '_states'\n",
        "_PLAY_DEVICE_ = 'cpu'\n",
        "_RADIUS_ = 8\n",
        "_SEED_SIZE_ = 64\n",
        "_PLAY_SIZE_ = 128\n",
        "_WINDOW_SCALE_ = 8\n",
        "_WINDOW_BG_COLOR_ = (0, 0, 0)\n",
        "_WINDOW_TEXT_COLOR_ = (255, 255, 255)\n",
        "\n",
        "# * set current device\n",
        "_DEVICE_ = _PLAY_DEVICE_\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "# * method to load model for play\n",
        "def load_model(_model_name):\n",
        "     # * find params from name\n",
        "    params = _model_name.split('_')\n",
        "    \n",
        "    # * set global vars\n",
        "    global MODEL_TYPE\n",
        "    global ANGLE_CHN\n",
        "    global SCALAR_CHN\n",
        "    global LOSS_FN\n",
        "    MODEL_TYPE = params[0].upper()\n",
        "    ANGLE_CHN = 1 if MODEL_TYPE == 'STEERABLE' else 0\n",
        "    SCALAR_CHN = CHN - ANGLE_CHN\n",
        "    LOSS_FN = params[2].upper()\n",
        "    \n",
        "    # * load model\n",
        "    model = CA()\n",
        "    model.load_state_dict(torch.load(os.path.join(_MODELS_DIR_, _model_name+'.pt'), map_location=_PLAY_DEVICE_))\n",
        "    model.eval()\n",
        "    \n",
        "    # * create seed and tensor\n",
        "    seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+seeds_list[curr_seed], _SEED_SIZE_)\n",
        "    pad = np.round((_PLAY_SIZE_-_SEED_SIZE_)/2.0, 0).astype(int)\n",
        "    seed_img = func.pad(seed_img, (pad, pad, pad, pad), 'constant', 0)\n",
        "    tensor = torch.cat([seed_img, seed_img[:, 3].repeat(1, 12, 1, 1).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "    # * randomize angles for steerable models\n",
        "    if params[0] == 'steerable':\n",
        "        rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "        tensor[:, -1:] = rand\n",
        "    return model, tensor, params, seed_img\n",
        "\n",
        "# * get list of seeds\n",
        "seeds_list = os.listdir('..\\\\_seeds')\n",
        "seeds_list = [item for item in seeds_list if item.endswith('.png')]\n",
        "print ('seeds: ', seeds_list)\n",
        "curr_seed = 2\n",
        "\n",
        "# * get list of models\n",
        "model_list = os.listdir(_MODELS_DIR_)\n",
        "model_list = [item.replace('.pt', '') for item in model_list if item.endswith('.pt')]\n",
        "print ('models: ', model_list)\n",
        "curr_model = 1\n",
        "\n",
        "# load first model\n",
        "model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
        "\n",
        "# * misc params\n",
        "angle = 0.0\n",
        "fps = 0\n",
        "show_vecs = False\n",
        "bg_color = 'WHITE' if _WINDOW_BG_COLOR_ == (255, 255, 255) else 'BLACK'\n",
        "prev_time = datetime.datetime.now()\n",
        "\n",
        "# * load vector image\n",
        "vec_img = cv2.imread('..\\\\_images\\\\vector_v3.png') \n",
        "vec_img = cv2.resize(vec_img, (_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
        "vec_img = vec_img.astype(float)/255.0\n",
        "\n",
        "# * start pygame\n",
        "pygame.init()\n",
        "pygame.display.set_caption('nca play - '+model_list[curr_model])\n",
        "\n",
        "# * model dependent params\n",
        "size = _PLAY_SIZE_\n",
        "window_size = size * _WINDOW_SCALE_\n",
        "window = pygame.display.set_mode((window_size, window_size))\n",
        "\n",
        "# * text renders\n",
        "font_size = 20\n",
        "my_font = pygame.font.SysFont('consolas', font_size)\n",
        "model_surface = my_font.render('[UP/DOWN] model: ' + model_list[curr_model], False, _WINDOW_TEXT_COLOR_)\n",
        "seed_surface = my_font.render('[LEFT/RIGHT] seed: ' + seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
        "text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
        "fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
        "vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
        "\n",
        "# * start infinite game loop\n",
        "running = True\n",
        "mouse_down = False\n",
        "model_start = False\n",
        "while running:\n",
        "    if not _PLAY_:\n",
        "        print ('skipping game')\n",
        "        break\n",
        "    # empty cache\n",
        "    torch.cuda.empty_cache()\n",
        "    # handle events\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.QUIT:\n",
        "            running = False\n",
        "        if event.type == pygame.KEYDOWN:\n",
        "            # * close application\n",
        "            if event.key == pygame.K_ESCAPE:\n",
        "                running = False\n",
        "                break\n",
        "            # * toggle showing vectors\n",
        "            if event.key == pygame.K_v:\n",
        "                show_vecs = not show_vecs\n",
        "                vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
        "            # * start current model\n",
        "            if event.key == pygame.K_SPACE:\n",
        "                model_start = not model_start\n",
        "            # * reset current model\n",
        "            if event.key == pygame.K_r:\n",
        "                model_start = False\n",
        "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(angle*np.pi))\n",
        "                tensor = torch.cat([seed_img_rot, seed_img_rot[:, 3].repeat(1, 12, 1, 1).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "                # * randomize angles for steerable models\n",
        "                if params[0] == 'steerable':\n",
        "                    rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "                    tensor[:, -1:] = rand\n",
        "            # * use up/down arrow keys to cycle though models\n",
        "            if event.key == pygame.K_UP:\n",
        "                    curr_model += 1\n",
        "                    if curr_model >= len(model_list):\n",
        "                        curr_model = 0\n",
        "            if event.key == pygame.K_DOWN:\n",
        "                curr_model -= 1\n",
        "                if curr_model < 0:\n",
        "                    curr_model = len(model_list)-1\n",
        "            # * load new model\n",
        "            if event.key == pygame.K_UP or event.key == pygame.K_DOWN:\n",
        "                model_start = False\n",
        "                model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
        "                pygame.display.set_caption('nca play - '+model_list[curr_model])\n",
        "                model_surface = my_font.render('[UP/DOWN] model: '+model_list[curr_model], False, _WINDOW_TEXT_COLOR_)\n",
        "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
        "            # * use left/right arrow keys to cycle though seeds\n",
        "            if event.key == pygame.K_LEFT:\n",
        "                curr_seed += 1\n",
        "                if curr_seed >= len(seeds_list):\n",
        "                    curr_seed = 0\n",
        "            if event.key == pygame.K_RIGHT:\n",
        "                curr_seed -= 1\n",
        "                if curr_seed < 0:\n",
        "                    curr_seed = len(seeds_list)-1\n",
        "            # * load new seed image\n",
        "            if event.key == pygame.K_LEFT or event.key == pygame.K_RIGHT:\n",
        "                model_start = False\n",
        "                seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+seeds_list[curr_seed], _SEED_SIZE_)\n",
        "                pad = np.round((_PLAY_SIZE_-_SEED_SIZE_)/2.0, 0).astype(int)\n",
        "                seed_img = func.pad(seed_img, (pad, pad, pad, pad), 'constant', 0)\n",
        "                tensor = torch.cat([seed_img, seed_img[:, 3].repeat(1, 12, 1, 1).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "                # * randomize angles for steerable models\n",
        "                if params[0] == 'steerable':\n",
        "                    rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "                    tensor[:, -1:] = rand\n",
        "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
        "        if event.type == pygame.MOUSEWHEEL:\n",
        "            # * let player rotate seed before starting model\n",
        "            if not model_start:\n",
        "                angle = np.round((event.y * 0.05) + angle, decimals=2)\n",
        "                text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
        "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(angle*np.pi))\n",
        "                tensor = torch.cat([seed_img_rot, seed_img_rot[:, 3].repeat(1, 12, 1, 1).to(_PLAY_DEVICE_)], 1).to(_PLAY_DEVICE_)\n",
        "                # * randomize angles for steerable models\n",
        "                if params[0] == 'steerable':\n",
        "                    rand = torch.rand(_PLAY_SIZE_, _PLAY_SIZE_)*np.pi*2.0\n",
        "                    tensor[:, -1:] = rand\n",
        "        # * mouse click events - erase and draw\n",
        "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
        "            mouse_down = True\n",
        "            if pygame.mouse.get_pressed(3)[2] and model_start:\n",
        "                mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
        "                pos = mouse / window_size * size\n",
        "                dot = np.zeros_like(tensor.detach().cpu().numpy())\n",
        "                dot[:, 3:, int(pos[1]), int(pos[0])] = 1.0\n",
        "                tensor += torch.tensor(dot).to(_PLAY_DEVICE_)\n",
        "        if event.type == pygame.MOUSEBUTTONUP:\n",
        "            mouse_down = False\n",
        "        if (event.type == pygame.MOUSEMOTION or event.type == pygame.MOUSEBUTTONDOWN) and mouse_down and model_start:\n",
        "            mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
        "            pos = mouse / window_size * size\n",
        "            if pygame.mouse.get_pressed(3)[0]:\n",
        "                mask = circle_mask(size, _RADIUS_, pos)\n",
        "                tensor[0:] *= torch.tensor(mask).to(_PLAY_DEVICE_)\n",
        "            \n",
        "    # * update tensor\n",
        "    if model_start:\n",
        "        with torch.no_grad():\n",
        "            tensor = model(tensor)\n",
        "    \n",
        "    # * draw tensor to window\n",
        "    window.fill(_WINDOW_BG_COLOR_)\n",
        "    img = to_rgb(tensor, _alpha=bg_color).squeeze()\n",
        "    vis = (np.array(img.cpu())*255).astype(np.uint8)\n",
        "    if show_vecs:\n",
        "        vecs = tensor[:, -1:].squeeze(0)\n",
        "        vecs = np.array(vecs.cpu())%(2.0*torch.pi)\n",
        "    pixel = pygame.Surface((_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
        "    for j in range(size):\n",
        "        for i in range(size):\n",
        "            color = vis[:, i, j]\n",
        "            # * create vectors for each cell\n",
        "            if show_vecs:\n",
        "                vec_dir = vecs[:, i, j]\n",
        "                vec = imutils.rotate(vec_img, angle=np.rad2deg(vec_dir).item())\n",
        "                vec *= color\n",
        "                surf = pygame.surfarray.make_surface(vec)\n",
        "                pixel.blit(surf, (0, 0))\n",
        "            # * fill cell with color\n",
        "            else:\n",
        "                pixel.fill(color)\n",
        "            draw_me = pygame.Rect(j*_WINDOW_SCALE_, i*_WINDOW_SCALE_, _WINDOW_SCALE_, _WINDOW_SCALE_)\n",
        "            window.blit(pixel, draw_me)\n",
        "    \n",
        "    # * calculate fps\n",
        "    now = datetime.datetime.now()\n",
        "    if (now - prev_time).seconds >= 1.0:\n",
        "        prev_time = now\n",
        "        fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
        "        fps = 0\n",
        "    else:\n",
        "        fps += 1       \n",
        "    \n",
        "    # * render text\n",
        "    window.blit(model_surface, (0, 0))\n",
        "    window.blit(seed_surface, (0, font_size))\n",
        "    window.blit(text_surface, (0, window_size-font_size))\n",
        "    window.blit(vec_surface, (0, window_size-font_size*2))\n",
        "    window.blit(fps_surface, (0, window_size-font_size*3))\n",
        "    \n",
        "    # * flip it!\n",
        "    pygame.display.flip()\n",
        "\n",
        "# * quit it!\n",
        "pygame.quit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
