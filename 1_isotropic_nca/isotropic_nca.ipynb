{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions\n",
    "- NOTE: tensors are organized as follows: [BATCH_SIZE, CHANNELS, WIDTH, HEIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1660 Ti (UUID: GPU-d77bcb98-b41a-4494-1c93-f4f7d0b55d9c)\n",
      "cuda available?  True\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as func\n",
    "import PIL.Image\n",
    "import random\n",
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torchvision.transforms.functional as trans\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "# * loads an image and converts to a tensor\n",
    "# *     default tensor shape: [BATCH_SIZE (1), CHANNELS (4), WIDTH (_size), HEIGHT (_size)]\n",
    "def load_image_as_tensor(_path, _size, _resample=PIL.Image.Resampling.BICUBIC):\n",
    "    img = PIL.Image.open(_path)\n",
    "    img = img.resize((_size, _size), _resample)\n",
    "    img = np.float32(img) / 255.0\n",
    "    img[..., :3] *= img[..., 3:]\n",
    "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]\n",
    "\n",
    "# * given a tensor of default shape, visualize the first 4 channels as a RGBA image\n",
    "def show_tensor_as_image(_tensor):\n",
    "    img = to_rgb(_tensor).squeeze().permute(1, 2, 0)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# * takes the first 4 channels of a tensor of default shape and converts to a RGB image\n",
    "def to_rgb(_x, _alpha='BLACK'):\n",
    "    rgb, a = _x[:, :3], _x[:, 3:4]\n",
    "    if _alpha == 'BLACK':\n",
    "        return torch.clamp(rgb, 0.0, 1.0)\n",
    "    elif _alpha == 'WHITE':\n",
    "        return torch.clamp(1.-a + rgb, 0.0, 1.0)\n",
    "\n",
    "# * creates a circle mask centered at a position of a given radius\n",
    "def circle_mask(_size, _radius, _pos):\n",
    "    Y, X = np.ogrid[:_size, :_size]\n",
    "    dist_from_center = np.sqrt((X - _pos[0])**2 + (Y-_pos[1])**2)\n",
    "    mask = dist_from_center >= _radius\n",
    "    return mask\n",
    "\n",
    "# * creates a mask for half the screen\n",
    "def half_mask(_size, _type):\n",
    "    mask_types = ['left', 'right', 'top', 'bottom']\n",
    "    if _type == 'rand':\n",
    "        _type = mask_types[np.random.randint(0, 4)]\n",
    "    mat = np.zeros([_size, _size])\n",
    "    if _type == 'left':\n",
    "        mat[:, _size//2:] = 1.0\n",
    "    elif _type == 'right':\n",
    "        mat[:, :-_size//2] = 1.0\n",
    "    elif _type == 'top':\n",
    "        mat[_size//2:, :] = 1.0\n",
    "    elif _type == 'bottom':\n",
    "        mat[:-_size//2, :] = 1.0\n",
    "    return mat\n",
    "\n",
    "# * shows a batch before and after a forward pass given two (2) tensors\n",
    "def show_batch(_batch_size, _before, _after, _dpi=256):\n",
    "    fig = plt.figure(figsize=(_batch_size, 2), dpi=_dpi)\n",
    "    axarr = fig.subplots(nrows=2, ncols=_batch_size)\n",
    "    gspec = gridspec.GridSpec(2, _batch_size)\n",
    "    gspec.update(wspace=0.1, hspace=0) # set the spacing between axes.\n",
    "    plt.clf()\n",
    "    for i in range(_batch_size):\n",
    "        img_i = _before[i].unsqueeze(0)\n",
    "        img_rgb = to_rgb(img_i, _alpha='WHITE').squeeze().permute(1, 2, 0)\n",
    "        axarr[0, i] = plt.subplot(gspec[i])\n",
    "        axarr[0, i].set_xticks([])\n",
    "        axarr[0, i].set_yticks([])\n",
    "        axarr[0, i].imshow(img_rgb, aspect='equal')\n",
    "        axarr[0, i].set_title(str(i), fontsize=8)   \n",
    "    for i in range(_batch_size):\n",
    "        img_i = _after[i].unsqueeze(0)\n",
    "        img_rgb = to_rgb(img_i, _alpha='WHITE').squeeze().permute(1, 2, 0)\n",
    "        axarr[1, i] = plt.subplot(gspec[i+_batch_size])\n",
    "        axarr[1, i].set_xticks([])\n",
    "        axarr[1, i].set_yticks([])\n",
    "        axarr[1, i].imshow(img_rgb, aspect='equal') \n",
    "    plt.show()\n",
    "\n",
    "# * find GPU available\n",
    "clear_output()\n",
    "!nvidia-smi -L\n",
    "\n",
    "# * sets the device\n",
    "# *     defaults to 'cuda'\n",
    "_DEVICE_ = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print ('cuda available? ', torch.cuda.is_available())\n",
    "print ('device: ', _DEVICE_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment block\n",
    "\n",
    "# img = load_image_as_tensor('..\\\\_images\\\\'+'cowboy.png', 40)\n",
    "# img = func.pad(img, (12, 12, 12, 12), 'constant', 0)\n",
    "\n",
    "# mask = half_mask(64, 'rand')\n",
    "# img = img * torch.tensor(mask, dtype=torch.int64)\n",
    "# print ('random half mask:')\n",
    "# show_tensor_as_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pre-Made Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_img.shape:  torch.Size([1, 4, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE90lEQVR4nO3bIQ7EMAwAweTU/3/ZxxaHRC2YwQZmKwPvmZkFAGut39sLAPAdogBARAGAiAIAEQUAIgoARBQAiCgAkOd0cO99cw8ALjv5VXYpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQ53RwZm7uAcAHuBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMgfGXENBwN97qoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE+ElEQVR4nO3aIQ7DQAwAwbuq//+yQ6pVQHEuYAYama0sec/MLABYa31OLwDAe4gCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgHxPLwBvsff+O5+ZhzeBc1wKAEQUAIgoABBRACCiAEB8H8GPLyNwKQBwIwoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQCzzPDQelRyLXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_SEED_FILE_ = '_1_seed_64.png'\n",
    "_SIZE_ = 64\n",
    "_SEED_ANGLE_RAD_ = (0)*np.pi\n",
    "\n",
    "seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+_SEED_FILE_,  _SIZE_)\n",
    "seed_img = trans.rotate(seed_img, np.rad2deg(_SEED_ANGLE_RAD_))\n",
    "print ('seed_img.shape: ', seed_img.shape)\n",
    "show_tensor_as_image(to_rgb(seed_img))\n",
    "show_tensor_as_image(to_rgb(seed_img, 'WHITE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Image to Train Model\n",
    "- NOTE: seed _SIZE_ should equal _TARGET-SIZE_ + (2 * _PAD_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_img.shape:  torch.Size([1, 4, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_TARGET_FILE_ = 'cowboy.png'\n",
    "_TARGET_SIZE_ = 40\n",
    "_PAD_ = 12\n",
    "\n",
    "target_img = load_image_as_tensor('..\\\\_images\\\\'+_TARGET_FILE_, _TARGET_SIZE_)\n",
    "target_img = func.pad(target_img, (_PAD_, _PAD_, _PAD_, _PAD_), 'constant', 0)\n",
    "print ('target_img.shape: ', target_img.shape)\n",
    "show_tensor_as_image(target_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptions:\n",
    "- LAPLACIAN: isotropic nca model\n",
    "- SOBEL_MAG: isotrpic nca variant which adds upon the 'laplacian' model by making use of the magnitude of the two directional sobel filters\n",
    "- ANGLE_STEER: angle-based steerable nca\n",
    "- GRAD_STEER: gradient-based steerable nca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SOBEL_DIV_ = 1.0\n",
    "_LAP_DIV_ = 1.0\n",
    "\n",
    "SOBEL_KERN = torch.tensor([\n",
    "    [-1., 0., 1.], \n",
    "    [-2., 0., 2.], \n",
    "    [-1., 0., 1.]])\n",
    "LAP_KERN = torch.tensor([\n",
    "    [1.,   2., 1.], \n",
    "    [2., -12., 2.], \n",
    "    [1.,   2., 1.]])\n",
    "ID_KERN = torch.tensor([\n",
    "    [0., 0., 0.], \n",
    "    [0., 1., 0.], \n",
    "    [0., 0., 0.]])\n",
    "\n",
    "# * performs a convolution per filter per channel\n",
    "def per_channel_conv(_x, _filters):\n",
    "    batch_size, channels, height, width = _x.shape\n",
    "    # * reshape x to make per-channel convolution possible + pad 1 on each side\n",
    "    y = _x.reshape(batch_size*channels, 1, height, width)\n",
    "    y = func.pad(y, (1, 1, 1, 1), 'circular')\n",
    "    # send to current device\n",
    "    _filters = _filters.to(_DEVICE_)\n",
    "    y = y.to(_DEVICE_)\n",
    "    # * perform per-channel convolutions\n",
    "    y = func.conv2d(y, _filters[:, None])\n",
    "    y = y.reshape(batch_size, -1, height, width)\n",
    "    return y\n",
    "\n",
    "# * only uses laplacian operator for local perception\n",
    "def laplacian_perception(_x):\n",
    "    # * add an extra dimention to account for batch size\n",
    "    lap_conv = per_channel_conv(_x, LAP_KERN[None, :]/_LAP_DIV_)\n",
    "    # * concat perception w/ self (identity)\n",
    "    y = torch.cat([_x, lap_conv], 1)\n",
    "    return y\n",
    "\n",
    "# * uses laplacian operator and sobel-magnitude (G) for local perception\n",
    "def sobel_mag_perception(_x):\n",
    "    # * add an extra dimention to account for batch size\n",
    "    lap_conv = per_channel_conv(_x, LAP_KERN[None, :]/_LAP_DIV_)\n",
    "    # * compute sobel-magnitude (G)\n",
    "    sobel_conv = per_channel_conv(_x, torch.stack([SOBEL_KERN/_SOBEL_DIV_, SOBEL_KERN.T/_SOBEL_DIV_]))\n",
    "    gx, gy = sobel_conv[:, ::2], sobel_conv[:, 1::2]\n",
    "    # * concat perceptions w/ self (identity)\n",
    "    y = torch.cat([_x, lap_conv, (gx*gx+gy*gy+1e-8).sqrt()], 1)\n",
    "    return y\n",
    "\n",
    "def angle_steerable_perception(_x):\n",
    "    # * separate states and angle channels\n",
    "    states, angle = _x[:, :-1], _x[:, -1:]\n",
    "    # * compute lap, gx and gy\n",
    "    lap_conv = per_channel_conv(states, LAP_KERN[None, :]/_LAP_DIV_).to(_DEVICE_)\n",
    "    gx = per_channel_conv(states, SOBEL_KERN[None, :]/_SOBEL_DIV_).to(_DEVICE_)\n",
    "    gy = per_channel_conv(states, SOBEL_KERN.T[None, :]/_SOBEL_DIV_).to(_DEVICE_)\n",
    "    # * compute px and py \n",
    "    _cos, _sin = angle.cos(), angle.sin()\n",
    "    px = (gx*_cos)+(gy*_sin)\n",
    "    py = (gy*_cos)-(gx*_sin)\n",
    "    # * concat and return\n",
    "    y = torch.cat([states, lap_conv, px, py], 1)\n",
    "    return y\n",
    "\n",
    "# * copy of paper's perception for testing\n",
    "def copy_steerable_perception(x):\n",
    "    state, angle = x[:, :-1], x[:, -1:]\n",
    "    c, s = angle.cos(), angle.sin()\n",
    "    filters = torch.stack([SOBEL_KERN, SOBEL_KERN.T])\n",
    "    grad = per_channel_conv(state, filters)\n",
    "    gx, gy = grad[:, ::2], grad[:, 1::2]\n",
    "    rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
    "    state_lap = per_channel_conv(state, LAP_KERN[None, :])\n",
    "    res = torch.cat([state, rot_grad, state_lap], 1)\n",
    "    return res\n",
    "\n",
    "def gradient_steerable_perception(_x):\n",
    "    # * compute sobel x/y convolutions\n",
    "    filters = torch.stack([SOBEL_KERN/_SOBEL_DIV_, SOBEL_KERN.T/_SOBEL_DIV_])\n",
    "    grad = per_channel_conv(_x, filters)\n",
    "    # * extract grad and dir\n",
    "    grad, dir = grad[:, :-2], grad[:, -2:]\n",
    "    dir = dir / dir.norm(dim=1, keepdim=True).clip(1.0)\n",
    "    gx, gy = grad[:, ::2], grad[:, 1::2]\n",
    "    # * rotate gx and gy using sin/cos of dir\n",
    "    _cos, _sin = dir[:, :1], dir[:, 1::2]\n",
    "    rot_grad = torch.cat([gx*_cos+gy*_sin, gy*_cos-gx*_sin], 1)\n",
    "    lap_conv = per_channel_conv(_x, LAP_KERN[None, :])\n",
    "    # * concat and return\n",
    "    y = torch.cat([_x, lap_conv, rot_grad], 1)\n",
    "    return y\n",
    "    \n",
    "perception = {\n",
    "    'LAPLACIAN': laplacian_perception,\n",
    "    'SOBEL_MAG': sobel_mag_perception,\n",
    "    'ANGLE_STEER': angle_steerable_perception,\n",
    "    'CARBON_COPY_STEER': copy_steerable_perception,\n",
    "    'GRADIENT': gradient_steerable_perception,\n",
    "}\n",
    "\n",
    "def get_alive_mask(_x):\n",
    "    return func.max_pool2d(_x[:, 3:4, :, :], kernel_size=3, stride=1, padding=1) > 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isotropic Neural Cellular Automata Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISO-NCA param count: 9856\n",
      "is steerable? True\n"
     ]
    }
   ],
   "source": [
    "_CHANNELS_ = 16\n",
    "_HIDDEN_ = 128\n",
    "_MODEL_TYPE_ = 'ANGLE_STEER'  #'LAPLACIAN', 'SOBEL_MAG', 'ANGLE_STEER', 'GRADIENT'\n",
    "_ANGLE_CHANNEL_ = 'DIRECTION' #'RANDOMIZED' \n",
    "_IS_STEERABLE_ = True if 'STEER' in _MODEL_TYPE_ else False\n",
    "_STOCHASTIC_UPDATE_RATE_ = 0.5\n",
    "\n",
    "class ISO_NCA(torch.nn.Module):\n",
    "    def __init__(self, _channels=_CHANNELS_, _hidden=_HIDDEN_, _device=_DEVICE_, _model_type=_MODEL_TYPE_):\n",
    "        super().__init__()\n",
    "        self.device = _device\n",
    "        _MODEL_TYPE_=_model_type\n",
    "\n",
    "        # * determine number of perceived channels\n",
    "        perception_channels = perception[_MODEL_TYPE_](torch.zeros([1, _channels, 8, 8]).to(_device)).shape[1]\n",
    "        \n",
    "        # * determine hidden channels (equalize the parameter count btwn model types)\n",
    "        hidden_channels = 8*1024 // (perception_channels+_channels)\n",
    "        hidden_channels = (_hidden+31) // 32*32\n",
    "        \n",
    "        # * model layers\n",
    "        self.conv1 = torch.nn.Conv2d(perception_channels, hidden_channels, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(hidden_channels, _channels, 1, bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.conv2.weight.data.zero_()\n",
    "        \n",
    "        # * send to device\n",
    "        self.to(_device)\n",
    "        \n",
    "    def forward(self, _x):\n",
    "        # * get alive mask\n",
    "        alive_mask = get_alive_mask(_x).to(self.device)\n",
    "        \n",
    "        # * perception step\n",
    "        _x = _x.to(self.device)\n",
    "        p = perception[_MODEL_TYPE_](_x)\n",
    "        \n",
    "        # * update step\n",
    "        p = self.conv2(torch.relu(self.conv1(p)))\n",
    "        \n",
    "        # * create stochastic update mask\n",
    "        stochastic_mask = (torch.rand(_x[:, :1, :, :].shape) <= _STOCHASTIC_UPDATE_RATE_).to(self.device, torch.float32)\n",
    "        \n",
    "        # * perform update\n",
    "        _x = _x + p * stochastic_mask\n",
    "        if _IS_STEERABLE_:\n",
    "            states = _x[:, :-1]*alive_mask\n",
    "            angle = _x[:, -1:] % (np.pi*2.0)\n",
    "            _x = torch.cat([states, angle], 1)\n",
    "        else:\n",
    "            _x = _x * alive_mask\n",
    "        return _x\n",
    "\n",
    "# * print model parameter count\n",
    "param_n = sum(p.numel() for p in ISO_NCA().parameters())\n",
    "print('ISO-NCA param count:', param_n)\n",
    "print ('is steerable? '+str(_IS_STEERABLE_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to create videos from NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Notebook Utilities and Setup\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pylab as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
    "import requests\n",
    "import torch\n",
    "import torchvision.transforms.functional as T\n",
    "from colorsys import hsv_to_rgb\n",
    "# from google.colab import drive, output\n",
    "from IPython.display import clear_output, Image\n",
    "from tqdm.notebook import tnrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
    "import moviepy.editor as mvp\n",
    "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
    "\n",
    "def imread(url, max_size=None, mode=None):\n",
    "  if url.startswith(('http:', 'https:')):\n",
    "    headers = {'User-Agent': 'Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    f = io.BytesIO(r.content)\n",
    "  else:\n",
    "    f = url\n",
    "  img = PIL.Image.open(f)\n",
    "  if max_size is not None:\n",
    "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
    "  if mode is not None:\n",
    "    img = img.convert(mode)\n",
    "  img = np.float32(img) / 255.\n",
    "  return img\n",
    "\n",
    "def np2pil(a):\n",
    "  if a.dtype in (np.float32, np.float64):\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None, quality=95):\n",
    "  a = np.asarray(a)\n",
    "  if isinstance(f, str):\n",
    "    fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "      fmt = 'jpeg'\n",
    "    f = open(f, 'wb')\n",
    "  np2pil(a).save(f, fmt, quality=quality)\n",
    "\n",
    "def imencode(a, fmt='jpeg'):\n",
    "  a = np.asarray(a)\n",
    "  if a.ndim == 3 and a.shape[-1] == 4:\n",
    "    fmt = 'png'\n",
    "  f = io.BytesIO()\n",
    "  imwrite(f, a, fmt)\n",
    "  return f.getvalue()\n",
    "\n",
    "def im2url(a, fmt='jpeg'):\n",
    "  encoded = imencode(a, fmt)\n",
    "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
    "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
    "\n",
    "def zoom(img, scale=4):\n",
    "  img = np.repeat(img, scale, 0)\n",
    "  img = np.repeat(img, scale, 1)\n",
    "  return img\n",
    "\n",
    "def imshow(a, fmt='jpeg', scale=4):\n",
    "  display(Image(data=imencode(zoom(a, scale), fmt)))\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "  a = np.asarray(a)\n",
    "  if w is None:\n",
    "    w = int(np.ceil(np.sqrt(a.shape[0])))\n",
    "  th, tw = a.shape[1:3]\n",
    "  pad = (w - a.shape[0]) % w\n",
    "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
    "  h = a.shape[0] // w\n",
    "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
    "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
    "  return a\n",
    "\n",
    "def to_rgb_copy(x):\n",
    "  rgb, a = x[:, :3], x[:, 3:4]\n",
    "  return 1. - a + rgb\n",
    "\n",
    "def grab_plot(close=True):\n",
    "  fig = pl.gcf()\n",
    "  fig.canvas.draw()\n",
    "  img = np.array(fig.canvas.renderer._renderer)\n",
    "  a = np.float32(img[..., 3:]/255.)\n",
    "  img = np.uint8(255*(1.-a)+img[..., :3]*a)\n",
    "  if close:\n",
    "    pl.close()\n",
    "  return img\n",
    "\n",
    "def vis_angle(x, w):\n",
    "  m = get_alive_mask(x).cpu()\n",
    "  rgb = to_rgb_copy(x)[0].clip(0, 1).permute(1, 2, 0).cpu()\n",
    "  ang, a, m = x[0, -1].cpu(), x[0, 3].cpu(), m[0,0]\n",
    "  c, s = ang.cos() * a, ang.sin() * a\n",
    "  px, py = np.mgrid[-1:1:w*1j, -1:1:w*1j]\n",
    "  pl.figure(figsize=(10, 10))\n",
    "  pl.axis('equal')\n",
    "  pl.xlim(-0.8, 0.8); pl.ylim(-0.8,0.8)\n",
    "  pl.quiver(px[m], py[m], c[m], s[m], color=rgb[m], pivot='mid', scale_units='xy', units='xy', scale=_SIZE_/3)\n",
    "  pl.tight_layout()\n",
    "  pl.axis('off')\n",
    "  return grab_plot()\n",
    "\n",
    "class VideoWriter:\n",
    "  def __init__(self, filename='_autoplay.mp4', fps=30., **kwargs):\n",
    "    self.writer = None\n",
    "    self.params = dict(filename=filename, fps=fps, **kwargs)\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "  \n",
    "  def __exit__(self, *args):\n",
    "    self.close()\n",
    "    if self.params['filename'] == '_autoplay.mp4':\n",
    "      self.show()\n",
    "\n",
    "  def add(self, img):\n",
    "    img = np.asarray(img)\n",
    "    if self.writer is None:\n",
    "      h, w = img.shape[:2]\n",
    "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
    "    if img.dtype in (np.float32, np.float64):\n",
    "      img = np.uint8(img.clip(0, 1)*255)\n",
    "    if img.ndim == 2:\n",
    "      img = np.repeat(img[..., None], 3, -1)\n",
    "    self.writer.write_frame(img)\n",
    "\n",
    "  def close(self):\n",
    "    if self.writer is not None:\n",
    "      self.writer.close()\n",
    "\n",
    "  def show(self, **kwargs):\n",
    "    self.close()\n",
    "    fn = self.params['filename']\n",
    "    display(mvp.ipython_display(fn, **kwargs))\n",
    "    \n",
    "def rgb_linspace(n):\n",
    "  '''Generates n visually distinct rgb combinations'''\n",
    "  if n == 1:\n",
    "    return torch.tensor([0.0, 0.0, 0.0], dtype=torch.float32)\n",
    "  return torch.tensor([hsv_to_rgb(i / n, 1.0, 1.0) for i in range(n)], dtype=torch.float32)\n",
    "\n",
    "def rotate_n(x, n, min=0., max=360.):\n",
    "  a = np.linspace(0., 360., n)\n",
    "  for i, a in zip(range(n), a):\n",
    "    x[i] = T.rotate(x[i], a)\n",
    "    # * set direction of growth\n",
    "    if _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "      r = np.deg2rad(a)\n",
    "      print ('r:',r)\n",
    "      x[:, -1] = r\n",
    "  return x\n",
    "\n",
    "def generate_seed(n, sz=128, p=2, r=4, xy=None, angle=0., flip=False, rgb_dist=rgb_linspace):\n",
    "    '''Generates a uniform p-point structured seed of radius r'''\n",
    "    x = torch.zeros(n, _CHANNELS_, sz, sz)\n",
    "    if _IS_STEERABLE_:\n",
    "    # * randomize angles for steerable models\n",
    "      if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "        x[:, -1] = torch.rand(n, sz, sz) * np.pi * 2.\n",
    "    # Initialize p points equidistant around a circle of radius r\n",
    "    t = np.linspace(0, 2 * np.pi, p, endpoint=False)\n",
    "    if xy is None:\n",
    "        xy = (np.c_[r*np.cos(t), r*np.sin(t)]+(sz//2)).astype(np.int32).T\n",
    "    # Assign distinct rgb values to each point\n",
    "    if _IS_STEERABLE_:\n",
    "        SCALAR_CHN = _CHANNELS_-1\n",
    "    else:\n",
    "        SCALAR_CHN = _CHANNELS_\n",
    "    x[:, :3, xy[0], xy[1]] = rgb_dist(xy.shape[1]).T\n",
    "    x[:, 3:SCALAR_CHN, xy[0], xy[1]] = 1.0\n",
    "    x = rotate_n(x, n) if angle is None else T.rotate(x, angle)\n",
    "    if flip:\n",
    "        x = torch.flip(x, [3])\n",
    "    return x\n",
    "\n",
    "def vidgen(filename, model, n_frames=500, max_speed=128, n=16, sz=72, p=2, r=4, angle=None):\n",
    "  with VideoWriter(filename=filename) as vid, torch.no_grad():\n",
    "    x = generate_seed(n, sz, p, r, angle=angle)\n",
    "    for i in tnrange(n_frames, leave=False):\n",
    "        img = to_rgb(x).permute(0, 2, 3, 1).cpu()\n",
    "        vid.add(zoom(tile2d(img), 2))\n",
    "        step_n = min(2**(i//30), max_speed)\n",
    "        for _ in range(step_n):\n",
    "            x = model(x)\n",
    "    vid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOSS_FUNC_ = 'PIXEL_WISE' #['PIXEL_WISE', 'INVARIANT']\n",
    "\n",
    "# * used for carbon-copy loss func\n",
    "copy_target = target_img.squeeze(0).to(_DEVICE_)\n",
    "\n",
    "# r = torch.linspace(0.5/_SIZE_, 1, _SIZE_//2.0)[:, None]\n",
    "# a = torch.range(0, _SIZE_*np.pi)/(_SIZE_/2)\n",
    "# polar_xy = torch.stack([r*a.cos(), r*a.sin()], -1)[None, :]\n",
    "# polar_target = func.grid_sample(unsharpen(target_img[None, ...]), polar_xy)\n",
    "\n",
    "# x = torch.linspace(-1, 1, _SIZE_)\n",
    "# y, x = torch.meshgrid(x, x)\n",
    "# xy_grid = torch.stack([x, y], -1)\n",
    "# fft_target = torch.fft.rfft(polar_target).conj()\n",
    "# polar_target_sqnorm = polar_target.square().sum(-1, keepdim=True)\n",
    "\n",
    "def pixel_wise_loss_func(_x, _target, _scale=1e3, _dims=[]):\n",
    "    return _scale * torch.mean(torch.square(_x[:, :4] - _target), _dims)\n",
    "\n",
    "def carbon_copy_fixed_loss_func(x, scale=1e3, ax=[]):\n",
    "    return scale * torch.mean(torch.square(x[:, :4] - copy_target[:4]), ax)\n",
    "\n",
    "# def invariant_losses_func(_x):\n",
    "#     img = unsharpen(_x)\n",
    "#     polar_img = func.grid_sample(img, polar_xy.repeat(len(img), 1, 1, 1), mode='bicubic')\n",
    "#     x = torch.fft.rfft(polar_img)\n",
    "#     xy = torch.fft.irfft(x*fft_target)\n",
    "#     xx = polar_img.square().sum(-1, keepdim=True)\n",
    "#     yy = polar_target_sqnorm\n",
    "#     diff = xx+yy-2.0*xy\n",
    "#     return diff.mean([1, 2])\n",
    "\n",
    "def invariant_loss_func(_x):\n",
    "    raise NotImplementedError\n",
    "    # return invariant_losses_func(_x).min(-1)[0].mean()\n",
    "\n",
    "loss_func = {\n",
    "    'PIXEL_WISE': pixel_wise_loss_func,\n",
    "    'INVARIANT': invariant_loss_func,\n",
    "    'CARBON_COPY': carbon_copy_fixed_loss_func\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ISO-NCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NAME_ = 'angle_steer_direction_cowboy_1_seed_v0'\n",
    "_POOL_SIZE_ = 256\n",
    "_BATCH_SIZE_ = 8\n",
    "_LOWER_LR_ = 1e-5\n",
    "_UPPER_LR_ = 1e-3\n",
    "\n",
    "# * create model / optimizer / lr-scheduler\n",
    "model = ISO_NCA()\n",
    "opt = torch.optim.Adam(model.parameters(), _UPPER_LR_)\n",
    "lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, _LOWER_LR_, _UPPER_LR_, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n",
    "\n",
    "# * create target batch\n",
    "target_batch = target_img.clone().repeat(_BATCH_SIZE_, 1, 1, 1).to(_DEVICE_)\n",
    "\n",
    "# * create seed\n",
    "seed = torch.cat([seed_img, seed_img[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "\n",
    "# * create training pool\n",
    "with torch.no_grad():\n",
    "    pool = seed.clone().repeat(_POOL_SIZE_, 1, 1, 1)\n",
    "    if _IS_STEERABLE_:\n",
    "        # * randomize angles for steerable models\n",
    "        if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "            for i in range(_POOL_SIZE_):\n",
    "                rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                pool[i, -1:] = rand\n",
    "        # * set direction of growth\n",
    "        elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "            for i in range(_POOL_SIZE_):\n",
    "                pool[i, -1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ISO-NCA Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "load_from = '_checkpoints\\\\angle_steer_direction_cowboy_1_seed_v0_cp5000'\n",
    "\n",
    "def load_model_checkpoint():\n",
    "    if not load_model: \n",
    "        return\n",
    "\n",
    "    # * open params json file\n",
    "    params = {}\n",
    "    with open(load_from + '_params.json', 'r') as openfile:\n",
    "        params = json.load(openfile)\n",
    "    \n",
    "    # * load in params\n",
    "    _DEVICE_ = params['_DEVICE_']\n",
    "    _SEED_FILE_ = params['_SEED_FILE_']\n",
    "    _SIZE_ = params['_SIZE_']\n",
    "    _SEED_ANGLE_RAD_ = params['_SEED_ANGLE_RAD_']\n",
    "    _NAME_ = params['_NAME_']\n",
    "    _MODEL_TYPE_ = params['_MODEL_TYPE_']\n",
    "    _IS_STEERABLE_ = params['_IS_STEERABLE_']\n",
    "    _ANGLE_CHANNEL_ = params['_ANGLE_CHANNEL_']\n",
    "    _POOL_SIZE_ = params['_POOL_SIZE_']\n",
    "    _TARGET_FILE_ = params['_TARGET_FILE_']\n",
    "    _TARGET_SIZE_ = params['_TARGET_SIZE_']\n",
    "    _PAD_ = params['_PAD_']\n",
    "    _SOBEL_DIV_ = params['_SOBEL_DIV_']\n",
    "    _LAP_DIV_ = params['_LAP_DIV_']\n",
    "    _BATCH_SIZE_ = params['_BATCH_SIZE_']\n",
    "    _LOWER_LR_ = params['_LOWER_LR_']\n",
    "    _UPPER_LR_ = params['_UPPER_LR_']\n",
    "    _LOSS_FUNC_ = params['_LOSS_FUNC_']\n",
    "    \n",
    "    # * load state dictionary\n",
    "    model.load_state_dict(torch.load(load_from + '.pt', map_location=_DEVICE_))   \n",
    "    model.train()\n",
    "\n",
    "    # * load seed\n",
    "    seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+_SEED_FILE_, _SIZE_)\n",
    "    seed_img = trans.rotate(seed_img, np.rad2deg(_SEED_ANGLE_RAD_))\n",
    "    seed = torch.cat([seed_img, seed_img[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "    \n",
    "    # * create training pool\n",
    "    with torch.no_grad():\n",
    "        pool = seed.clone().repeat(_POOL_SIZE_, 1, 1, 1)\n",
    "        # * randomize angles for steerable models\n",
    "        if _IS_STEERABLE_:\n",
    "            # * randomize angles for steerable models\n",
    "            if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "                for i in range(_POOL_SIZE_):\n",
    "                    rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                    pool[i, -1:] = rand\n",
    "            # * set direction of growth\n",
    "            elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                for i in range(_POOL_SIZE_):\n",
    "                    pool[i, -1:] = 0\n",
    "        \n",
    "    # * load target\n",
    "    target_img = load_image_as_tensor('..\\\\_images\\\\'+_TARGET_FILE_, _TARGET_SIZE_)\n",
    "    target_img = torch.nn.functional.pad(target_img, (_PAD_, _PAD_, _PAD_, _PAD_), 'constant', 0)\n",
    "    target_batch = target_img.clone().repeat(_BATCH_SIZE_, 1, 1, 1).to(_DEVICE_)\n",
    "    \n",
    "    # * setup loss function etc.\n",
    "    opt = torch.optim.Adam(model.parameters(), _UPPER_LR_)\n",
    "    lr_sched = torch.optim.lr_scheduler.CyclicLR(opt, _LOWER_LR_, _UPPER_LR_, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n",
    "    \n",
    "    print ('model loaded in successfully')\n",
    "\n",
    "load_model_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2048x512 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \tloss: 45.42992401123047 \tmin-loss: 45.42992401123047 \tlr: 1.0495000000000166e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5001 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [3] cannot be broadcast to indexing result of shape [16, 3, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\1_isotropic_nca\\isotropic_nca.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m         \u001b[39m# * create video\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m _VIDEO_RATE_ \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m             vidgen(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_videos/\u001b[39;49m\u001b[39m{\u001b[39;49;00m_NAME_\u001b[39m}\u001b[39;49;00m\u001b[39m_cp\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m.mp4\u001b[39;49m\u001b[39m'\u001b[39;49m, model, p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, n_frames\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, sz\u001b[39m=\u001b[39;49m_SIZE_)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m \u001b[39m# * save final model\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m \u001b[39mif\u001b[39;00m _TRAIN_MODEL_:\n",
      "\u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\1_isotropic_nca\\isotropic_nca.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvidgen\u001b[39m(filename, model, n_frames\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, max_speed\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, sz\u001b[39m=\u001b[39m\u001b[39m72\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, r\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, angle\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m   \u001b[39mwith\u001b[39;00m VideoWriter(filename\u001b[39m=\u001b[39mfilename) \u001b[39mas\u001b[39;00m vid, torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m     x \u001b[39m=\u001b[39m generate_seed(n, sz, p, r, angle\u001b[39m=\u001b[39;49mangle)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tnrange(n_frames, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m         img \u001b[39m=\u001b[39m to_rgb(x)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n",
      "\u001b[1;32mc:\\Users\\Marco\\Documents\\GitHub\\neural-cellular-automata\\1_isotropic_nca\\isotropic_nca.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m     SCALAR_CHN \u001b[39m=\u001b[39m _CHANNELS_\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m x[:, :\u001b[39m3\u001b[39;49m, xy[\u001b[39m0\u001b[39;49m], xy[\u001b[39m1\u001b[39;49m]] \u001b[39m=\u001b[39m rgb_dist(xy\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mT\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m x[:, \u001b[39m3\u001b[39m:SCALAR_CHN, xy[\u001b[39m0\u001b[39m], xy[\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Marco/Documents/GitHub/neural-cellular-automata/1_isotropic_nca/isotropic_nca.ipynb#X26sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m x \u001b[39m=\u001b[39m rotate_n(x, n) \u001b[39mif\u001b[39;00m angle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m T\u001b[39m.\u001b[39mrotate(x, angle)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [3] cannot be broadcast to indexing result of shape [16, 3, 1]"
     ]
    }
   ],
   "source": [
    "_TRAIN_MODEL_ = True\n",
    "_EPOCHS_ = 5_000\n",
    "_NUM_DAMG_ = 4\n",
    "_DAMG_RATE_ = 2\n",
    "_INFO_RATE_ = 500\n",
    "_SAVE_RATE_ = 5000\n",
    "_VIDEO_RATE_ = 5000\n",
    "\n",
    "# * save model method\n",
    "def save_model(_dir, _model, _name):\n",
    "    model_path = pathlib.Path(_dir)\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(_model.state_dict(), _dir + '\\\\' + _name + '.pt')\n",
    "    \n",
    "    # * save model parameters\n",
    "    dict = {\n",
    "        # seed info\n",
    "        '_SEED_FILE_': _SEED_FILE_,\n",
    "        '_SIZE_': _SIZE_,\n",
    "        '_SEED_ANGLE_RAD_':_SEED_ANGLE_RAD_,\n",
    "        # target image info\n",
    "        '_TARGET_FILE_': _TARGET_FILE_,\n",
    "        '_TARGET_SIZE_': _TARGET_SIZE_,\n",
    "        '_PAD_': _PAD_,\n",
    "        # kernel dividers\n",
    "        '_SOBEL_DIV_': _SOBEL_DIV_,\n",
    "        '_LAP_DIV_': _LAP_DIV_,\n",
    "        # model info\n",
    "        '_CHANNELS_': _CHANNELS_,\n",
    "        '_HIDDEN_': _HIDDEN_,\n",
    "        '_MODEL_TYPE_': _MODEL_TYPE_,\n",
    "        '_IS_STEERABLE_': _IS_STEERABLE_,\n",
    "        '_ANGLE_CHANNEL_': _ANGLE_CHANNEL_,\n",
    "        '_STOCHASTIC_UPDATE_RATE_': _STOCHASTIC_UPDATE_RATE_,\n",
    "        # loss/lr info\n",
    "        '_LOSS_FUNC_': _LOSS_FUNC_,\n",
    "        '_LOWER_LR_': _LOWER_LR_,\n",
    "        '_UPPER_LR_': _UPPER_LR_,\n",
    "        # training info\n",
    "        '_DEVICE_': _DEVICE_,\n",
    "        '_NAME_': _NAME_,\n",
    "        '_EPOCHS_': _EPOCHS_,\n",
    "        '_POOL_SIZE_': _POOL_SIZE_,\n",
    "        '_BATCH_SIZE_': _BATCH_SIZE_,\n",
    "        '_NUM_DAMG_': _NUM_DAMG_,\n",
    "        # training rate info\n",
    "        '_DAMG_RATE_': _DAMG_RATE_,\n",
    "        '_INFO_RATE_': _INFO_RATE_,\n",
    "        '_SAVE_RATE_': _SAVE_RATE_,\n",
    "    }\n",
    "    json_object = json.dumps(dict, indent=4)\n",
    "    with open(_dir + '\\\\' + _name + '_params.json', 'w') as outfile:\n",
    "        outfile.write(json_object)\n",
    "    print ('model + params saved!')\n",
    "\n",
    "loss_log = []\n",
    "progress = 0\n",
    "\n",
    "# * begin training \n",
    "for _ in tqdm(range(_EPOCHS_+1)):\n",
    "    if not _TRAIN_MODEL_:\n",
    "        print ('skipping training')\n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        # * sample batch from pool\n",
    "        i = len(loss_log)\n",
    "        batch_idxs = np.random.choice(_POOL_SIZE_, _BATCH_SIZE_, replace=False)\n",
    "        x = pool[batch_idxs]\n",
    "        \n",
    "        # * re-order batch based on loss\n",
    "        loss_ranks = torch.argsort(loss_func[_LOSS_FUNC_](x, target_batch, _dims=[-2, -3, -1]), descending=True)\n",
    "        x = x[loss_ranks]\n",
    "        \n",
    "        # * re-add seed into batch\n",
    "        x[:1] = seed\n",
    "\n",
    "        # * randomize angles for steerable models\n",
    "        if _IS_STEERABLE_:\n",
    "            # * randomize angles for steerable models\n",
    "            if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "                for j in range(_POOL_SIZE_):\n",
    "                    rand = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                    pool[j, -1:] = rand\n",
    "            # * set direction of growth\n",
    "            elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                for j in range(_POOL_SIZE_):\n",
    "                    pool[j, -1:] = 0\n",
    "            \n",
    "        # * damage lowest loss in batch\n",
    "        if i % _DAMG_RATE_ == 0:\n",
    "            # * use random half mask\n",
    "            if i % 10 == 0:\n",
    "                mask = half_mask(_SIZE_, 'rand')\n",
    "            # * use random circle mask\n",
    "            else:\n",
    "                radius = random.uniform(_SIZE_*0.05, _SIZE_*0.2)\n",
    "                u = random.uniform(0, 1) * _SIZE_\n",
    "                v = random.uniform(0, 1) * _SIZE_\n",
    "                mask = circle_mask(_SIZE_, radius, [u, v])\n",
    "            x[-_NUM_DAMG_:] *= torch.tensor(mask).to(_DEVICE_)\n",
    "            \n",
    "    # * save batch before\n",
    "    if i % _INFO_RATE_ == 0:\n",
    "        before = x.detach().cpu()\n",
    "\n",
    "    # * different loss values\n",
    "    overflow_loss = 0.0\n",
    "    diff_loss = 0.0\n",
    "    target_loss = 0.0\n",
    "    \n",
    "    # * forward pass\n",
    "    num_steps = np.random.randint(64, 96)\n",
    "    for _ in range(num_steps):\n",
    "        prev_x = x\n",
    "        x = model(x)\n",
    "        diff_loss += (x - prev_x).abs().mean()\n",
    "        if _IS_STEERABLE_:\n",
    "            overflow_loss += (x - x.clamp(-2.0, 2.0))[:, :_CHANNELS_-1].square().sum()\n",
    "        else:\n",
    "            overflow_loss += (x - x.clamp(-2.0, 2.0))[:, :_CHANNELS_].square().sum()\n",
    "    \n",
    "    # * calculate losses\n",
    "    target_loss += loss_func[_LOSS_FUNC_](x, target_batch)\n",
    "    target_loss /= 2.0\n",
    "    diff_loss *= 10.0\n",
    "    loss = target_loss + overflow_loss + diff_loss\n",
    "\n",
    "    \n",
    "    # * backward pass\n",
    "    with torch.no_grad():\n",
    "        loss.backward()\n",
    "        # * normalize gradients \n",
    "        for p in model.parameters():\n",
    "            p.grad /= (p.grad.norm()+1e-8) \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        lr_sched.step()\n",
    "        # * re-add batch to pool\n",
    "        pool[batch_idxs] = x\n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        # * print out info\n",
    "        if i % _INFO_RATE_ == 0:\n",
    "            # * show loss plot\n",
    "            clear_output(True)\n",
    "            pl.plot(loss_log, '.', alpha=0.1)\n",
    "            pl.yscale('log')\n",
    "            pl.ylim(np.min(loss_log), loss_log[0])\n",
    "            pl.show()\n",
    "            \n",
    "            # * show batch\n",
    "            after = x.detach().cpu()\n",
    "            show_batch(_BATCH_SIZE_, before, after)\n",
    "            \n",
    "            # * print info\n",
    "            print('\\rstep:', i, '\\tloss:', loss.item(), '\\tmin-loss:', np.min(loss_log),  '\\tlr:', lr_sched.get_last_lr()[0], end='')\n",
    "                \n",
    "        # * save checkpoint\n",
    "        if i % _SAVE_RATE_ == 0 and i != 0:\n",
    "            save_model('_checkpoints', model, _NAME_+'_cp'+str(i))\n",
    "            \n",
    "        # * create video\n",
    "        if i % _VIDEO_RATE_ == 0 and i != 0:\n",
    "            vidgen(f'_videos/{_NAME_}_cp{i}.mp4', model, p=1, n_frames=256, sz=_SIZE_)\n",
    "            \n",
    "# * save final model\n",
    "if _TRAIN_MODEL_:\n",
    "    save_model('_models', model, _NAME_)\n",
    "    vidgen(f'_videos/_final_{_NAME_}.mp4', model, n_frames=256, sz=_SIZE_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "_PLAY_ = True\n",
    "_MODELS_DIR_ = '_models'\n",
    "_PLAY_DEVICE_ = 'cuda'\n",
    "_RADIUS_ = 8\n",
    "_PLAY_SIZE_ = 64\n",
    "_WINDOW_SCALE_ = 10\n",
    "_WINDOW_BG_COLOR_ = (255, 255, 255)\n",
    "_WINDOW_TEXT_COLOR_ = (0, 0, 0)\n",
    "\n",
    "# * set current device\n",
    "_DEVICE_ = _PLAY_DEVICE_\n",
    "\n",
    "# * method to load model for play\n",
    "def load_model(_model_name):\n",
    "    # * read params from json file\n",
    "    params = {}\n",
    "    with open(_MODELS_DIR_+'\\\\'+_model_name+'_params.json', 'r') as openfile:\n",
    "        params = json.load(openfile)\n",
    "\n",
    "    # * set important parameters\n",
    "    global _SOBEL_DIV_\n",
    "    global _LAP_DIV_ \n",
    "    global _MODEL_TYPE_\n",
    "    global _IS_STEERABLE_\n",
    "    global _LOSS_FUNC_\n",
    "    global _ANGLE_CHANNEL_\n",
    "    global _CHANNELS_\n",
    "    _SOBEL_DIV_ = params['_SOBEL_DIV_']\n",
    "    _LAP_DIV_ = params['_LAP_DIV_']\n",
    "    _MODEL_TYPE_ = params['_MODEL_TYPE_']\n",
    "    _IS_STEERABLE_ = params['_IS_STEERABLE_']\n",
    "    _ANGLE_CHANNEL_ = params['_ANGLE_CHANNEL_']\n",
    "    _LOSS_FUNC_ = params['_MODEL_TYPE_']\n",
    "    _CHANNELS_ = params['_CHANNELS_']\n",
    "    \n",
    "    # * load in model\n",
    "    model = ISO_NCA(_device=_PLAY_DEVICE_, _model_type=_MODEL_TYPE_)\n",
    "    model.load_state_dict(torch.load(_MODELS_DIR_+'\\\\'+_model_name+'.pt', map_location=_PLAY_DEVICE_))\n",
    "    model.eval()\n",
    "\n",
    "    # * create seed and tensor\n",
    "    seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+params['_SEED_FILE_'], params['_SIZE_'])\n",
    "    seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']))\n",
    "    pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "    seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "    tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "    # * randomize angles for steerable models\n",
    "    if _IS_STEERABLE_:\n",
    "        # * randomize angles for steerable models\n",
    "        if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "            tensor[:, -1:] = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "        # * set direction of growth\n",
    "        elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "            tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']))\n",
    "    return model, tensor, params, seed_img\n",
    "\n",
    "# * get list of seeds\n",
    "seeds_list = os.listdir('..\\\\_seeds')\n",
    "seeds_list = [item for item in seeds_list if item.endswith('.png')]\n",
    "print ('seeds: ', seeds_list)\n",
    "curr_seed = 0\n",
    "\n",
    "# * get list of models\n",
    "model_list = os.listdir(_MODELS_DIR_)\n",
    "model_list = [item.replace('.pt', '') for item in model_list if item.endswith('.pt')]\n",
    "print ('models: ', model_list)\n",
    "curr_model = 0\n",
    "\n",
    "# load first model\n",
    "model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
    "\n",
    "# * misc params\n",
    "angle = 0.0\n",
    "fps = 0\n",
    "show_vecs = False\n",
    "bg_color = 'WHITE' if _WINDOW_BG_COLOR_ == (255, 255, 255) else 'BLACK'\n",
    "prev_time = datetime.datetime.now()\n",
    "\n",
    "# * load vector image\n",
    "vec_img = cv2.imread('..\\\\_images\\\\vector_v3.png')\n",
    "vec_img = cv2.resize(vec_img, (_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
    "vec_img = vec_img.astype(float)/255.0\n",
    "\n",
    "# * start pygame\n",
    "pygame.init()\n",
    "pygame.display.set_caption('nca play - '+params['_NAME_'])\n",
    "\n",
    "# * model dependent params\n",
    "size = _PLAY_SIZE_\n",
    "window_size = size * _WINDOW_SCALE_\n",
    "window = pygame.display.set_mode((window_size, window_size))\n",
    "\n",
    "# * text renders\n",
    "font_size = 20\n",
    "my_font = pygame.font.SysFont('consolas', font_size)\n",
    "model_surface = my_font.render('[UP/DOWN] model: ' + params['_NAME_'], False, _WINDOW_TEXT_COLOR_)\n",
    "seed_surface = my_font.render('[LEFT/RIGHT] seed: ' + params['_SEED_FILE_'], False, _WINDOW_TEXT_COLOR_)\n",
    "text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
    "fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
    "vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
    "\n",
    "# * start infinite game loop\n",
    "running = True\n",
    "mouse_down = False\n",
    "model_start = False\n",
    "while running:\n",
    "    if not _PLAY_:\n",
    "        print ('skipping game')\n",
    "        break\n",
    "    # empty cache\n",
    "    torch.cuda.empty_cache()\n",
    "    # handle events\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            # * close application\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                running = False\n",
    "                break\n",
    "            # * toggle showing vectors\n",
    "            if event.key == pygame.K_v:\n",
    "                show_vecs = not show_vecs\n",
    "                vec_surface = my_font.render('[V] show vectors: ' + str(show_vecs), False, _WINDOW_TEXT_COLOR_)\n",
    "            # * start current model\n",
    "            if event.key == pygame.K_SPACE:\n",
    "                model_start = not model_start\n",
    "            # * reset current model\n",
    "            if event.key == pygame.K_r:\n",
    "                model_start = False\n",
    "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "                pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "                seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "                tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _IS_STEERABLE_:\n",
    "                    # * randomize angles for steerable models\n",
    "                    if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "                        tensor[:, -1:] = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                    # * set direction of growth\n",
    "                    elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                        tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "            # * use up/down arrow keys to cycle though models\n",
    "            if event.key == pygame.K_UP:\n",
    "                    curr_model += 1\n",
    "                    if curr_model >= len(model_list):\n",
    "                        curr_model = 0\n",
    "            if event.key == pygame.K_DOWN:\n",
    "                curr_model -= 1\n",
    "                if curr_model < 0:\n",
    "                    curr_model = len(model_list)-1\n",
    "            # * load new model\n",
    "            if event.key == pygame.K_UP or event.key == pygame.K_DOWN:\n",
    "                model_start = False\n",
    "                model, tensor, params, seed_img = load_model(model_list[curr_model])\n",
    "                pygame.display.set_caption('nca play - '+params['_NAME_'])\n",
    "                model_surface = my_font.render('[UP/DOWN] model: '+params['_NAME_'], False, _WINDOW_TEXT_COLOR_)\n",
    "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+params['_SEED_FILE_'], False, _WINDOW_TEXT_COLOR_)\n",
    "            # * use left/right arrow keys to cycle though seeds\n",
    "            if event.key == pygame.K_LEFT:\n",
    "                curr_seed += 1\n",
    "                if curr_seed >= len(seeds_list):\n",
    "                    curr_seed = 0\n",
    "            if event.key == pygame.K_RIGHT:\n",
    "                curr_seed -= 1\n",
    "                if curr_seed < 0:\n",
    "                    curr_seed = len(seeds_list)-1\n",
    "            # * load new seed image\n",
    "            if event.key == pygame.K_LEFT or event.key == pygame.K_RIGHT:\n",
    "                model_start = False\n",
    "                seed_img = load_image_as_tensor('..\\\\_seeds\\\\'+seeds_list[curr_seed], params['_SIZE_'])\n",
    "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']))\n",
    "                pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "                seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "                tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _IS_STEERABLE_:\n",
    "                    # * randomize angles for steerable models\n",
    "                    if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "                        tensor[:, -1:] = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                    # * set direction of growth\n",
    "                    elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                        tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "                seed_surface = my_font.render('[LEFT/RIGHT] seed: '+seeds_list[curr_seed], False, _WINDOW_TEXT_COLOR_)\n",
    "        if event.type == pygame.MOUSEWHEEL:\n",
    "            # * let player rotate seed before starting model\n",
    "            if not model_start:\n",
    "                angle = np.round((event.y * 0.05)+angle, decimals=2)\n",
    "                text_surface = my_font.render('[SCROLL] angle: ' + str(angle) + 'π', False, _WINDOW_TEXT_COLOR_)\n",
    "                seed_img_rot = trans.rotate(seed_img, np.rad2deg(params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "                pad = np.round((_PLAY_SIZE_ - params['_SIZE_'])/2.0, 0).astype(int)\n",
    "                seed_pad = func.pad(seed_img_rot, (pad, pad, pad, pad), 'constant', 0)\n",
    "                tensor = torch.cat([seed_pad, seed_pad[:, 3].repeat(1, 12, 1, 1)], 1).to(_DEVICE_)\n",
    "                # * randomize angles for steerable models\n",
    "                if _IS_STEERABLE_:\n",
    "                    # * randomize angles for steerable models\n",
    "                    if _ANGLE_CHANNEL_ == 'RANDOMIZED':\n",
    "                        tensor[:, -1:] = torch.rand(_SIZE_, _SIZE_)*np.pi*2.0\n",
    "                    # * set direction of growth\n",
    "                    elif _ANGLE_CHANNEL_ == 'DIRECTION':\n",
    "                        tensor[:, -1:] = torch.tensor(np.full((_SIZE_), params['_SEED_ANGLE_RAD_']+(angle*np.pi)))\n",
    "        # * mouse click events - erase and draw\n",
    "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            mouse_down = True\n",
    "            if pygame.mouse.get_pressed(3)[2] and model_start:\n",
    "                mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
    "                pos = mouse / window_size * size\n",
    "                dot = np.zeros_like(tensor.detach().cpu().numpy())\n",
    "                dot[:, 3:, int(pos[1]), int(pos[0])] = 1.0\n",
    "                tensor += torch.tensor(dot).to(_PLAY_DEVICE_)\n",
    "        if event.type == pygame.MOUSEBUTTONUP:\n",
    "            mouse_down = False\n",
    "        if (event.type == pygame.MOUSEMOTION or event.type == pygame.MOUSEBUTTONDOWN) and mouse_down and model_start:\n",
    "            mouse = np.array(pygame.mouse.get_pos(), dtype=float)\n",
    "            pos = mouse / window_size * size\n",
    "            if pygame.mouse.get_pressed(3)[0]:\n",
    "                mask = circle_mask(size, _RADIUS_, pos)\n",
    "                tensor[0:] *= torch.tensor(mask).to(_PLAY_DEVICE_)\n",
    "            \n",
    "    # * update tensor\n",
    "    if model_start:\n",
    "        with torch.no_grad():\n",
    "            tensor = model(tensor)\n",
    "    \n",
    "    # * draw tensor to window\n",
    "    window.fill(_WINDOW_BG_COLOR_)\n",
    "    img = to_rgb(tensor, _alpha=bg_color).squeeze()\n",
    "    vis = (np.array(img.cpu())*255).astype(np.uint8)\n",
    "    if show_vecs:\n",
    "        vecs = tensor[:, -1:].squeeze(0)\n",
    "        vecs = np.array(vecs.cpu())%(2.0*torch.pi)\n",
    "        pixel = pygame.Surface((_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
    "    else:\n",
    "        pixel = pygame.Surface((_WINDOW_SCALE_, _WINDOW_SCALE_))\n",
    "    for j in range(size):\n",
    "        for i in range(size):\n",
    "            color = vis[:, i, j]\n",
    "            # * create vectors for each cell\n",
    "            if show_vecs:\n",
    "                vec_dir = vecs[:, i, j]\n",
    "                vec = imutils.rotate(vec_img, angle=np.rad2deg(vec_dir).item())\n",
    "                vec *= color\n",
    "                surf = pygame.surfarray.make_surface(vec)\n",
    "                pixel.blit(surf, (0, 0))\n",
    "            # * fill cell with color\n",
    "            else:\n",
    "                pixel.fill(color)\n",
    "            draw_me = pygame.Rect(j*_WINDOW_SCALE_, i*_WINDOW_SCALE_, _WINDOW_SCALE_, _WINDOW_SCALE_)\n",
    "            window.blit(pixel, draw_me)\n",
    "    \n",
    "    # * calculate fps\n",
    "    now = datetime.datetime.now()\n",
    "    if (now - prev_time).seconds >= 1.0:\n",
    "        prev_time = now\n",
    "        fps_surface = my_font.render('fps: ' + str(int(fps)), False, _WINDOW_TEXT_COLOR_)\n",
    "        fps = 0\n",
    "    else:\n",
    "        fps += 1       \n",
    "    \n",
    "    # * render text\n",
    "    window.blit(model_surface, (0, 0))\n",
    "    window.blit(seed_surface, (0, font_size))\n",
    "    window.blit(text_surface, (0, window_size-font_size))\n",
    "    window.blit(vec_surface, (0, window_size-font_size*2))\n",
    "    window.blit(fps_surface, (0, window_size-font_size*3))\n",
    "    \n",
    "    # * flip it!\n",
    "    pygame.display.flip()\n",
    "\n",
    "# * quit it!\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CREATE_VIDEO_ = False\n",
    "_VIDEO_MODEL_ = 'angle_steer_cowboy_2_seeds_v5'\n",
    "global _DEVICE_\n",
    "global _PLAY_DEVICE_\n",
    "_DEVICE_ = 'cuda'\n",
    "_PLAY_DEVICE_ = 'cuda'\n",
    "    \n",
    "if _CREATE_VIDEO_:\n",
    "    model, tensor, params, seed_img = load_model(_VIDEO_MODEL_)\n",
    "    vidgen(f'_videos/{_VIDEO_MODEL_}.mp4', model, n_frames=256, sz=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
