****************
timestamp: 2024-04-03 17:27:21.182549
initializing training...
========================
available cuda devices:
0: Quadro RTX 6000, mem:22690MB, mpc:72
1: Quadro RTX 6000, mem:22690MB, mpc:72
2: Quadro RTX 6000, mem:22690MB, mpc:72
3: Quadro RTX 6000, mem:22690MB, mpc:72
4: Quadro RTX 6000, mem:22690MB, mpc:72
5: Quadro RTX 6000, mem:22690MB, mpc:72
6: Quadro RTX 6000, mem:22690MB, mpc:72
7: Quadro RTX 6000, mem:22690MB, mpc:72
========================
device: cuda
forcing cuDNN initialization...
nca perception channels: 65
nca parameter count: 10496
nca isotropic type: 3
training new model from scratch...
model: minicube5_quat_v2
type: QUATERNION
channels: 16
hidden: 128
hidden-seed-info: False
batch-size: 8
pool-size: 32
lr: 0.0005>1e-05 w/ 2000 step
seed.shape: [1, 16, 9, 9, 9]
target.shape: [8, 4, 9, 9, 9]
starting training w/ 5001 epochs...
[100/5001]	 0.312it/s	 time: 0:05:21~4:22:09	 loss: 414.041>21.288	 lr: 3.474e-05 ▲
[200/5001]	 0.315it/s	 time: 0:10:34~4:13:36	 loss: 43.638>21.288	 lr: 5.924e-05 ▲
[300/5001]	 0.317it/s	 time: 0:15:46~4:07:00	 loss: 1493.878>21.288	 lr: 8.375e-05 ▲
[400/5001]	 0.32it/s	 time: 0:20:51~3:59:46	 loss: 971.308>21.288	 lr: 0.00010824 ▲
[500/5001]	 0.32it/s	 time: 0:26:03~3:54:27	 loss: 46329.728>21.288	 lr: 0.00013275 ▲
[600/5001]	 0.322it/s	 time: 0:31:05~3:47:56	 loss: 37.917>21.288	 lr: 0.00015724 ▲
[700/5001]	 0.322it/s	 time: 0:36:13~3:42:28	 loss: 23828.807>21.288	 lr: 0.00018174 ▲
[800/5001]	 0.323it/s	 time: 0:41:17~3:36:44	 loss: 974.933>21.099	 lr: 0.00020625 ▲
[900/5001]	 0.322it/s	 time: 0:46:34~3:32:08	 loss: 65.673>19.098	 lr: 0.00023074 ▲
[1000/5001]	 0.322it/s	 time: 0:51:47~3:27:07	 loss: 21.424>17.2	 lr: 0.00025524 ▲
[1100/5001]	 0.322it/s	 time: 0:56:57~3:21:54	 loss: 19.344>15.345	 lr: 0.00027975 ▲
[1200/5001]	 0.322it/s	 time: 1:02:11~3:16:54	 loss: 26.597>14.935	 lr: 0.00030425 ▲
[1300/5001]	 0.322it/s	 time: 1:07:20~3:11:38	 loss: 17.217>13.415	 lr: 0.00032875 ▲
[1400/5001]	 0.322it/s	 time: 1:12:32~3:06:30	 loss: 14.653>11.483	 lr: 0.00035324 ▲
[1500/5001]	 0.322it/s	 time: 1:17:43~3:01:20	 loss: 12.17>8.929	 lr: 0.00037774 ▲
[1600/5001]	 0.322it/s	 time: 1:22:54~2:56:09	 loss: 9.086>6.851	 lr: 0.00040224 ▲
[1700/5001]	 0.322it/s	 time: 1:28:03~2:50:55	 loss: 7.501>6.559	 lr: 0.00042675 ▲
[1800/5001]	 0.322it/s	 time: 1:33:16~2:45:48	 loss: 8.633>6.369	 lr: 0.00045125 ▲
[1900/5001]	 0.322it/s	 time: 1:38:27~2:40:37	 loss: 7.722>6.107	 lr: 0.00047574 ▲
[2000/5001]	 0.321it/s	 time: 1:43:49~2:35:43	 loss: 6.947>5.539	 lr: 0.00049976 ▲
[2100/5001]	 0.321it/s	 time: 1:49:00~2:30:31	 loss: 6.212>5.114	 lr: 0.00047526 ▼
[2200/5001]	 0.321it/s	 time: 1:54:13~2:25:22	 loss: 6.126>4.82	 lr: 0.00045075 ▼
[2300/5001]	 0.321it/s	 time: 1:59:24~2:20:09	 loss: 41.4>4.82	 lr: 0.00042625 ▼
[2400/5001]	 0.321it/s	 time: 2:04:40~2:15:03	 loss: 7.185>4.82	 lr: 0.00040176 ▼
[2500/5001]	 0.321it/s	 time: 2:09:49~2:09:48	 loss: 5.68>4.82	 lr: 0.00037726 ▼
[2600/5001]	 0.321it/s	 time: 2:14:57~2:04:34	 loss: 5.398>4.692	 lr: 0.00035276 ▼
[2700/5001]	 0.321it/s	 time: 2:20:09~1:59:23	 loss: 5.302>4.638	 lr: 0.00032825 ▼
[2800/5001]	 0.321it/s	 time: 2:25:21~1:54:12	 loss: 4.987>4.217	 lr: 0.00030375 ▼
[2900/5001]	 0.321it/s	 time: 2:30:37~1:49:04	 loss: 4.919>3.59	 lr: 0.00027926 ▼
[3000/5001]	 0.321it/s	 time: 2:35:48~1:43:51	 loss: 4.456>3.31	 lr: 0.00025476 ▼
[3100/5001]	 0.321it/s	 time: 2:41:00~1:38:40	 loss: 4.284>3.093	 lr: 0.00023026 ▼
[3200/5001]	 0.321it/s	 time: 2:46:08~1:33:27	 loss: 3.607>2.89	 lr: 0.00020575 ▼
[3300/5001]	 0.321it/s	 time: 2:51:28~1:28:19	 loss: 3.362>2.806	 lr: 0.00018125 ▼
[3400/5001]	 0.321it/s	 time: 2:56:38~1:23:07	 loss: 3.308>2.656	 lr: 0.00015676 ▼
[3500/5001]	 0.321it/s	 time: 3:01:52~1:17:56	 loss: 3.533>2.656	 lr: 0.00013226 ▼
[3600/5001]	 0.321it/s	 time: 3:07:01~1:12:43	 loss: 3.263>2.583	 lr: 0.00010776 ▼
[3700/5001]	 0.321it/s	 time: 3:12:17~1:07:33	 loss: 2.966>2.461	 lr: 8.325e-05 ▼
[3800/5001]	 0.321it/s	 time: 3:17:31~1:02:22	 loss: 2.94>2.461	 lr: 5.875e-05 ▼
[3900/5001]	 0.321it/s	 time: 3:22:40~0:57:09	 loss: 2.809>2.369	 lr: 3.426e-05 ▼
[4000/5001]	 0.321it/s	 time: 3:27:53~0:51:58	 loss: 2.787>2.329	 lr: 1.012e-05 ▼
[4100/5001]	 0.321it/s	 time: 3:33:10~0:46:47	 loss: 2.741>2.323	 lr: 2.237e-05 ▲
[4200/5001]	 0.321it/s	 time: 3:38:24~0:41:35	 loss: 2.732>2.3	 lr: 3.462e-05 ▲
[4300/5001]	 0.32it/s	 time: 3:43:44~0:36:25	 loss: 2.709>2.3	 lr: 4.687e-05 ▲
[4400/5001]	 0.321it/s	 time: 3:48:48~0:31:11	 loss: 2.713>2.285	 lr: 5.912e-05 ▲
[4500/5001]	 0.32it/s	 time: 3:54:01~0:26:00	 loss: 2.717>2.285	 lr: 7.137e-05 ▲
[4600/5001]	 0.32it/s	 time: 3:59:14~0:20:48	 loss: 2.769>2.285	 lr: 8.362e-05 ▲
[4700/5001]	 0.32it/s	 time: 4:04:26~0:15:36	 loss: 2.695>2.285	 lr: 9.587e-05 ▲
[4800/5001]	 0.321it/s	 time: 4:09:35~0:10:23	 loss: 2.686>2.221	 lr: 0.00010812 ▲
[4900/5001]	 0.321it/s	 time: 4:14:41~0:05:11	 loss: 2.715>2.221	 lr: 0.00012037 ▲
[5000/5001]	 0.321it/s	 time: 4:19:53~0:00:00	 loss: 2.657>2.221	 lr: 0.00013262 ▲
model [minicube5_quat_v2_cp5000] saved to _checkpoints...
train time: 4:19:53
model [minicube5_quat_v2] saved to _models...
elapsed time: 4:20:11
****************
