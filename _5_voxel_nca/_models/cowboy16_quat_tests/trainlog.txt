****************
timestamp: 2023-11-14 10:24:59.790619
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:25:25.379906
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:25:53.243220
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:29:31.702298
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:31:03.932365
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:31:28.109196
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:32:10.016251
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:33:19.993304
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:34:26.404385
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:35:45.462548
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:36:58.003050
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:37:23.829076
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:39:57.344289
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:40:10.686662
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:41:25.244357
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:41:51.443747
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:42:08.831449
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:44:09.282098
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:44:32.844833
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:45:42.500070
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:47:05.562001
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:48:17.166544
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:48:48.155562
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:51:30.732120
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:51:59.736299
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:55:47.695957
initializing training...
device: cuda
****************
timestamp: 2023-11-14 10:56:05.837158
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 10:58:42.329977
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 11:01:21.667865
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 11:02:09.952828
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 11:03:21.262213
initializing training...
device: cuda
****************
timestamp: 2023-11-14 11:04:04.288350
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 11:05:38.057656
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 11:05:49.761209
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
training new model from scratch...
model: cowboy16_quat_tests
type: QUATERNION
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
[20/5001]	 0.046it/s	 time: 0:07:11~1 day, 5:48:39	 loss: 32.649>21.429	 lr: 2.039e-05 ▲
[40/5001]	 0.047it/s	 time: 0:14:10~1 day, 5:16:40	 loss: 54.512>21.334	 lr: 3.03e-05 ▲
[60/5001]	 0.047it/s	 time: 0:21:11~1 day, 5:04:05	 loss: 23.431>21.334	 lr: 4.019e-05 ▲
[80/5001]	 0.047it/s	 time: 0:28:30~1 day, 5:12:45	 loss: 23.63>21.334	 lr: 5.01e-05 ▲
[100/5001]	 0.047it/s	 time: 0:35:35~1 day, 5:03:34	 loss: 23.618>21.334	 lr: 5.999e-05 ▲
[120/5001]	 0.046it/s	 time: 0:43:08~1 day, 5:14:05	 loss: 23.627>21.229	 lr: 6.99e-05 ▲
****************
timestamp: 2023-11-14 12:25:45.931746
initializing training...
device: cuda
****************
timestamp: 2023-11-14 12:27:46.871775
initializing training...
device: cuda
****************
timestamp: 2023-11-14 12:28:15.139495
initializing training...
device: cuda
****************
timestamp: 2023-11-14 12:28:35.649430
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
nca isotropic type: 3
training new model from scratch...
model: cowboy16_quat_tests
type: Perception.PYTORCH3D
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 12:31:07.541600
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
nca isotropic type: 3
training new model from scratch...
model: cowboy16_quat_tests
type: Perception.FAST_QUAT
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
****************
timestamp: 2023-11-14 12:45:57.276941
initializing training...
device: cuda
****************
timestamp: 2023-11-14 12:46:48.264528
initializing training...
device: cuda
****************
timestamp: 2023-11-14 12:47:56.569172
initializing training...
device: cuda
nca perception channels: 68
nca parameter count: 10880
nca isotropic type: 3
training new model from scratch...
model: cowboy16_quat_tests
type: Perception.FAST_QUAT
batch-size: 4
pool-size: 32
lr: 0.001>1e-05 w/ 2000 step
seed.shape: [1, 16, 24, 24, 24]
target.shape: [4, 4, 24, 24, 24]
starting training w/ 5001 epochs...
[20/5001]	 0.012it/s	 time: 0:28:49~4 days, 23:35:21	 loss: 28.869>21.693	 lr: 2.039e-05 ▲
