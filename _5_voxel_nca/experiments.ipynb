{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook used to run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing converting pytorch tensor to .obj file\n",
    "\n",
    "with open('../obj/test.mtl', 'w') as f:\n",
    "    f.write('newmtl mycolor\\n')\n",
    "    f.write('Ka 0.0 0.0 0.0\\n')\n",
    "    f.write('Kd 1.0 0.0 0.0\\n')\n",
    "    f.write('Ks 0.0 0.0 0.0\\n')\n",
    "    f.write('Ns 0.0\\n')\n",
    "    f.write('illum 0\\n')\n",
    "    f.write('\\n')\n",
    "\n",
    "with open('../obj/test.obj', 'w') as f:\n",
    "    f.write('o test_obj\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('mtllib test.mtl\\n')\n",
    "    f.write('usemtl mycolor\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    # f.write('vt 0.0 0.5\\n')\n",
    "    # f.write('\\n')\n",
    "    \n",
    "    f.write('v 0.0 0.0 0.0\\n')\n",
    "    f.write('v 0.0 0.0 1.0\\n')\n",
    "    f.write('v 1.0 0.0 1.0\\n')\n",
    "    f.write('v 1.0 0.0 0.0\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('g square\\n')\n",
    "    f.write('f 1 2 3\\n')\n",
    "    f.write('f 3 4 1\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing converting pytorch tensor to .vox file using midvoxio\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scripts.vox.Vox import Vox\n",
    "from scripts.vox.VoxModels import get_default_palette\n",
    "from midvoxio.voxio import write_list_to_vox, plot_3d\n",
    "\n",
    "target_file = '../voxnp/sphere16.npy'\n",
    "\n",
    "with open(target_file, 'rb') as f:\n",
    "    target_ten = torch.from_numpy(np.load(f))\n",
    "            \n",
    "vox = Vox().load_from_tensor(target_ten)\n",
    "vox.render()\n",
    "\n",
    "print (f'target_ten.shape: {target_ten.shape}')\n",
    "\n",
    "array = target_ten.cpu().detach().numpy().squeeze(0).transpose([1, 2, 3, 0])\n",
    "print (f'array.shape: {array.shape}')\n",
    "\n",
    "# plot_3d(arr=array)\n",
    "\n",
    "palette = get_default_palette()\n",
    "rgb = array[:, :, :, :3]\n",
    "voxels = array[:, :, :, 3] > 0.1\n",
    "\n",
    "write_list_to_vox(arr=array, vox_fname='../saved_vox/sphere16.vox', palette_arr=palette)\n",
    "\n",
    "Vox().load_from_file('../saved_vox/sphere16.vox').render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing converting pytorch tensor to .vox file using voxypy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scripts.vox.Vox import Vox\n",
    "from scripts.vox.VoxModels import get_default_palette\n",
    "from voxypy.models import Entity, Voxel\n",
    "\n",
    "target_file = '../voxnp/sphere16.npy'\n",
    "\n",
    "with open(target_file, 'rb') as f:\n",
    "    target_ten = torch.from_numpy(np.load(f))\n",
    "            \n",
    "vox = Vox().load_from_tensor(target_ten)\n",
    "vox.render()\n",
    "\n",
    "print (f'target_ten.shape: {target_ten.shape}')\n",
    "\n",
    "array = target_ten.cpu().detach().numpy().squeeze(0).transpose([1, 2, 3, 0])\n",
    "print (f'array.shape: {array.shape}')\n",
    "\n",
    "rgb = array[:, :, :, :3]\n",
    "\n",
    "voxels = array[:, :, :, 3] > 0.1\n",
    "\n",
    "# * extract viewable voxels\n",
    "size = array.shape[0]\n",
    "viewable_voxels = []\n",
    "for x in range(size):\n",
    "    for y in range(size):\n",
    "        for z in range(size):\n",
    "            # * make sure not on edge voxel\n",
    "            if x != 0 and x != size-1 and y != 0 and y != size-1 and z != 0 and z != size-1:\n",
    "                \n",
    "                # * check if voxel is completly obstructed\n",
    "                if not (array[x+1, y, z, 3] > 0.1 and\n",
    "                    array[x+1, y, z, 3] > 0.1 and\n",
    "                    array[x-1, y, z, 3] > 0.1 and\n",
    "                    array[x, y+1, z, 3] > 0.1 and\n",
    "                    array[x, y-1, z, 3] > 0.1 and\n",
    "                    array[x, y, z+1, 3] > 0.1 and\n",
    "                    array[x, y, z-1, 3] > 0.1):\n",
    "                    viewable_voxels.append(array[x, y, z])\n",
    "\n",
    "viewable_voxels = np.array(viewable_voxels)\n",
    "print (f'viewable_voxels.shape: {viewable_voxels.shape}')\n",
    "print (f'viewable_voxels: {viewable_voxels}')\n",
    "\n",
    "a, b, c, d = array.shape\n",
    "colors_flat = array.reshape(a*b*c, d)\n",
    "print (f'colors_flat.shape: {colors_flat.shape}')\n",
    "\n",
    "filt_colors_flat = []\n",
    "for color in colors_flat:\n",
    "    if color[3] > 0.1:\n",
    "        filt_colors_flat.append(color)\n",
    "\n",
    "filt_colors_flat = np.array(filt_colors_flat)\n",
    "print (f'filt_colors_flat.shape: {filt_colors_flat.shape}')\n",
    "\n",
    "entity = Entity().from_dense(voxels)\n",
    "# optional\n",
    "# entity.set_palette_from_file('palette.png')\n",
    "# entity.set_palette()\n",
    "entity.save('../saved_vox/sphere16_voxypy.vox')\n",
    "\n",
    "Vox().load_from_file('../saved_vox/sphere16_voxypy.vox').render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing quaternion rotations using pytorch3d.transforms.quaternion_apply\n",
    "\n",
    "from pytorch3d.transforms import quaternion_apply\n",
    "from scripts.nca import VoxelUtil as voxutil\n",
    "import torch\n",
    "import numpy as np\n",
    "pi = np.pi\n",
    "\n",
    "# Example points\n",
    "p1 = torch.tensor([1.0, 0.0, 0.0])  # Point along the x-axis\n",
    "p2 = torch.tensor([0.0, 1.0, 0.0])  # Point along the y-axis\n",
    "p3 = torch.tensor([0.0, 0.0, 1.0])  # Point along the z-axis\n",
    "\n",
    "# Euler angles for rotation (in radians)\n",
    "# 90 degree rotation about x-axis\n",
    "rx1, ry1, rz1 = pi/2, 0.0, 0.0\n",
    "\n",
    "# 90 degree rotation about y-axis\n",
    "rx2, ry2, rz2 = 0.0, pi/2, 0.0\n",
    "\n",
    "# 90 degree rotation about z-axis\n",
    "rx3, ry3, rz3 = 0.0, 0.0, pi/2\n",
    "\n",
    "p = torch.tensor([0.0, 0.0, -1.0])\n",
    "p = p.unsqueeze(0)\n",
    "rx, ry, rz = 0.0, pi/2, 0.0\n",
    "rx, ry, rz = torch.tensor([rx]), torch.tensor([ry]), torch.tensor([rz])\n",
    "rx = rx.unsqueeze(0)\n",
    "ry = ry.unsqueeze(0)\n",
    "rz = rz.unsqueeze(0)\n",
    "\n",
    "print (f'p.shape: {p.shape}')\n",
    "print (f'p: {p}')\n",
    "\n",
    "print (f'rx: {rx}')\n",
    "print (f'ry: {ry}')\n",
    "print (f'rz: {rz}')\n",
    "\n",
    "q = voxutil.euler_to_quaternion(rx, ry, rz)\n",
    "\n",
    "print (f'quaternion rotation: {q}')\n",
    "\n",
    "res = quaternion_apply(q, p)\n",
    "\n",
    "print (f'res: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing cuda availability\n",
    "\n",
    "import torch \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing model type print out\n",
    "\n",
    "from scripts.nca.VoxelPerception import Perception\n",
    "_MODEL_TYPE_ = Perception.YAW_ISO_V2\n",
    "print(f'type: {_MODEL_TYPE_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing seed creation functions\n",
    "\n",
    "from scripts.vox.Vox import Vox\n",
    "from scripts.nca import VoxelUtil as voxutil\n",
    "\n",
    "Vox().load_from_file('../vox/rubiks_slice.vox').render(_show_grid=True)\n",
    "\n",
    "_SEED_DIST_ = 3\n",
    "_SEED_DIC_ = {\n",
    "    'center': None,\n",
    "    'plus_x': None,\n",
    "    'minus_x': None,\n",
    "    'plus_y': 'cyan',\n",
    "    'minus_y': 'red',\n",
    "    'plus_z': None,\n",
    "    'minus_z': None,\n",
    "}\n",
    "seed_ten = voxutil.custom_seed(_size=15, _channels=16, _dist=_SEED_DIST_, _center=_SEED_DIC_['center'], \n",
    "                                _plus_x=_SEED_DIC_['plus_x'], _minus_x=_SEED_DIC_['minus_x'],\n",
    "                                _plus_y=_SEED_DIC_['plus_y'], _minus_y=_SEED_DIC_['minus_y'],\n",
    "                                _plus_z=_SEED_DIC_['plus_z'], _minus_z=_SEED_DIC_['minus_z']).unsqueeze(0)\n",
    "\n",
    "Vox().load_from_tensor(seed_ten).render(_show_grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing out spherical seed generation\n",
    "\n",
    "import scripts.nca.VoxelUtil as util\n",
    "from scripts.vox.Vox import Vox\n",
    "\n",
    "# seed_axis = util.custom_seed(_size=16, _dist=3, _plus_x='red', _plus_y='green', _plus_z='blue')\n",
    "# print (f'seed.shape: {seed_axis.shape}')\n",
    "# Vox().load_from_tensor(seed_axis).render(_show_grid=True)\n",
    "\n",
    "sphere_seed = util.seed_3d(16, 16, 5, 4)\n",
    "print (f'seed.shape: {sphere_seed.shape}')\n",
    "\n",
    "Vox().load_from_tensor(sphere_seed).render(_show_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT: saving perception functions with pickle\n",
    "\n",
    "import pickle\n",
    "from scripts.nca.VoxelNCA import VoxelNCA as NCA\n",
    "from scripts.nca.VoxelPerception import Perception\n",
    "\n",
    "model = NCA(_name='test', _model_type=Perception.ANISOTROPIC)\n",
    "\n",
    "# * pickle perception function\n",
    "with open(f'test_perception_func.pyc', 'ab') as pfile:\n",
    "    pickle.dump(model.p.perception[model.model_type], pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT: loading perception functions with pickle\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "from scripts.nca.VoxelPerception import VoxelPerception as vp\n",
    "\n",
    "pfile = open('test_perception_func.pyc', 'rb')\n",
    "fnc = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "x = torch.rand([1, 3, 2, 2, 2])\n",
    "\n",
    "p = vp('cuda')\n",
    "y = fnc(p, x)\n",
    "\n",
    "print (f'y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT: create colorful sphere target vox\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scripts.vox.Vox import Vox\n",
    "\n",
    "size = 16\n",
    "half = size//2\n",
    "print (f'size: {size}, half: {half}')\n",
    "sphere = np.zeros([1, size, size, size, 4])\n",
    "\n",
    "for x in range(size):\n",
    "    for y in range(size):\n",
    "        for z in range(size):\n",
    "            color = np.array([x/size, y/size, z/size, 1.0])\n",
    "            sphere[:, x, y, z] = color\n",
    "            \n",
    "sphere = sphere.transpose([0, 4, 1, 2, 3])\n",
    "print (f'sphere.shape: {sphere.shape}')\n",
    "\n",
    "x, y, z = np.indices((size, size, size))\n",
    "\n",
    "# Calculate the coordinates of the center\n",
    "center = (size - 1) / 2.0\n",
    "\n",
    "# Calculate the Euclidean distance from the center for each voxel\n",
    "distances = np.sqrt((x - center)**2 + (y - center)**2 + (z - center)**2)\n",
    "\n",
    "mask = torch.tensor(distances < half)\n",
    "mask = mask[None, None, ...]\n",
    "\n",
    "\n",
    "print (f'mask.shape: {mask.shape}')\n",
    "\n",
    "sphere = torch.from_numpy(sphere)\n",
    "sphere *= mask\n",
    "Vox().load_from_tensor(sphere).render()\n",
    "\n",
    "with open('sphere.npy', 'wb') as f:\n",
    "# * EXPERIMENT:     np.save(f, sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing old custom seed creation function\n",
    "\n",
    "import torch\n",
    "from scripts.nca import VoxelUtil as util\n",
    "from scripts.vox.Vox import Vox\n",
    "\n",
    "size = 8\n",
    "dist = 2\n",
    "\n",
    "# seed_1 = util.custom_seed(_size=size, _dist=dist, _plus_x='red', _plus_y='green', _plus_z='blue')\n",
    "# Vox().load_from_tensor(seed_1).render(_show_grid=True)\n",
    "\n",
    "# seed_2 = util.custom_seed(_size=size, _dist=dist, _minus_x='green', _plus_y='red', _plus_z='blue')\n",
    "# Vox().load_from_tensor(seed_2).render(_show_grid=True)\n",
    "\n",
    "# seed_3 = util.custom_seed(_size=size, _dist=dist, _minus_x='red', _minus_y='green', _plus_z='blue')\n",
    "# Vox().load_from_tensor(seed_3).render(_show_grid=True)\n",
    "\n",
    "# seed_4 = util.custom_seed(_size=size, _dist=dist, _plus_x='green', _minus_y='red', _plus_z='blue')\n",
    "# Vox().load_from_tensor(seed_4).render(_show_grid=True)\n",
    "\n",
    "seed_5 = util.custom_seed(_size=size, _dist=2, _plus_y='red',_minus_y='green')\n",
    "seed_5[-1:] = torch.rand(size, size, size)*torch.pi*2.0\n",
    "\n",
    "Vox().load_from_tensor(seed_5).render(_show_grid=True)\n",
    "\n",
    "print (f'seed.shape: {seed_5.shape}')\n",
    "# for i in range(16):\n",
    "#     print (f'layer {i}: {seed_5[i, ...]}')\n",
    "    \n",
    "rot_seed = torch.rot90(seed_5, 1, (2, 3))\n",
    "Vox().load_from_tensor(rot_seed).render(_show_grid=True)\n",
    "\n",
    "print (f'seed.shape: {rot_seed.shape}')\n",
    "# for i in range(16):\n",
    "#     print (f'layer {i}: {rot_seed[i, ...]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing converting euler angles to quaterion and applying rotations\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from scripts.nca import VoxelUtil as util\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "test_cases = [\n",
    "# Basic Cases\n",
    "([0, 0, 0], [1, 0, 0, 0]),\n",
    "\n",
    "# Rotation around Each Axis\n",
    "([45, 0, 0], [0.92388, 0.38268, 0, 0]),\n",
    "([0, 30, 0], [0.96593, 0, 0.25882, 0]),\n",
    "([0, 0, 60], [0.86603, 0, 0, 0.5]),\n",
    "\n",
    "# Combined Rotations\n",
    "([45, 30, 60], [0.85355, 0.35355, 0.14644, 0.35355]),\n",
    "\n",
    "# Negative Angles\n",
    "([-45, -30, -60], [0.85355, -0.35355, -0.14644, -0.35355]),\n",
    "\n",
    "# Edge Cases\n",
    "([90, 0, 0], [0, 1, 0, 0]),\n",
    "([0, 90, 0], [0.70711, 0.70711, 0, 0]),\n",
    "([0, 0, 90], [0.70711, 0, 0, 0.70711]),\n",
    "\n",
    "# Random Angles\n",
    "([23.5, 56.8, -12.3], [0.91018, 0.36363, 0.17845, -0.09006]),\n",
    "\n",
    "# Normalization\n",
    "([180, 0, 0], [-1, 0, 0, 0]),\n",
    "\n",
    "# Singularities\n",
    "([90, 90, 0], [0.5, 0.5, 0.5, -0.5]),\n",
    "([90, -90, 0], [0.5, -0.5, 0.5, 0.5]),\n",
    "]\n",
    "    \n",
    "    \n",
    "for i in range(len(test_cases)):\n",
    "    tc = test_cases[i]\n",
    "    _ax = tc[0][0]\n",
    "    _ay = tc[0][1]\n",
    "    _az = tc[0][2]\n",
    "    x = torch.tensor([math.radians(_ax)]).unsqueeze(0)\n",
    "    y = torch.tensor([math.radians(_ay)]).unsqueeze(0)\n",
    "    z = torch.tensor([math.radians(_az)]).unsqueeze(0)\n",
    "    q = util.euler_to_quaternion(x, y, z)\n",
    "    \n",
    "    r = Rotation.from_euler('xyz', [_ax, _ay, _az], degrees=True)\n",
    "    sci_q = r.as_quat()\n",
    "    sci_q2 = [sci_q[3], sci_q[0], sci_q[1], sci_q[2]]\n",
    "    \n",
    "    \n",
    "    print (f'test case: {i}:\\n\\t angle: {tc[0]},\\n\\t quat: {tc[1]},\\n\\t util res: {np.array(q)},\\n\\t scipy res: {sci_q2},\\n\\t pass: {q == sci_q2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing scipy.spatial.transform.Rotation\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "p = [[0.43, 0.79, 0.11], [0.21, 0.11, 12.33]]\n",
    "r = [[45, 30, 60], [-45, -30, -60]]\n",
    "\n",
    "rot = Rotation.from_euler('xyz', r, degrees=True)\n",
    "res = rot.apply(p)\n",
    "\n",
    "print (f'p: {p}, res: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * EXPERIMENT: testing custom 3d convolution kernels\n",
    "\n",
    "import torch\n",
    "\n",
    "from scripts.vox.Vox import Vox\n",
    "from scripts.nca.VoxelPerception import VoxelPerception as vp\n",
    "from scripts.nca.VoxelPerception import X_SOBEL, Y_SOBEL, Z_SOBEL_DOWN, X_SOBEL_2D_XY, Y_SOBEL_2D_XY, LAP_2D_XY, X_SOBEL_2D_XZ, Y_SOBEL_2D_XZ, LAP_2D_XZ, X_SOBEL_2D_YZ, Y_SOBEL_2D_YZ, LAP_2D_YZ\n",
    "\n",
    "cowboy = Vox().load_from_file('../vox/rubiks_black_cube.vox')\n",
    "size = 16\n",
    "\n",
    "# * make sure Vox.tensor() works as expeccted\n",
    "cowboy_ten = cowboy.tensor().to('cuda')\n",
    "Vox().load_from_tensor(cowboy_ten).render(_show_grid=True)\n",
    "\n",
    "percep = vp()\n",
    "\n",
    "sobel_x_xy = percep.per_channel_conv3d(cowboy_ten, X_SOBEL_2D_XY[None, :])\n",
    "sobel_y_xy = percep.per_channel_conv3d(cowboy_ten, Y_SOBEL_2D_XY[None, :])\n",
    "lap_xy = percep.per_channel_conv3d(cowboy_ten, LAP_2D_XY[None, :])\n",
    "\n",
    "sobel_x_xz = percep.per_channel_conv3d(cowboy_ten, X_SOBEL_2D_XZ[None, :])\n",
    "sobel_y_xz = percep.per_channel_conv3d(cowboy_ten, Y_SOBEL_2D_XZ[None, :])\n",
    "lap_xz= percep.per_channel_conv3d(cowboy_ten, LAP_2D_XZ[None, :])\n",
    "\n",
    "sobel_x_yz = percep.per_channel_conv3d(cowboy_ten, X_SOBEL_2D_YZ[None, :])\n",
    "sobel_y_yz = percep.per_channel_conv3d(cowboy_ten, Y_SOBEL_2D_YZ[None, :])\n",
    "lap_yz= percep.per_channel_conv3d(cowboy_ten, LAP_2D_YZ[None, :])\n",
    "\n",
    "\n",
    "print ('sobel_x_xy:')\n",
    "Vox().load_from_tensor(sobel_x_xy).render(_show_grid=True)\n",
    "\n",
    "print ('sobel_y_xy:')\n",
    "Vox().load_from_tensor(sobel_y_xy).render(_show_grid=True)\n",
    "\n",
    "print ('lap_xy:')\n",
    "Vox().load_from_tensor(lap_xy).render(_show_grid=True)\n",
    "\n",
    "\n",
    "print ('sobel_x_xz:')\n",
    "Vox().load_from_tensor(sobel_x_xz).render(_show_grid=True)\n",
    "\n",
    "print ('sobel_y_xz:')\n",
    "Vox().load_from_tensor(sobel_y_xz).render(_show_grid=True)\n",
    "\n",
    "print ('lap_xz:')\n",
    "Vox().load_from_tensor(lap_xz).render(_show_grid=True)\n",
    "\n",
    "print ('sobel_x_yz:')\n",
    "Vox().load_from_tensor(sobel_x_yz).render(_show_grid=True)\n",
    "\n",
    "print ('sobel_y_yz:')\n",
    "Vox().load_from_tensor(sobel_y_yz).render(_show_grid=True)\n",
    "\n",
    "print ('lap_yz:')\n",
    "Vox().load_from_tensor(lap_yz).render(_show_grid=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
